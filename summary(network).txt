
Android

Most network-connected Android apps use HTTP to send and receive data. The Android platform includes the HttpsURLConnection client, which supports TLS, streaming uploads and downloads, configurable timeouts, IPv6, and connection pooling.





------------------------------------------------------------------------


When using a subclass of AsyncTask to run network operations, you must be cautious that you don't create a memory leak in the case where the Activity that is referenced by the AsyncTask is destroyed before the AsyncTask finishes its background work. To ensure this doesn't happen, the following snippet clears any references to the Activity in the Fragment's onDetach() method.


------------------------------------------------------------------------


Android 原生的http请求

使用HttpURLConnection或者他的子类HttpsURLConnection

例如，使用HttpURLConnection， 一般都是结合 异步任务AsyncTask 或者 线程 来使用的，
为的是防止主线程阻塞， 并且防止 触发  NetworkOnMainThreadException 的异常抛出

也就是说 HttpURLConnection不会像其他第三方库那样 带有异步处理功能，需要自己封装


url.openConnection() 拿到的类
com.android.okhttp.internal.huc.HttpURLConnectionImpl
该源代码移植进了机器的 android / platform / external 里面，
要查看的话，只能下载源码，或者去官方源码的文档查看
（https://android.googlesource.com/platform/external/okhttp/)
 (https://android.googlesource.com/platform/external/okhttp/+/bad0a11146d43955d3f3b949aa277f0dd7cc3abb/okhttp-urlconnection/src/main/java/com/squareup/okhttp/internal/huc/HttpURLConnectionImpl.java)





最底层的 android http 连接类：

从URL类的url.openConnection() 开始，在URl类中 URLStreamHandler的赋值是这样的：
       		    if (protocol.equals("file")) {
                        handler = (URLStreamHandler)Class.
                            forName("sun.net.www.protocol.file.Handler").newInstance();
                    } else if (protocol.equals("ftp")) {
                        handler = (URLStreamHandler)Class.
                            forName("sun.net.www.protocol.ftp.Handler").newInstance();
                    } else if (protocol.equals("jar")) {
                        handler = (URLStreamHandler)Class.
                            forName("sun.net.www.protocol.jar.Handler").newInstance();
                    } else if (protocol.equals("http")) {
                        handler = (URLStreamHandler)Class.
                            forName("com.android.okhttp.HttpHandler").newInstance();
                    } else if (protocol.equals("https")) {
                        handler = (URLStreamHandler)Class.
                            forName("com.android.okhttp.HttpsHandler").newInstance();
                    }

也进一步反应了底层是用okhttp写的, 所以说，原生http框架和okhttp框架的区别就是 okhttp1.x 和 okhttp3的区别
这里查看android 官方源代码：
@Override 
protected URLConnection openConnection(URL url) throws IOException {
        return new OkHttpClient().open(url);
    }

https://android.googlesource.com/platform/external/okhttp/+/5f7fde35d881e7e9f8850daeac4de52265635656/android/main/java/com/squareup/okhttp

发现使用的是旧版本的okhttp（目前用的okhttp3)
使用这个版本的okhttp来分析
    // https://mvnrepository.com/artifact/com.squareup.okhttp/okhttp
    compile group: 'com.squareup.okhttp', name: 'okhttp', version: '1.5.4'

看到返回的是HttpURLConnectionImpl类， 也就是网络操作 或者其他方法 都是 okhttp中的 HttpURLConnectionImpl来实现的
  HttpURLConnection open(URL url, Proxy proxy) {
    String protocol = url.getProtocol();
    OkHttpClient copy = copyWithDefaults();
    copy.proxy = proxy;

    if (protocol.equals("http")) return new HttpURLConnectionImpl(url, copy);
    if (protocol.equals("https")) return new HttpsURLConnectionImpl(url, copy);
    throw new IllegalArgumentException("Unexpected protocol: " + protocol);
  }


看到在底层，连接是由httpEngine 实现的

HttpURLConnectionImpl.connect() 和 HttpURLConnectionImpl.getResponse()
这两个方法都会调用initHttpEngine() 和 execute()

excute 中调用 httpEngine.sendRequest();
还调用了httpEngine.readResponse()方法(只有HttpURLConnectionImpl.getResponse() connect方法不会读区response)

httpEngine.sendRequest() 是发起请求的关键，这里会打开套接字，计算响应类型，创建请求体
会对httpEngine中的request对象进行设置,例如：设置请求头( prepareRawRequestHeaders() )， 调用Connection的connect()

execute中的 httpEngine.readResponse() -> (HttpTransport)transport.flushRequest() -> httpConnection.flush() （flush是真正的发出请求的代码段）-> (Okio.sink)sink.flush() 为什么是Okio.sink，因为HttpTransport 是在 Connection中创建的，构造方法HttpTransport时，传入了sink作为参数 而Connection中的sink 就是Okio.sink  ->  （！！！ 到了这里已经有一些代码是android原生代码 的底层代码了） out.flush() 这个 out 通过Connection中的socket.getOutputStream() 获取 是 PlainSocketOutputStream 类 创建于SocksSocketImpl(继承PlainSocketImpl) 中

Connection中的代码已接近于对底层源码的调用，
java.net.Socket 和
java.net.Proxy 和
java.net.SocketTimeoutException
javax.net.ssl.SSLSocket 都是android原生代码


Socket类关乎网络 请求和响应的数据传输, 查看了下java的代码，网络数据传输就是用socket的输入输出流进行传输的



是真正发送请求的代码段

Connection.connect.socket.getOutputStream()


  以下列okhttp1.5的代码为例， 一共会调用两次到三次 excute和sendRequest，第一次是由connection.connect触发
以后都是由connection.getResponseCode()触发，最后一次sendRequest，服务器就收到了一条get请求，并返回响应，
  可以理解为connection.getResponseCode() 才是发送请求到服务器的代码段，
此过程中，本人一直开着服务器的终端 和android机器调试 进行监测
          	connection = okHttpClient.open(url);
                connection.setReadTimeout(3000);
                connection.setConnectTimeout(600000);
                connection.setRequestMethod("GET");
                connection.setDoInput(true);
                connection.connect();
                int responseCode = connection.getResponseCode();
                stream = connection.getInputStream();





      java.net.PlainSocketImpl;
      PlainSocketOutputStream;


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Okhttp3 框架


整体框架:

无论是 okhttp3 还是3之前的1和2，整体架构都是用门面模式（设计模式之一，也称外观模式）去写的，
门面模式：
一、概念介绍
　　外观模式（Facade）,他隐藏了系统的复杂性，并向客户端提供了一个可以访问系统的接口。这种类型的设计模式属于结构性模式。为子系统中的一组接口提供了一个统一的访问接口，这个接口使得子系统更容易被访问或者使用。 
二、角色及使用场景
　　简单来说，该模式就是把一些复杂的流程封装成一个接口供给外部用户更简单的使用。这个模式中，设计到3个角色。
　　1）.门面角色：外观模式的核心。它被客户角色调用，它熟悉子系统的功能。内部根据客户角色的需求预定了几种功能的组合。
　　2）.子系统角色:实现了子系统的功能。它对客户角色和Facade时未知的。它内部可以有系统内的相互交互，也可以由供外界调用的接口。
　　3）.客户角色:通过调用Facede来完成要实现的功能。
　　使用场景：
　　1- 为复杂的模块或子系统提供外界访问的模块；
　　2- 子系统相互独立；
　　3- 在层析结构中，可以使用外观模式定义系统的每一层的入口

核心入口OkHttpClient
  OkHttpClient知晓子模块的所有配置以及提供需要的参数。client会将所有从客户端发来的请求委派到相应的子系统去，例如上面的cache、连接以及连接池相关类的集合、网络配置相关类集合等等。每个子系统都可以被客户端直接调用，或者被门面角色调用。子系统并不知道门面的存在，对于子系统而言，门面仅仅是另外一个客户端而已。同时，OkHttpClient可以看作是整个框架的上下文。

  该框架的几大核心子系统；路由、连接协议、拦截器、代理、安全性认证、连接池以及网络适配。从client大大降低了开发者使用难度。同时非常明了的展示了该框架在所有需要的配置以及获取结果的方式。



-------------------

先是第一章的 Dispatcher会产生作用，然后 Dispatcher中会调用getResponseWithInterceptorChain

特别要记住这个方法，它位于realcall类中，设置了多个非常重要的默认的拦截器，还有开发者自己实现并添加的拦截器
例如：CacheInterceptor（与缓存有关的拦截器），ConnectInterceptor（与连接池复用有关的拦截器），
     client.interceptors()（开发者自己实现并添加的拦截器）
具体看拦截器篇
  Response getResponseWithInterceptorChain() throws IOException {
    // Build a full stack of interceptors.
    List<Interceptor> interceptors = new ArrayList<>();
    interceptors.addAll(client.interceptors());
    interceptors.add(retryAndFollowUpInterceptor);
    interceptors.add(new BridgeInterceptor(client.cookieJar()));
    interceptors.add(new CacheInterceptor(client.internalCache()));
    interceptors.add(new ConnectInterceptor(client));
    if (!forWebSocket) {
      interceptors.addAll(client.networkInterceptors());
    }
    interceptors.add(new CallServerInterceptor(forWebSocket));

    Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);
  }

所有的拦截器最初始的调用也是在这里：
    Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);

？ -> 
工程模式
builder模式
--------------------------------------------------
并发控制，分发机制，Dispatcher

当我们用OkHttpClient.newCall(request)进行execute/enqueue时，实际是将请求Call放到了Dispatcher中，okhttp使用Dispatcher进行线程分发，
它有两种方法，一个是普通的同步单线程； 另一种是 （异步）使用了队列进行并发任务的分发(Dispatch)与回调，

同步：realcall 的 excute 直接调用 getResponseWithInterceptorChain 获取数据

异步：RealCall 的 enqueue 中 client.dispatcher().enqueue(new AsyncCall(responseCallback)) ， 实例化AsyncCall并入队
     dispatcher类中 的enqueue方法，最大请求数和runningAsyncCalls做了对比，如果满足条件，那么就直接把AsyncCall直接加到runningCalls的队列中，
     并在线程池（ThreadPoolExecutor）中执行（线程池会根据当前负载自动创建，销毁，缓存相应的线程）。反之就放入readyAsyncCalls进行缓存等待。

     AsyncCall 的 execute 方法同样调用了getResponseWithInterceptorChain 来获取 response
     
     ThreadPoolExecutor是从ExecutorService接口继承下来的，ExecutorService继承Executor接口
     
     Dispatcher的 finished 方法将 当前正在运行的任务Call从队列runningAsyncCalls中移除后，接着执行promoteCalls()
     Dispatcher 的 promoteCalls()， 其中判断了 runningAsyncCalls.size() >= maxRequests （最大负荷运转） ， readyAsyncCalls.isEmpty()(缓存区是否为空) ，接着迭代器 （Iterator）遍历缓存区readyAsyncCalls ，把 缓存区的call移除再加入到runningAsyncCalls中并执行call


OkHttp采用Dispatcher技术，类似于Nginx，与线程池配合实现了高并发，低阻塞的运行
Okhttp采用Deque作为缓存，按照入队的顺序先进先出
OkHttp最出彩的地方就是在try/finally中调用了finished函数，可以主动控制等待队列的移动，而不是采用锁或者wait/notify，极大减少了编码复杂性


0. RealCall 中有内部类 AsyncCall， AsyncCall是从Runnable继承下来的

1. client.dispatcher().finished(this); 的作用
   runningAsyncCalls移除当前AsyncCall，遍历readyAsyncCalls。
   如果满足条件，把readyAsyncCalls中的AsyncCall移除，加入到runningAsyncCalls并执行。
   AsyncCall是这么执行的：ThreadPoolExecutor.execute(Runnable)

2. 同步和异步都会调用getResponseWithInterceptorChain 和 dispatcher().finished
   同步中 RealCall的execute方法直接调用 dispatcher().finished
   异步中 RealCall的 AsyncCall类 中的 execute方法 调用dispatcher().finished

3. readyAsyncCalls等待队列里面的任务怎么进入到 runningAsyncCalls 里面执行的
   在同步或者异步的每一次任务完成之后，dispatcher().finished调用 promoteCalls() ，
   promoteCalls()主动移动 readyAsyncCalls 和 runningAsyncCalls

4. JAVA多线程 wait/notify 是多线程时，锁对象调用wait方法 让当前线程等待，等到其他线程调用 锁对象的notify方法，让当前线程继续执行

5. 单步和异步的执行流程的不同点：
   总结：两者是互不干扰的，只是调用的方法有些相同

   一开始的入队就已经不同，同步进的是 Deque<RealCall> runningSyncCalls，
   异步进的是 Deque<AsyncCall> runningAsyncCalls 或者 Deque<AsyncCall> readyAsyncCalls 
   (从代码注释来看，runningSyncCalls 是为同步而创建的)
   下面是异步和同步的finish，是不同的方法，第三参数是不同的，意味着同步不会调用promoteCalls
   也就是说，同步并不会推进异步的线程前进，
  /** Used by {@code AsyncCall#run} to signal completion. */
  void finished(AsyncCall call) {
    finished(runningAsyncCalls, call, true);
  }
  /** Used by {@code Call#execute} to signal completion. */
  void finished(RealCall call) {
    finished(runningSyncCalls, call, false);
  }
  private <T> void finished(Deque<T> calls, T call, boolean promoteCalls) {
    int runningCallsCount;
    Runnable idleCallback;
    synchronized (this) {
      if (!calls.remove(call)) throw new AssertionError("Call wasn't in-flight!");
      if (promoteCalls) promoteCalls();
      runningCallsCount = runningCallsCount();
      idleCallback = this.idleCallback;
    }

    if (runningCallsCount == 0 && idleCallback != null) {
      idleCallback.run();
    }
  }

6. maxRequests 和 maxRequestsPerHost区别
   maxRequests = 64: 最大并发请求数为64
   maxRequestsPerHost = 5: 每个主机最大请求数为5，通过判断域名判断是不是相同主机， runningCallsForHost(Call) 方法

7. ThreadPoolExecutor
   一、重用线程池中的线程， 避免因为线程的创建和销毁所带来的性能开销.
   二、有效控制线程池中的最大并发数，避免大量线程之间因为相互抢占系统资源而导致的阻塞现象.
   三、能够对线程进行简单的管理，可提供定时执行和按照指定时间间隔循环执行等功能.




-----------------------------------------------------------------------------------------------------------------------------------------


在线程的使用过程中，要特别注意线程同步的问题，
例如：在线程中遍历列表list，如果其他线程对列表list进行 删除操作，则可能出现 下标溢出、空指针等错误
方法1：如果列表list在主线程创建，则在主线程中复制多个列表list，再作为参数赋给各个线程

方法2：使用线程同步synchronized锁住list，在使用到list的地方都将list使用synchronized锁住

方法3：使用线程同步synchronized锁住方法，封装list，将list用另外的类A 封装，在该类A的实例化对象中对list操作，
	   其他线程通过操作类A的实例化对象来对list操作， 在类A中的操作list的方法method前加入synchronized，将操作list的方法锁住，
	   可以防止多个线程同时操作该方法，这样也就是对list操作实现了线程同步




public ThreadPoolExecutor(int corePoolSize,
                      int maximumPoolSize,
                      long keepAliveTime,
                      TimeUnit unit,
                      BlockingQueue<Runnable> workQueue,
                      ThreadFactory threadFactory,
                      RejectedExecutionHandler handler) {
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
corePoolSize: 线程池的核心线程数，默认情况下， 核心线程会在线程池中一直存活， 即使处于闲置状态. 但如果将allowCoreThreadTimeOut设置为true的话, 那么核心线程也会有超时机制， 在keepAliveTime设置的时间过后， 核心线程也会被终止.
maximumPoolSize: 最大的线程数， 包括核心线程， 也包括非核心线程， 在线程数达到这个值后，新来的任务将会被阻塞.
keepAliveTime: 超时的时间， 闲置的非核心线程超过这个时长，讲会被销毁回收， 当allowCoreThreadTimeOut为true时，这个值也作用于核心线程.
unit：超时时间的时间单位.
workQueue：线程池的任务队列， 通过execute方法提交的runnable对象会存储在这个队列中.
threadFactory: 线程工厂, 为线程池提供创建新线程的功能.
handler: 任务无法执行时，回调handler的rejectedExecution方法来通知调用者.

Okhttp中的创建线程工厂
  public static ThreadFactory threadFactory(final String name, final boolean daemon) {
    return new ThreadFactory() {
      @Override public Thread newThread(Runnable runnable) {
        Thread result = new Thread(runnable, name);
        result.setDaemon(daemon);
        return result;
      }
    };
  }

可以使用 execute 和 submit 两个方法向线程池提交任务
（1）execute方法用于提交不需要返回值的任务，利用这种方式提交的任务无法得知是否正常执行
threadPoolExecutor.execute(new Runnable() {  
              
            @Override  
            public void run() {  
                try {  
                    Thread.sleep(5000);  
                } catch (InterruptedException e) {  
                    e.printStackTrace();  
                }  
            }  
        });  
（2） submit方法用于提交一个任务并带有返回值，这个方法将返回一个Future类型对象。可以通过这个返回对象判断任务是否执行成功，并且可以通过future.get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成。
Future<?> future=threadPoolExecutor.submit(futureTask);  
Object value=future.get();  


关闭线程池
可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。

-----------------------------------------------------------------------------------------------------------------------------------------

拦截器机制：

1. getResponseWithInterceptorChain 中创建了Interceptor.Chain，
参数interceptors就是所有的拦截器， 0 是当前index（表示从下标0的interceptor开始执行）
 Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);


2. 在proceed方法中的核心代码可以看到，proceed实际上也做了两件事：
创建下一个拦截链。传入index + 1使得下一个拦截器链只能从下一个拦截器开始访问
执行索引为index的intercept方法，并将下一个拦截器链传入该方法
    RealInterceptorChain next = new RealInterceptorChain(
        interceptors, streamAllocation, httpCodec, connection, index + 1, request);
    Interceptor interceptor = interceptors.get(index);
    Response response = interceptor.intercept(next);


3. 首先是开发者自己在okhttpclient.builder里面add进去的Interceptor，
例如：new OkHttpClient.Builder().addInterceptor(new Interceptor()
之前写过一个Interceptor，我的Interceptor也是通过以下语句来获取response的，
Response response = chain.proceed(request);
而chain.proceed(request) 的 proceed方法就是 RealInterceptorChain的proceed方法，
proceed方法又会去再次执行下一个拦截器的intercept方法


4.总体的执行逻辑：
第一个默认的拦截器RetryAndFollowUpInterceptor的intercept中
这段代码最关键的代码是:
response = ((RealInterceptorChain) chain).proceed(request, streamAllocation, null, null);
这行代码就是执行下一个拦截器链的proceed方法。

***而我们知道在下一个拦截器链（RealInterceptorChain）中又会执行（proceed）下一个拦截器的intercept方法。
所以整个执行链就在拦截器与拦截器链中交替执行，最终完成所有拦截器的操作。
这也是OkHttp拦截器的链式执行逻辑。而一个拦截器的intercept方法所执行的逻辑大致分为三部分：
（1）在发起请求前对request进行处理
（2）调用下一个拦截器，获取response
（3）对response进行处理，返回给上一个拦截器

这就是OkHttp拦截器机制的核心逻辑。
所以一个网络请求实际上就是一个个拦截器执行其intercept方法的过程。
而这其中除了用户自定义的拦截器外还有几个核心拦截器完成了网络访问的核心逻辑，按照先后顺序依次是：
RetryAndFollowUpInterceptor
BridgeInterceptor
CacheInterceptor
ConnectIntercetot
CallServerInterceptor


5. RetryAndFollowUpInterceptor
如上文代码所示，RetryAndFollowUpInterceptor负责两部分逻辑：
在网络请求失败后进行重试
当服务器返回当前请求需要进行重定向时直接发起新的请求，并在条件允许情况下复用当前连接


6. BridgeInterceptor主要负责以下几部分内容：
设置内容长度，内容编码
设置gzip压缩，并在接收到内容后进行解压。省去了应用层处理数据解压的麻烦
添加cookie
设置其他报头，如User-Agent,Host,Keep-alive等。其中Keep-Alive是实现多路复用的必要步骤


7. CacheInterceptor的职责很明确，就是负责Cache的管理
当网络请求有符合要求的Cache时直接返回Cache
当服务器返回内容有改变时更新当前cache
如果当前cache失效，删除


8. ConnectInterceptor的intercept方法只有一行关键代码:
RealConnection connection = streamAllocation.connection();
即为当前请求找到合适的连接，可能复用已有连接也可能是重新创建的连接，返回的连接由连接池负责决定。


9. client.networkInterceptors()，开发者自己加进来的 networkInterceptors，其实也是 Interceptors接口的实现，但是是开发者自己实现的


10. CallServerInterceptor负责向服务器发起真正的访问请求，并在接收到服务器返回后读取响应返回。



总结（再一次写出执行流程）：
1. 分发机制Dispatcher调用 RealCall.getResponseWithInterceptorChain(此过程中将 拦截器列表给了RealInterceptorChain) ->
2. RealInterceptorChain.proceed此过程中 
读取拦截器列表，
创建新的new RealInterceptorChain(本chain的变量给了新的chain，包括了List<Interceptor>,StreamAllocation,HttpCodec,RealConnection,index,Request)
执行 interceptor.intercept()，拦截器index+1
3. intercept又再次执行了 RealInterceptorChain.proceed（为了获取response）
4. 最后由 CallServerInterceptor返回真正从网络拿到的 response




-----------------------------------------------------------------------------------------------------------------------------------------
okhttp连接池 复用机制

keep-alive 就是浏览器和服务端之间保持长连接，这个连接是可以复用的。在HTTP1.1中是默认开启的。
Connection是response中的头字段，他有两个值，其中之一就是keep-alive

例如：浏览器加载一个HTML网页，HTML中可能需要加载数十个资源，典型场景下这些资源中大部分来自同一个站点。
按照HTTP1.0的做法，这需要建立数十个TCP连接，每个连接负责一个资源请求。创建一个TCP连接需要3次握手，而释放连接则需要2次或4次握手。
重复的创建和释放连接极大地影响了网络效率，同时也增加了系统开销。

keep-alive在传输数据后仍然保持连接，当客户端需要再次获取数据时，直接使用刚刚空闲下来的连接而 不需要再次握手（这个很重要）
在现代浏览器中，一般同时开启6～8个keepalive connections的socket连接，并保持一定的链路生命，当不需要时再关闭；
而在服务器中，一般是由软件根据负载情况(比如FD最大值、Socket内存、超时时间、栈内存、栈数量等)决定是否主动关闭。

缺点：如果存在大量空闲的keepalive connections（我们可以称作僵尸连接或者泄漏连接），其它客户端们的正常连接速度也会受到影响

---------------------------
这是 okhttpClient中的代码，很多地方都会使用到Internal.instance，
特别是用到连接池的几个方法：connectionBecameIdle， get， put等等
Internal.instance = new Internal()

---------------------------

在 ConnectInterceptor的intercept方法中，一步一步往下走，最终步骤是取得到一个RealConnection用来拿response
RouteSelector（路由选择类） 
    streamAllocation.newStream(client, doExtensiveHealthChecks) -> findHealthyConnection -> findConnection


get是ConnectionPool中最为重要的方法，StreamAllocation在其findConnection方法内部通过调用get方法为其找到stream找到合适的连接，如果没有则新建一个连接。首先来看下findConnection的逻辑：
查看当前streamAllocation是否有之前已经分配过的连接，有则直接使用
从连接池中查找可复用的连接，有则返回该连接
配置路由，配置后再次从连接池中查找是否有可复用连接，有则直接返回
新建一个连接，并修改其StreamAllocation标记计数，将其放入连接池中
查看连接池是否有重复的多路复用连接，有则清除


private RealConnection findConnection(int connectTimeout, int readTimeout, int writeTimeout,
                                        boolean connectionRetryEnabled) throws IOException {
    Route selectedRoute;
    synchronized (connectionPool) {
      if (released) throw new IllegalStateException("released");
      if (codec != null) throw new IllegalStateException("codec != null");
      if (canceled) throw new IOException("Canceled");

      // 一个StreamAllocation刻画的是一个Call的数据流动，一个Call可能存在多次请求(重定向，Authenticate等)，所以当发生类似重定向等事件时优先使用原有的连接
      RealConnection allocatedConnection = this.connection;
      if (allocatedConnection != null && !allocatedConnection.noNewStreams) {
        return allocatedConnection;
      }

      // 试图从连接池中找到可复用的连接
      Internal.instance.get(connectionPool, address, this, null);
      if (connection != null) {
        return connection;
      }

      selectedRoute = route;
    }

    // 获取路由配置，所谓路由其实就是代理，ip地址等参数的一个组合
    if (selectedRoute == null) {
      selectedRoute = routeSelector.next();
    }

    RealConnection result;
    synchronized (connectionPool) {
      if (canceled) throw new IOException("Canceled");

      //拿到路由后可以尝试重新从连接池中获取连接，这里主要针对http2协议下清除域名碎片机制
      Internal.instance.get(connectionPool, address, this, selectedRoute);
      if (connection != null) return connection;

      //新建连接
      route = selectedRoute;
      refusedStreamCount = 0;
      result = new RealConnection(connectionPool, selectedRoute);
      //修改result连接stream计数，方便connection标记清理
      acquire(result);
    }

    // Do TCP + TLS handshakes. This is a blocking operation.
    result.connect(connectTimeout, readTimeout, writeTimeout, connectionRetryEnabled);
    routeDatabase().connected(result.route());

    Socket socket = null;
    synchronized (connectionPool) {
      // 将新建的连接放入到连接池中
      Internal.instance.put(connectionPool, result);

      // 如果同时存在多个连向同一个地址的多路复用连接，则关闭多余连接，只保留一个
      if (result.isMultiplexed()) {
        socket = Internal.instance.deduplicate(connectionPool, address, this);
        result = connection;
      }
    }
    closeQuietly(socket);

    return result;
  }



Internal.instance实在okhttpclient中创建实例的，实例的get方法就是直接调用的 connectionPool 的get方法
有关于connectionPool的逻辑，看一下篇


---------------------------

Okhttp支持5个并发KeepAlive，默认链路生命为5分钟(链路空闲后，保持存活的时间)

*Connection: （其实是RealConnection，Connection只是一个接口，一个RealConnection对应一个socket）
对jdk的socket物理连接的包装，它内部有List<WeakReference<StreamAllocation>>的引用

ConnectionPool: Socket连接池，对连接缓存进行回收与管理，与CommonPool有类似的设计
Call: 对http的请求封装，属于程序员能够接触的上层高级代码
StreamAllocation: 表示RealConnection被上层高级代码的引用次数
Deque: Deque也就是双端队列，双端队列同时具有队列和栈性质，经常在缓存中被使用，这个是java基础

*在socket连接中，也就是RealConnection中，本质是封装好的流操作，除非手动close掉连接，基本不会被GC掉，非常容易引发内存泄露。

*小结：在okhttp中，在高层代码的调用中，使用了类似于引用计数的方式跟踪Socket流的调用，这里的计数对象是StreamAllocation，它被反复执行aquire与release操作(点击函数可以进入github查看)，这两个函数其实是在改变RealConnection中的List<WeakReference<StreamAllocation>>大小。List中Allocation的数量也就是物理socket被引用的计数（Refference Count），如果计数为0的话，说明此连接没有被使用，是空闲的，需要通过下文的算法实现回收；如果上层代码仍然引用，就不需要关闭连接。

引用计数法：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用。它不能处理循环引用的问题。

代码分析：
okhttpclient的build方法，创建ConnectionPool，当然，也可以在builder中将自己创建的ConnectionPool传入
      connectionPool = new ConnectionPool();

连接池内部维护了一个叫做OkHttp ConnectionPool的ThreadPool，专门用来淘汰末位的socket，当满足以下条件时，就会进行末位淘汰，非常像GC
1. 并发socket空闲连接超过5个
2. 某个socket的keepalive时间大于5分钟
源码：  private static final Executor executor = new ThreadPoolExecutor(0 /* corePoolSize */,
      Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,
      new SynchronousQueue<Runnable>(), Util.threadFactory("OkHttp ConnectionPool", true));

维护着一个Deque<Connection>，提供get/put/remove等数据结构的功能
  private final Deque<RealConnection> connections = new ArrayDeque<>();

维护着一个RouteDatabase，它用来记录连接失败的Route的黑名单，当连接失败的时候就会把失败的线路加进去（本文不讨论）
  final RouteDatabase routeDatabase = new RouteDatabase();

在连接池ConnectionPool中，提供如下的操作，这里可以看成是对deque的一个简单的包装
//从连接池中获取
get
//放入连接池
put
//线程变成空闲，并调用清理线程池
connectionBecameIdle
//关闭所有连接
evictAll

例如 get方法，遍历了 connections，并返回其中一个满足条件的RealConnection，RealConnection中有一个socket对象，
  @Nullable RealConnection get(Address address, StreamAllocation streamAllocation, Route route) {
    assert (Thread.holdsLock(this));
    for (RealConnection connection : connections) {
      if (connection.isEligible(address, route)) {
        streamAllocation.acquire(connection);
        return connection;
      }
    }
    return null;
  }

随着上述操作被更高级的对象调用，RealConnection中的StreamAllocation被不断的aquire与release，
也就是List<WeakReference<StreamAllocation>>的大小将时刻变化


-----------------------------

自动回收机制：

当用户socket连接成功，向连接池中put新的socket时，回收函数会被主动调用，线程池就会执行cleanupRunnable，如下
//Socket清理的Runnable，每当put操作时，就会被主动调用
//注意put操作是在网络线程， executor 是 ThreadPoolExecutor对象
      executor.execute(cleanupRunnable);

//而Socket清理是在`OkHttp ConnectionPool`线程池中调用
  private final Runnable cleanupRunnable = new Runnable() {
    @Override public void run() {
      while (true) {
        long waitNanos = cleanup(System.nanoTime());
        if (waitNanos == -1) return;
        if (waitNanos > 0) {
          long waitMillis = waitNanos / 1000000L;
          waitNanos -= (waitMillis * 1000000L);
          synchronized (ConnectionPool.this) {
            try {
              ConnectionPool.this.wait(waitMillis, (int) waitNanos);
            } catch (InterruptedException ignored) {
            }
          }
        }
      }
    }
  };
这段死循环实际上是一个阻塞的清理任务，首先进行清理(clean)，并返回下次需要清理的间隔时间，
然后调用wait(timeout)进行等待以释放锁与时间片，当等待时间到了后，再次进行清理，并返回下次要清理的间隔时间

Connect变得闲置时调用了 connectionBecameIdle方法，里面调用了 notifyAll() ，唤醒通知：


Cleanup:
cleanup使用了类似于GC的标记-清除算法，也就是首先标记出最不活跃的连接(我们可以叫做泄漏连接，或者空闲连接)，接着进行清除，流程如下:
 long cleanup(long now) {
    int inUseConnectionCount = 0;
    int idleConnectionCount = 0;
    RealConnection longestIdleConnection = null;
    long longestIdleDurationNs = Long.MIN_VALUE;

    // Find either a connection to evict, or the time that the next eviction is due.
    synchronized (this) {
      // 迭代器遍历
      for (Iterator<RealConnection> i = connections.iterator(); i.hasNext(); ) {
        RealConnection connection = i.next();

        // If the connection is in use, keep searching.
        if (pruneAndGetAllocationCount(connection, now) > 0) {
          // 如果是被使用的，就是活跃的，跳过这个connection，被使用数量加一
          inUseConnectionCount++;
          continue;
        }

        // 如果上面的判断失败，就是不活跃的, 闲置数量加一
        idleConnectionCount++;

        // If the connection is ready to be evicted, we're done.
        long idleDurationNs = now - connection.idleAtNanos;
        // 遍历找出最不活跃的连接,选择排序法
        if (idleDurationNs > longestIdleDurationNs) {
          longestIdleDurationNs = idleDurationNs;
          longestIdleConnection = connection;
        }
      }



    if (longestIdleDurationNs >= this.keepAliveDurationNs
        || idleConnectionCount > this.maxIdleConnections) {
      //如果(`空闲socket连接超过5个`
      //且`keepalive时间大于5分钟`)
      //就将此泄漏连接从`Deque`中移除
      connections.remove(longestIdleConnection);
    } else if (idleConnectionCount > 0) {
      //返回此连接即将到期的时间，供下次清理
      //这里依据是在上文`connectionBecameIdle`中设定的计时
      return keepAliveDurationNs - longestIdleDurationNs;
    } else if (inUseConnectionCount > 0) {
      //全部都是活跃的连接，5分钟后再次清理
      return keepAliveDurationNs;
    } else {
      //没有任何连接，跳出循环
      cleanupRunning = false;
      return -1;
    }
  }

  //关闭连接，返回`0`，也就是立刻再次清理
  closeQuietly(longestIdleConnection.socket());
  return 0;
  }


1. 遍历Deque中所有的RealConnection，标记泄漏的连接
2. 如果被标记的连接满足(空闲socket连接超过5个&&keepalive时间大于5分钟)，就将此连接从Deque中移除，并关闭连接，返回0，也就是将要执行wait(0)，提醒立刻再次扫描
3. 如果(目前还可以塞得下5个连接，但是有可能泄漏的连接(即空闲时间即将达到5分钟))，就返回此连接即将到期的剩余时间，供下次清理
4. 如果(全部都是活跃的连接)，就返回默认的keep-alive时间，也就是5分钟后再执行清理
5. 如果(没有任何连接)，就返回-1,跳出清理的死循环


需要注意的是pruneAndGetAllocationCount方法，这个方法标记并找到最不活跃的连接呢，这里使用了pruneAndGetAllocationCount的方法，它主要依据弱引用是否为null而判断这个连接是否泄漏

//类似于引用计数法，如果引用全部为空，返回立刻清理
private int pruneAndGetAllocationCount(RealConnection connection, long now) {
  //虚引用列表
  List<Reference<StreamAllocation>> references = connection.allocations;
  //遍历弱引用列表
  for (int i = 0; i < references.size(); ) {
    Reference<StreamAllocation> reference = references.get(i);
    //如果正在被使用，跳过，接着循环
    //是否置空是在上文`connectionBecameIdle`的`release`控制的
    if (reference.get() != null) {
      //非常明显的引用计数
      i++;
      continue;
    }

    //否则移除引用
    references.remove(i);
    connection.noNewStreams = true;

    //如果所有分配的流均没了，标记为已经距离现在空闲了5分钟
    if (references.isEmpty()) {
      connection.idleAtNanos = now - keepAliveDurationNs;
      return 0;
    }
  }
    
  return references.size();
}
遍历RealConnection连接中的StreamAllocationList，它维护着一个弱引用列表
查看此StreamAllocation是否为空(它是在线程池的put/remove手动控制的)，如果为空，说明已经没有代码引用这个对象了，需要在List中删除
遍历结束，如果List中维护的StreamAllocation删空了，就返回0，表示这个连接已经没有代码引用了，是泄漏的连接;否则返回非0的值，表示这个仍然被引用，是活跃的连接。



-----------------------------------------------------------------------------------------------------------------------------------------


304 表示服务器没有做修改，客户端直接使用上一次请求的缓存，

跟缓存有关的头字段，需要注意的是，有些字段是请求头的，有些是响应头的，但是是内容相同的，并且有关联：

Expires(响应头字段)
　　http/1.0中定义的header，是最基础的浏览器缓存处理，表示资源在一定时间内从浏览器的缓存中获取资源，不需要请求服务器获取资源，从而达到快速获取资源，缓解服务器压力的目的。
　　在response的header中的格式为：Expires: Thu, 01 Dec 1994 16:00:00 GMT （必须是GMT格式）

Last-modified(Reponse Header) 和 If-Modified-Since报头(Request Header)
　　望文知义，根据这个词条的直译应该是上次修改（时间），通过修改服务器端的文件后再请求，发现response的header中的Last-modified改变了
更新原理：
　　1、在浏览器首次请求某个资源时，服务器端返回的状态码是200 （ok），内容是你请求的资源，同时有一个Last-Modified的属性标记(Reponse Header)，标识此文件在服务期端最后被修改的时间，格式：Last-Modified:Tue, 24 Feb 2009 08:01:04 GMT
　　2、浏览器第二次请求该资源时，根据HTTP协议的规定，浏览器会向服务器传送If-Modified-Since报头(Request Header)，询问该文件是否在指定时间之后有被修改过，格式为：If-Modified-Since:Tue, 24 Feb 2009 08:01:04 GMT
　　3、如果服务器端的资源没有变化，则服务器返回304状态码（Not Modified），内容为空，这样就节省了传输数据量。当服务器端代码发生改变，则服务器返回200状态码（ok），内容为请求的资源，和第一次请求资源时类似。从而保证在资源没有修改时不向客户端重复发出资源，也保证当服务器有变化时，客户端能够及时得到最新的资源。

ETag（response header） 和 If-None-Match(Request Header)
1、当浏览器首次请求资源的时候，服务器会返回200的状态码（ok）,内容为请求的资源，同时response header会有一个ETag标记，该标记是服务器端根据容器（IIS或者Apache等等）中配置的ETag生成策略生成的一串唯一标识资源的字符串，ETag格式为 ETag:"856247206"
2、当浏览器第2次请求该资源时，浏览器会在传递给服务器的request中添加If-None-Match报头，询问服务器改文件在上次获取后是否修改了，报头格式：If-None-Match:"856246825"
3、服务器在获取到浏览器的请求后，会根据请求的资源查找对应的ETag，将当前服务器端指定资源对应的Etag与request中的If-None-Match进行对比，如果相同，说明资源没有修改，服务器返回304状态码（Not Modified），内容为空；如果对比发现不相同，则返回200状态码，同时将新的Etag添加到返回浏览器的response中。

max-age
 Cache-Control中设置资源在本地缓存时间的一个值，单位为：秒(s)，其他值还有private、no-cache、must-revalidate等
---------------
Last-Modified和Expires的区别
Last-Modified标识是发了http请求出去的，但在资源未修改时（304）返回的response内容为空
Expires不用发送HTTP请求，
通常而言，Last-Modified和Expires一起用，不会只用一个

Etag和Expires
和 Last-Modified和Expires的情况类似，需要Expires控制请求的频率，Etag在强制刷新时作为保障

----------------
Last-Modified和Etag区别
Last-Modified和Etag的功能差不多，实现有区别，一个是标识时间，一个是标识资源。

Last-Modified与ETag是可以一起使用的，服务器会优先验证ETag，一致的情况下，才会继续比对Last-Modified，
最后才决定是否返回304。现在我知道 因为last-modified只能精确到秒级 所以etag才比last-modified的优先级高
如果 ETag 和 Last-Modified 都有，则必须一次性都发给服务器，没有优先级。
最后，如果服务器输出了 ETag，没有必要再输出 Last-Modified。

总之，把Last-Modified 和ETags请求的http报头一起使用，过程如下: 
1. 客户端请求一个页面（A）。  
2. 服务器返回页面A，并在给A加上一个Last-Modified/ETag。  
3. 客户端展现该页面，并将页面连同Last-Modified/ETag一起缓存。  
4. 客户再次请求页面A，并将上次请求时服务器返回的Last-Modified/ETag一起传递给服务器。  
5. 服务器检查该Last-Modified或ETag，并判断出该页面自上次客户端请求之后还未被修改，直接返回响应304和一个空的响应体。

-----------------------------------------------------------------------------------------------------------------------------------------

Okhttp 缓存策略
只是分析了代码，加强了自身理解，具体还是看文档

0. 缓存入口：是否获取缓存是从getResponseWithInterceptorChain这个位于realcall中的方法来判断的，
  Response getResponseWithInterceptorChain() throws IOException {
    // Build a full stack of interceptors.
    List<Interceptor> interceptors = new ArrayList<>();
    interceptors.addAll(client.interceptors());
    interceptors.add(retryAndFollowUpInterceptor);
    interceptors.add(new BridgeInterceptor(client.cookieJar()));

    // 关键， 把 internalCache 给了进去
    interceptors.add(new CacheInterceptor(client.internalCache()));
    interceptors.add(new ConnectInterceptor(client));
    if (!forWebSocket) {
      interceptors.addAll(client.networkInterceptors());
    }
    interceptors.add(new CallServerInterceptor(forWebSocket));

    Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);
  }
}

client中的代码，判断了cache是否为空，再把 cache.internalCache传到CacheInterceptor中，下一篇会介绍cache类的实现，这里跳过
CacheInterceptor 中的InternalCache cache 就是 cacha类的 InternalCache
  InternalCache internalCache() {
    return cache != null ? cache.internalCache : internalCache;
  }


CacheInterceptor 的intercept方法 是关键，
流程 
1.从cache取出候选 Response，如果没有cache，那么cacheCandidate就是null
 Response cacheCandidate = cache != null
        ? cache.get(chain.request())
        : null;

2.接着把使用了cacheCandidate 传给 CacheStrategy（缓存策略类）
在 CacheStrategy中 判断请求头，响应过期等信息，判断缓存是否能用，如下代码
    CacheStrategy strategy = new CacheStrategy.Factory(now, chain.request(), cacheCandidate).get();
    Request networkRequest = strategy.networkRequest;
    Response cacheResponse = strategy.cacheResponse;

这里需要注意的是，通过 get()取出来的 strategy的 cacheResponse很有可能是null的，因为通过了策略判断之后，有可能 缓存的response已经不能用了
networkRequest也可能是空的，因为断网了

3.接下来调用closeQuietly关闭了不可用缓存，

4.判断了networkRequest 和 cacheResponse 是否为空，抛出504

5.判断了网络环境（networkRequest是否为空），返回了 cacheResponse （缓存的请求）

6.之前的取cache已经走完了，接下来是 通过请求网络来获取 response，
networkResponse = chain.proceed(networkRequest) 是 执行网络请求，获取response的语句
chain是RealInterceptorChain类

7.判断了cacheResponse是否为空 和 responseHTTP状态码（HTTP Status Code）是不是 304（状态未改变，可以使用缓存），
并返回response

8.重新封装 cacheResponse 和 networkResponse到一个新的 response

9.检查cache是否为空，把 新的response 存到 cache中



类：
1. CacheStrategy 缓存策略类
new CacheStrategy.Factory(now, chain.request(), cacheCandidate).get()
Factory()方法初始化了多个全局变量，例如：
sentRequestMillis，receivedResponseMillis， servedDate，servedDateString ，expires，lastModified，lastModifiedString ，etag，ageSeconds

get()方式调用getCandidate()真正的逻辑实现，getCandidate()方法中，会创建一个CacheStrategy对象并返回，
CacheStrategy(Request networkRequest, Response cacheResponse)的两个参数是否为空进过的层层判断

getCandidate()总体分为两部分：
上部分是判断了null值，https等等
      if (cacheResponse == null) {
        return new CacheStrategy(request, null);
      }
      if (request.isHttps() && cacheResponse.handshake() == null) {
        return new CacheStrategy(request, null);
      }
      if (!isCacheable(cacheResponse, request)) {
        return new CacheStrategy(request, null);
      }
      CacheControl requestCaching = request.cacheControl();
      if (requestCaching.noCache() || hasConditions(request)) {
        return new CacheStrategy(request, null);
      }
下半部分是判断了过期时间，并且返回一个缓存的response, 此处省略代码
      long ageMillis = cacheResponseAge();
      long freshMillis = computeFreshnessLifetime();
      ......
      if (!responseCaching.noCache() && ageMillis + minFreshMillis < freshMillis + maxStaleMillis) {
        ......
        return new CacheStrategy(null, builder.build());
      }
      ......
      String conditionName;
      String conditionValue;
      if (etag != null) {
      ......
      } else if (lastModified != null) {
      ......
      } else if (servedDate != null) {
      ......
      } else {
        return new CacheStrategy(request, null); // No condition! Make a regular request.
      }
      ......
      return new CacheStrategy(conditionalRequest, cacheResponse);



-----------------------------------------------------------------------------------------------------------------------------------------

序列化 (Serialization)是将对象的状态信息转换为可以存储或传输的形式的过程。一般将一个对象存储至一个储存媒介，例如档案或是记亿体缓冲等。在网络传输过程中，可以是字节或是XML等格式。而字节的或XML编码格式可以还原完全相等的对象。这个相反的过程又称为反序列化。

磁盘缓存 Cache类，
cache类可以直接设置给 OkHttpClient.Builder()，在cache类中可看到代码，只缓存get请求，不是get不缓存
查看其源码可见cache.internalCache 是Cache 类的内部类，但是需要注意的是Cache最终调用的是DiskLruCache 类，Cache 类只不过是它的封装，调用Cache 类来对本地缓存数据进行修改、删除等操作。

这里贴出cache类和DiskLruCache类中的 读取磁盘和写入磁盘代码（删除和更新就不贴了，只是最终操作不一样，流程差不多）

cache.internalCache中的（例如以下put） get,put,remove,update,trackConditionalCacheHit,trackResponse等方法都是调用cahce自己的相同方法名的方法，
    @Override public CacheRequest put(Response response) throws IOException {
      return Cache.this.put(response);
    }

cache的put方法返回response，
private CacheRequest put(Response response) {
    String requestMethod = response.request().method();
    if (HttpMethod.invalidatesCache(response.request().method())) {
      try {
        remove(response.request());
      } catch (IOException ignored) {
      }
      return null;
    }
    if (!requestMethod.equals("GET")) {
      return null;
    }

    if (HttpHeaders.hasVaryAll(response)) {
      return null;
    }
    Entry entry = new Entry(response);
    DiskLruCache.Editor editor = null;
    try {
      editor = cache.edit(urlToKey(response.request()));
      if (editor == null) {
        return null;
      }
      entry.writeTo(editor);
      return new CacheRequestImpl(editor);
    } catch (IOException e) {
      abortQuietly(editor);
      return null;
    }
  }

Cache类的put 方法最终调用的还是DiskLruCache类，即它才是操作本地缓存的底层对象，此方法就是往本地文件中写入缓存数据，首先if判断当前的请求方式是否支持，如果支持的话先移除对应请求的数据，避免重复；然后通过DiskLruCache类获取可书写Editor 对象，然后会根据当前请求的URL做一个MD5的加密，生成的本地缓存名字就是一串字符，如下图所示，获取此文件后，调用Entry的writeTo 方法写入数据即可结束。此方法源码如下：
public void writeTo(DiskLruCache.Editor editor) throws IOException {
      BufferedSink sink = Okio.buffer(editor.newSink(ENTRY_METADATA));

      sink.writeUtf8(url)
          .writeByte('\n');
      sink.writeUtf8(requestMethod)
          .writeByte('\n');
      sink.writeDecimalLong(varyHeaders.size())
          .writeByte('\n');
      for (int i = 0, size = varyHeaders.size(); i < size; i++) {
        sink.writeUtf8(varyHeaders.name(i))
            .writeUtf8(": ")
            .writeUtf8(varyHeaders.value(i))
            .writeByte('\n');
      }

      sink.writeUtf8(new StatusLine(protocol, code, message).toString())
          .writeByte('\n');
      sink.writeDecimalLong(responseHeaders.size() + 2)
          .writeByte('\n');
      for (int i = 0, size = respon
      ......
      }



最后，去查看okhttpclient中设置的缓存目录，可以看到用MD5加密文件名出来的文件
联系上一篇，可以在 CacheInterceptor中看到 对InternalCache cache 的各种操作

-----------------------------------------------------------------------------------------------------------------------------------------

最后一个拦截器：CallServerInterceptor，负责发出网络请求

不过其实在这个拦截器之前，还可以自定义networkInterceptors。
在Okhttp的拦截器链条里面有两个地方可以自定义拦截：
最开始的时候（Interceptors）：对发出去的请求做最初的处理，以及在拿到最后Reponse时候做最后的处理；
最后数据交换前（networkInterceptors）：对发出去的请求做最后的处理，以及在拿到结果时候做最初的处理。
我们可以自定义拦截器，去处理我们需要做的事情。

我们知道Http发送网络请求前两个步骤是： 
1、建立TCP链接 
2、客户端向web服务器发送请求命令：形如GET /login/login.jsp?username=android&password=123 HTTP/1.1的信息
在Okhttp中ConnectInterceptor负责第一个步骤，
第二个步骤是是httpCodec对象的writeRequestHeaders方法。(该方法在CallserverInterceptor的intercept里面调用)

代码
 public Response intercept(Chain chain) throws IOException {
    // 省略部分代码
    // 获取HttpCodec 
    HttpCodec httpCodec = realChain.httpStream();
    // 省略部分代码
    Request request = realChain.request();
    //向服务器发送请求
    httpCodec.writeRequestHeaders(request);

    Response.Builder responseBuilder = null;
    // 检测是否有请求body
    if (HttpMethod.permitsRequestBody(request.method()) && request.body() != null) {

      if ("100-continue".equalsIgnoreCase(request.header("Expect"))) {
        httpCodec.flushRequest();
        //构建responseBuilder对象
        responseBuilder = httpCodec.readResponseHeaders(true);
      }

       //如果服务器允许发送请求body发送
      if (responseBuilder == null) {
        Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength());
        BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
        request.body().writeTo(bufferedRequestBody);
        bufferedRequestBody.close();
      } else if (!connection.isMultiplexed()) {
         //省略部分代码
      }
    }

    //结束请求
    httpCodec.finishRequest();

    //构建请求buidder对象
    if (responseBuilder == null) {
      responseBuilder = httpCodec.readResponseHeaders(false);
    }

    Response response = responseBuilder
        .request(request)
        .handshake(streamAllocation.connection().handshake())
        .sentRequestAtMillis(sentRequestMillis)
        .receivedResponseAtMillis(System.currentTimeMillis())
        .build();

    int code = response.code();
    if (forWebSocket && code == 101) {
      //省略部分代码
    } else {
      response = response.newBuilder()
          .body(httpCodec.openResponseBody(response))
          .build();
    }

    //省略部分代码

    return response;
  }


1. 该方法首先是获取了httpCodec对象，该对象的主要功能就是对不同http协议（http1.1和http/2）的请求和响应做处理，
该对象的初始化是在ConnectIntercepor的intercept里面：
 HttpCodec httpCodec = streamAllocation.newStream(client, doExtensiveHealthChecks);


2. 最终httpCodec的初始化又是在StreamAllocation的newStream方法
  public HttpCodec newStream(OkHttpClient client, boolean doExtensiveHealthChecks) {
     //：省略部分代码;
      HttpCodec resultCodec = resultConnection.newCodec(client, this);

  }
    public HttpCodec newCodec(
      OkHttpClient client, StreamAllocation streamAllocation) throws SocketException {
    if (http2Connection != null) {
      return new Http2Codec(client, streamAllocation, http2Connection);
    } else {
      //设置socket的读超时时间
      socket.setSoTimeout(client.readTimeoutMillis());
      //InputStream的超时时间
      source.timeout().timeout(client.readTimeoutMillis(), MILLISECONDS);
      //OutputStream的超时时间
      sink.timeout().timeout(client.writeTimeoutMillis(), MILLISECONDS);
      return new Http1Codec(client, streamAllocation, source, sink);
    }
  }

3. 可以发现Okhttp的提供了两种HttpCodec的实现类，如果使用了http2协议则返回Http2Codec，否则返回Http1Codec！并且设置了超时时间,本篇就以Http1Codec对象来进行分析。

4. 调用了
public void writeRequestHeaders(Request request) throws IOException {
  //RequestLine.get用来构建形如GET xx HTTP/1.1的字符串
    String requestLine = RequestLine.get(
        request, streamAllocation.connection().route().proxy().type());
  //像服务器发送请求，形如GET xxx HTTP/1.1
    writeRequest(request.headers(), requestLine);
  }  

5. 可以发现Okhttp通过OkIO的Sink对象（该对象可以看做Socket的OutputStream对象）的writeRequest来向服务器发送请求的。
public void writeRequest(Headers headers, String requestLine) throws IOException {
    if (state != STATE_IDLE) throw new IllegalStateException("state: " + state);
    sink.writeUtf8(requestLine).writeUtf8("\r\n");
    for (int i = 0, size = headers.size(); i < size; i++) {
      sink.writeUtf8(headers.name(i))
          .writeUtf8(": ")
          .writeUtf8(headers.value(i))
          .writeUtf8("\r\n");
    }
    sink.writeUtf8("\r\n");
    state = STATE_OPEN_REQUEST_BODY;
  }


6. 我们知道HTTP支持post,delete,get,put等方法，而post，put等方法是需要请求体的（在Okhttp中用RequestBody来表示）。所以接着writeRequestHeaders之后Okhttp对请求体也做了响应的处理：

    //如果当前request请求需要请求体
    if (HttpMethod.permitsRequestBody(request.method()) && request.body() != null) {

      //询问Server使用愿意接受数据 
      if ("100-continue".equalsIgnoreCase(request.header("Expect"))) {
        httpCodec.flushRequest();
        //构建responseBuilder对象
        responseBuilder = httpCodec.readResponseHeaders(true);
      }

       //向服务器发送请求体
      if (responseBuilder == null) {

         //发送请求体，详见下文描述
      } else if (!connection.isMultiplexed()) {
        //省略部分代码
      }
    }
通过上面的代码可以发现Okhttp对Expect头部也做了支持，上面代码对客户端是否使用该头部做了判断，“100 continue”的作用就是：客户端有一个RequestBody(比如post或者PUT方法)要发给服务器，但是客户端希望在发送RequestBody之前查看服务器是否接受这个body,服务端在接受到这个请求后必须进行响应。客户端通过Expect首部来发送这个消息，当然如果客户端没有实体发送，就不应该发送100 continue 首部，因为这样会使服务器误以为客户端有body要发送。所以okhttp在发送这个之前要permitsRequestBody来判断。当然常规的get请求是不会走这个方法的。

7.   //构建请求体对象组成的输入流
  Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength());
        BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
        //发送请求体
        request.body().writeTo(bufferedRequestBody);

8.   //构建请求体对象组成的输入流
  Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength());
        BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
        //发送请求体
        request.body().writeTo(bufferedRequestBody);


9. 客户端向服务端发送请求的部分已经讲解完毕，下面就剩下读取服务器响应然后构建Response对象了
//构建请求buider对象
    if (responseBuilder == null) {
      responseBuilder = httpCodec.readResponseHeaders(false);
    }

    //构建response对象
    Response response = responseBuilder
        .request(request)
        .handshake(streamAllocation.connection().handshake())
        .sentRequestAtMillis(sentRequestMillis)
        .receivedResponseAtMillis(System.currentTimeMillis())
        .build();

    int code = response.code();
    if (forWebSocket && code == 101) {
      //返回空的即无效的响应
      response = response.newBuilder()
          .body(Util.EMPTY_RESPONSE)
          .build();
    } else {
      response = response.newBuilder()
          .body(httpCodec.openResponseBody(response))
          .build();
    }

上面的代码做了三个工作： 
（1）、调用HttpCodec的readResponseHeaders方法读取服务器响应的数据，构建Response.Builder对象（以Hppt1Codec分析）：

 public Response.Builder readResponseHeaders(boolean expectContinue) throws IOException {
      //省略部分代码
      //读取服务器
      StatusLine statusLine = StatusLine.parse(source.readUtf8LineStrict());

      Response.Builder responseBuilder = new Response.Builder()
          .protocol(statusLine.protocol)//http协议版本
          .code(statusLine.code)//http响应状态码
          //http的message :like "OK" or "Not Modified"
          .message(statusLine.message)
          .headers(readHeaders());//http响应header
      //省略部分代码

      return responseBuilder;

  }

（2）、通过ResopnseBuilder对象来最终创建Response对象，并返回。 
最关键的是服务器的响应体或者响应内容是如果传给Response的，代码如下：

  response = response.newBuilder()
          .body(httpCodec.openResponseBody(response))

Response的body通过httpCodec对象的openResponseBody传进来,进入Http1Codec对象的openResponseBody方法看看都做了些神马：

public ResponseBody openResponseBody(Response response) throws IOException {
    Source source = getTransferStream(response);
    return new RealResponseBody(response.headers(), Okio.buffer(source));
  }

很简单，openResponseBody将Socket的输入流InputStream对象交给OkIo的Source对象(在本篇博文中只需简单的将Sink作为Socket的输入流，Source作为Socket的输入流看待即可，详细的分析可参考OKIO），然后封装成RealResponseBody（该类是ResponseBody的子类）作为Response的body.

那么我们怎么通过这个body来获取服务器发送过来的字符串呢？ResponseBody提供了string()方法：

  public final String string() throws IOException {
    BufferedSource source = source();
    try {
      Charset charset = Util.bomAwareCharset(source, charset());
      //InputStream 读取数据
      return source.readString(charset);
    } finally {
      Util.closeQuietly(source);
    }
  }

string(）方法也很简单，就是通过一些处理然后让调用source.readString来读取服务器的数据。需要注意的是该方法最后调用closeQuietly来关闭了当前请求的InputStream输入流，所以string()方法只能调用一次,再次调用的话会报错，毕竟输入流已经关闭了，你还怎么读取数据呢？


总结：
到此为止CallServerInterceptor简单分析完毕，总结下主要做了如下工作： 
（1）获取HttpCodec对象，对<=Http1.1之前的或者http/2不同协议的http请求处理。 
（2）发送http请求数据，构建Resposne.Builder对象，然后构建Response并返回。




其他小结：
1. streamAllocation被创建于RetryAndFollowUpInterceptor，从RetryAndFollowUpInterceptor开始， streamAllocation在RealInterceptorChain中就不再是null，每一次走Interceptor.Intercept 都会被传递给下一个RealInterceptorChain
这个类是用于 连接池的复用计数的，具体看连接池篇

2. HttpCodec 的创建
ConnectInterceptor中 -> streamAllocation.newStream，
StreamAllocation中 -> resultConnection.newCodec 这里判断是支持http1或http2来返回
注释翻译：
/** Flush the request to the underlying socket. */
/** 将请求刷新到底层套接字。*/
HttpCodec.flushRequest

/** Flush the request to the underlying socket and signal no more bytes will be transmitted. */
/** 将请求刷新到底层套接字，并且不会传输更多的字节。*/
HttpCodec.finishRequest

3. sink和source 位于 RealConnection 中，是这么创建的
source = Okio.buffer(Okio.source(socket));
sink = Okio.buffer(Okio.sink(socket));
sink封装了socket的OutputStream输出流
source封装了socket的InputStream输出流
sink和source只是接口，但他们都在Okio.java中被实现了，
他们的flush() close() 等方法都是拿 socket 的输入流和输出流去操作的
具体查看Okio.java

4. http 100-continue 用于客户端在发送POST数据给服务器前，征询服务器情况，看服务器是否处理POST的数据，
如果不处理，客户端则不上传POST数据，如果处理，则POST上传数据。在现实应用中，通过在POST大数据时，才会使用100-continue协议。
客户端策略:
　　　　1）如果客户端有POST数据要上传，可以考虑使用100-continue协议。加入头{"Expect":"100-continue"}
　　　　2）如果没有POST数据，不能使用100-continue协议，因为这会让服务端造成误解。
　　　　3）并不是所有的Server都会正确实现100-continue协议，如果Client发送Expect:100-continue消息后，在timeout时间内无响应，Client需要立马上传POST数据。
　　　　4）有些Server会错误实现100-continue协议，在不需要此协议时返回100，此时客户端应该忽略。
服务端策略:
　　　　1）正确情况下，收到请求后，返回100或错误码。
　　　　2）如果在发送100-continue前收到了POST数据（客户端提前发送POST数据），则不发送100响应码(略去)。






----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Http 请求头中的字段

Accept 设置接受的内容类型
Accept: text/plain

Accept-Charset 设置接受的字符编码
Accept-Charset: utf-8

Accept-Encoding 设置接受的编码格式
Accept-Encoding: gzip, deflate

Accept-Datetime 设置接受的版本时间
Accept-Datetime: Thu, 31 May 2007 20:35:00 GMT

Accept-Language 设置接受的语言
Accept-Language: en-US

Authorization 设置HTTP身份验证的凭证
Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==

Cache-Control 设置请求响应链上所有的缓存机制必须遵守的指令
Cache-Control: no-cache

Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项
Connection: keep-alive
Connection: Upgrade

Content-Length 设置请求体的字节长度
Content-Length: 348

Content-MD5 设置基于MD5算法对请求体内容进行Base64二进制编码
Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==

Content-Type 设置请求体的MIME类型（适用POST和PUT请求）
Content-Type: application/x-www-form-urlencoded

Cookie 设置服务器使用Set-Cookie发送的http cookie
Cookie: $Version=1; Skin=new;

Date 设置消息发送的日期和时间
Date: Tue, 15 Nov 1994 08:12:31 GMT

Expect 标识客户端需要的特殊浏览器行为
Expect: 100-continue

Forwarded 披露客户端通过http代理连接web服务的源信息
Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43
Forwarded: for=192.0.2.43, for=198.51.100.17

From 设置发送请求的用户的email地址
From: user@example.com

Host 设置服务器域名和TCP端口号，如果使用的是服务请求标准端口号，端口号可以省略
Host: en.wikipedia.org:8080
Host: en.wikipedia.org

If-Match 设置客户端的ETag,当时客户端ETag和服务器生成的ETag一致才执行，适用于更新自从上次更新之后没有改变的资源
If-Match: "737060cd8c284d8af7ad3082f209582d

If-Modified-Since 设置更新时间，从更新时间到服务端接受请求这段时间内如果资源没有改变，允许服务端返回304 Not Modified
If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT

If-None-Match 设置客户端ETag，如果和服务端接受请求生成的ETage相同，允许服务端返回304 Not Modified
If-None-Match: "737060cd8c284d8af7ad3082f209582d"

If-Range 设置客户端ETag，如果和服务端接受请求生成的ETage相同，返回缺失的实体部分；否则返回整个新的实体
If-Range: "737060cd8c284d8af7ad3082f209582d"

If-Unmodified-Since 设置更新时间，只有从更新时间到服务端接受请求这段时间内实体没有改变，服务端才会发送响应
If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT

Max-Forwards 限制代理或网关转发消息的次数
Max-Forwards: 10

Origin 标识跨域资源请求（请求服务端设置Access-Control-Allow-Origin响应字段）
Origin: http://www.example-social-network.com

Pragma 设置特殊实现字段，可能会对请求响应链有多种影响
Pragma: no-cache

Proxy-Authorization 为连接代理授权认证信息
Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==

Range 请求部分实体，设置请求实体的字节数范围，具体可以参见HTTP/1.1中的Byte serving
Range: bytes=500-999

Referer 设置前一个页面的地址，并且前一个页面中的连接指向当前请求，意思就是如果当前请求是在A页面中发送的，那么referer就是A页面的url地址（轶事：这个单词正确的拼法应该是"referrer",但是在很多规范中都拼成了"referer"，所以这个单词也就成为标准用法）
Referer: http://en.wikipedia.org/wiki/Main_Page

TE 设置用户代理期望接受的传输编码格式，和响应头中的Transfer-Encoding字段一样
TE: trailers, deflate

Upgrade 请求服务端升级协议
Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket

User-Agent 用户代理的字符串值
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0

Via 通知服务器代理请求
Via: 1.0 fred, 1.1 example.com (Apache/1.1)

Warning 实体可能会发生的问题的通用警告
Warning: 199 Miscellaneous warning

-----------------------------------------------------------------------------------------------------------------------------------------

Http 响应头中的字段
Access-Control-Allow-Origin 指定哪些站点可以参与跨站资源共享
Access-Control-Allow-Origin: *

Accept-Patch 指定服务器支持的补丁文档格式，适用于http的patch方法
Accept-Patch: text/example;charset=utf-8

Accept-Ranges 服务器通过byte serving支持的部分内容范围类型
Accept-Ranges: bytes

Age 对象在代理缓存中暂存的秒数
Age: 12

Allow 设置特定资源的有效行为，适用方法不被允许的http 405错误
Allow: GET, HEAD

Alt-Svc 服务器使用"Alt-Svc"（Alternative Servicesde的缩写）头标识资源可以通过不同的网络位置或者不同的网络协议获取
Alt-Svc: h2="http2.example.com:443"; ma=7200

Cache-Control 告诉服务端到客户端所有的缓存机制是否可以缓存这个对象，单位是秒
Cache-Control: max-age=3600

Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项
Connection: close

Content-Disposition 告诉客户端弹出一个文件下载框，并且可以指定下载文件名
Content-Disposition: attachment; filename="fname.ext"

Content-Encoding 设置数据使用的编码类型
Content-Encoding gzip

Content-Language 为封闭内容设置自然语言或者目标用户语言
Content-Language: en

Content-Length 响应体的字节长度
Content-Length: 348

Content-Location 设置返回数据的另一个位置
Content-Location: /index.htm

Content-MD5 设置基于MD5算法对响应体内容进行Base64二进制编码
Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==

Content-Range 标识响应体内容属于完整消息体中的那一部分
Content-Range: bytes 21010-47021/47022

Content-Type 设置响应体的MIME类型
Content-Type: text/html; charset=utf-8

Date 设置消息发送的日期和时间
Date: Tue, 15 Nov 1994 08:12:31 GMT

ETag 特定版本资源的标识符，通常是消息摘要
ETag: "737060cd8c284d8af7ad3082f209582d"

Expires 设置响应体的过期时间
Expires: Thu, 01 Dec 1994 16:00:00 GMT

Last-Modified 设置请求对象最后一次的修改日期
Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT

Link 设置与其他资源的类型关系
Link: </feed>; rel="alternate"

Location 在重定向中或者创建新资源时使用
Location: http://www.w3.org/pub/WWW/People.html

P3P 以P3P:CP="your_compact_policy"的格式设置支持P3P(Platform for Privacy Preferences Project)策略，大部分浏览器没有完全支持P3P策略，许多站点设置假的策略内容欺骗支持P3P策略的浏览器以获取第三方cookie的授权
P3P: CP="This is not a P3P policy! See http://www.google.com/support/accounts/bin/answer.py?hl=en&answer=151657 for more info."

Pragma 设置特殊实现字段，可能会对请求响应链有多种影响
Pragma: no-cache

Proxy-Authenticate 设置访问代理的请求权限
Proxy-Authenticate: Basic

Public-Key-Pins 设置站点的授权TLS证书
Public-Key-Pins: max-age=2592000; pin-sha256="E9CZ9INDbd+2eRQozYqqbQ2yXLVKB9+xcprMF+44U1g=";

Refresh "重定向或者新资源创建时使用，在页面的头部有个扩展可以实现相似的功能，并且大部分浏览器都支持
<meta http-equiv="refresh" content="5; url=http://example.com/">

Refresh: 5; url=http://www.w3.org/pub/WWW/People.html
Retry-After 如果实体暂时不可用，可以设置这个值让客户端重试，可以使用时间段（单位是秒）或者HTTP时间

Example 1: Retry-After: 120
Example 2: Retry-After: Fri, 07 Nov 2014 23:59:59 GMT

Server 服务器名称
Server: Apache/2.4.1 (Unix)

Set-Cookie 设置HTTP Cookie
Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1

Status 设置HTTP响应状态
Status: 200 OK

Strict-Transport-Security 一种HSTS策略通知HTTP客户端缓存HTTPS策略多长时间以及是否应用到子域
Strict-Transport-Security: max-age=16070400; includeSubDomains

Trailer 标识给定的header字段将展示在后续的chunked编码的消息中
Trailer: Max-Forwards

Transfer-Encoding 设置传输实体的编码格式，目前支持的格式： chunked, compress, deflate, gzip, identity
Transfer-Encoding: chunked

TSV Tracking Status Value，在响应中设置给DNT(do-not-track),可能的取值
　　　"!" — under construction
　　　"?" — dynamic
　　　"G" — gateway to multiple parties
　　　"N" — not tracking
　　　"T" — tracking
　　　"C" — tracking with consent
　　　"P" — tracking only if consented
　　　"D" — disregarding DNT
　　　"U" — updated
TSV: ?

Upgrade 请求客户端升级协议
Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket

Vary 通知下级代理如何匹配未来的请求头已让其决定缓存的响应是否可用而不是重新从源主机请求新的

Example 1: Vary: *
Example 2: Vary: Accept-Language

Via 通知客户端代理，通过其要发送什么响应
Via: 1.0 fred, 1.1 example.com (Apache/1.1)

Warning 实体可能会发生的问题的通用警告
Warning: 199 Miscellaneous warning

WWW-Authenticate 标识访问请求实体的身份验证方案
WWW-Authenticate: Basic

X-Frame-Options 点击劫持保护：
　　　deny frame中不渲染
　　　sameorigin 如果源不匹配不渲染
　　　allow-from 允许指定位置访问
　　　allowall 不标准，允许任意位置访问
X-Frame-Options: deny


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


