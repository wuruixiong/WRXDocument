
Android

Most network-connected Android apps use HTTP to send and receive data. The Android platform includes the HttpsURLConnection client, which supports TLS, streaming uploads and downloads, configurable timeouts, IPv6, and connection pooling.





------------------------------------------------------------------------


When using a subclass of AsyncTask to run network operations, you must be cautious that you don't create a memory leak in the case where the Activity that is referenced by the AsyncTask is destroyed before the AsyncTask finishes its background work. To ensure this doesn't happen, the following snippet clears any references to the Activity in the Fragment's onDetach() method.


------------------------------------------------------------------------


网络协议中的套接字
常用的TCP/IP协议的3种套接字类型如下所示。
1.流式套接字（SOCK_STREAM）：
流式套接字用于提供面向连接、可靠的数据传输服务。该服务将保证数据能够实现无差错、无重复发送，并按顺序接收。流式套接字之所以能够实现可靠的数据服务，原因在于其使用了传输控制协议，即TCP（The Transmission Control Protocol）协议。

2.数据报套接字（SOCK_DGRAM）：
数据报套接字提供了一种无连接的服务。该服务并不能保证数据传输的可靠性，数据有可能在传输过程中丢失或出现数据重复，且无法保证顺序地接收到数据。数据报套接字使用UDP（User Datagram Protocol）协议进行数据的传输。由于数据报套接字不能保证数据传输的可靠性，对于有可能出现的数据丢失情况，需要在程序中做相应的处理。

3.原始套接字（SOCK_RAW）：
原始套接字(SOCKET_RAW)允许对较低层次的协议直接访问，比如IP、 ICMP协议，它常用于检验新的协议实现，或者访问现有服务中配置的新设备，因为RAW SOCKET可以自如地控制Windows下的多种协议，能够对网络底层的传输机制进行控制，所以可以应用原始套接字来操纵网络层和传输层应用。比如，我们可以通过RAW SOCKET来接收发向本机的ICMP、IGMP协议包，或者接收TCP/IP栈不能够处理的IP包，也可以用来发送一些自定包头或自定协议的IP包。网络监听技术很大程度上依赖于SOCKET_RAW
原始套接字与标准套接字（标准套接字指的是前面介绍的流式套接字和数据报套接字）的区别在于：原始套接字可以读写内核没有处理的IP数据包，而流式套接字只能读取TCP协议的数据，数据报套接字只能读取UDP协议的数据。因此，如果要访问其他协议发送数据必须使用原始套接字。

4. Socket=Ip address+ TCP/UDP + port
区分不同应用程序进程间的网络通信和连接,主要有3个参数：通信的目的IP地址、使用的传输层协议(TCP或UDP)和使用的端口号。

5. HTTP是一个客户端和服务器端请求和应答的标准（TCP）
HTTP使用TCP而不是UDP的原因在于一个网页必须传送很多数据，而TCP协议提供传输控制，按顺序组织数据，和错误纠正。

6.UDP是 非连接，就是数据只管发送，不理会接收方是不是能收到
也就没有 连接状态，关闭连接等等行为

Java中的的socket类
 Java中的网络支持针对网络通信的不同层次，Java提供了不同的API，其提供的网络功能有四大类： 
    InetAddress:用于标识网络上的硬件资源，主要是IP地址  
    URL：统一资源定位符，通过URL可以直接读取或写入网络上的数据  
    Sockets：使用TCP协议实现的网络通信Socket相关的类  
    Datagram:使用UDP协议，将数据保存在用户数据报中，通过网络进行通信。

重点是用于 TCP协议 Socket类（服务器端ServerSocket类），（Socket类几乎就是为了TCP连接而设计的，其中大量全局变量保存了许多连接状态）
用于 UDP协议 DatagramSocket

InetAddress类用于标识网络上的硬件资源，标识互联网协议(IP)地址。  该类没有构造方法
//获取本机的InetAddress实例 
InetAddress address =InetAddress.getLocalHost(); 
address.getHostName();//获取计算机名 
address.getHostAddress();//获取IP地址 
byte[] bytes = address.getAddress();//获取字节数组形式的IP地址,以点分隔的四部分 
//获取其他主机的InetAddress实例 
InetAddress address2 =InetAddress.getByName("其他主机名"); 
InetAddress address3 =InetAddress.getByName("IP地址"); 

URL类
//创建一个URL的实例 
URL baidu =new URL("http://www.baidu.com"); 
URL url =new URL(baidu,"/index.html?username=tom#test");//？表示参数，#表示锚点 
url.getProtocol();//获取协议 
url.getHost();//获取主机 
url.getPort();//如果没有指定端口号，根据协议不同使用默认端口。此时getPort()方法的返回值为 -1 
url.getPath();//获取文件路径 
url.getFile();//文件名，包括文件路径+参数 
url.getRef();//相对路径，就是锚点，即#号后面的内容 
url.getQuery();//查询字符串，即参数 


TCP编程
1、TCP协议是面向连接的、可靠的、有序的、以字节流的方式发送数据，通过三次握手方式建立连接，形成传输数据的通道，在连接中进行大量数据的传输，效率会稍低  
2、Java中基于TCP协议实现网络通信的类  客户端的Socket类  服务器端的ServerSocket类
3、Socket通信的步骤
① 创建ServerSocket和Socket ② 打开连接到Socket的输入/输出流 ③ 按照协议对Socket进行读/写操作  ④ 关闭输入输出流、关闭Socket


UDP编程
UDP协议（用户数据报协议）是无连接的、不可靠的、无序的,速度快
进行数据传输时，首先将要传输的数据定义成数据报（Datagram），大小限制在64k，在数据报中指明数据索要达到的Socket（主机地址和端口号），然后再将数据报发送出去
DatagramPacket类:表示数据报包
DatagramSocket类：进行端到端通信的类
1、服务器端实现步骤
① 创建DatagramSocket，指定端口号  ② 创建DatagramPacket  ③ 接受客户端发送的数据信息  ④ 读取数据
2、客户端实现步骤
① 定义发送信息  ② 创建DatagramPacket，包含将要发送的信息  ③ 创建DatagramSocket  ④ 发送数据



Socket中有许多构造器，有些构造方法是会创建套接字并连接的（有些则不会在构造时连接目标服务器），例如以下构造方法：
Socket(String host, int port)
Socket(InetAddress address, int port)
Socket(String host, int port, InetAddress localAddr, int localPort) 
Socket(InetAddress address, int port, InetAddress localAddr, int localPort)


------------------------------------------------------------------------


Android 原生的http请求

使用HttpURLConnection或者他的子类HttpsURLConnection

例如，使用HttpURLConnection， 一般都是结合 异步任务AsyncTask 或者 线程 来使用的，
为的是防止主线程阻塞， 并且防止 触发  NetworkOnMainThreadException 的异常抛出

也就是说 HttpURLConnection不会像其他第三方库那样 带有异步处理功能，需要自己封装


url.openConnection() 拿到的类
com.android.okhttp.internal.huc.HttpURLConnectionImpl
该源代码移植进了机器的 android / platform / external 里面，
要查看的话，只能下载源码，或者去官方源码的文档查看
（https://android.googlesource.com/platform/external/okhttp/)
 (https://android.googlesource.com/platform/external/okhttp/+/bad0a11146d43955d3f3b949aa277f0dd7cc3abb/okhttp-urlconnection/src/main/java/com/squareup/okhttp/internal/huc/HttpURLConnectionImpl.java)





最底层的 android http 连接类：

从URL类的url.openConnection() 开始，在URl类中 URLStreamHandler的赋值是这样的：
       		    if (protocol.equals("file")) {
                        handler = (URLStreamHandler)Class.
                            forName("sun.net.www.protocol.file.Handler").newInstance();
                    } else if (protocol.equals("ftp")) {
                        handler = (URLStreamHandler)Class.
                            forName("sun.net.www.protocol.ftp.Handler").newInstance();
                    } else if (protocol.equals("jar")) {
                        handler = (URLStreamHandler)Class.
                            forName("sun.net.www.protocol.jar.Handler").newInstance();
                    } else if (protocol.equals("http")) {
                        handler = (URLStreamHandler)Class.
                            forName("com.android.okhttp.HttpHandler").newInstance();
                    } else if (protocol.equals("https")) {
                        handler = (URLStreamHandler)Class.
                            forName("com.android.okhttp.HttpsHandler").newInstance();
                    }

也进一步反应了底层是用okhttp写的, 所以说，原生http框架和okhttp框架的区别就是 okhttp1.x 和 okhttp3的区别
这里查看android 官方源代码：
@Override 
protected URLConnection openConnection(URL url) throws IOException {
        return new OkHttpClient().open(url);
    }

https://android.googlesource.com/platform/external/okhttp/+/5f7fde35d881e7e9f8850daeac4de52265635656/android/main/java/com/squareup/okhttp

发现使用的是旧版本的okhttp（目前用的okhttp3)
使用这个版本的okhttp来分析
    // https://mvnrepository.com/artifact/com.squareup.okhttp/okhttp
    compile group: 'com.squareup.okhttp', name: 'okhttp', version: '1.5.4'

看到返回的是HttpURLConnectionImpl类， 也就是网络操作 或者其他方法 都是 okhttp中的 HttpURLConnectionImpl来实现的
  HttpURLConnection open(URL url, Proxy proxy) {
    String protocol = url.getProtocol();
    OkHttpClient copy = copyWithDefaults();
    copy.proxy = proxy;

    if (protocol.equals("http")) return new HttpURLConnectionImpl(url, copy);
    if (protocol.equals("https")) return new HttpsURLConnectionImpl(url, copy);
    throw new IllegalArgumentException("Unexpected protocol: " + protocol);
  }


看到在底层，连接是由httpEngine 实现的

HttpURLConnectionImpl.connect() 和 HttpURLConnectionImpl.getResponse()
这两个方法都会调用initHttpEngine() 和 execute()

excute 中调用 httpEngine.sendRequest();
还调用了httpEngine.readResponse()方法(只有HttpURLConnectionImpl.getResponse() connect方法不会读区response)

httpEngine.sendRequest() 是发起请求的关键，这里会打开套接字，计算响应类型，创建请求体
会对httpEngine中的request对象进行设置,例如：设置请求头( prepareRawRequestHeaders() )， 调用Connection的connect()

execute中的 httpEngine.readResponse() -> (HttpTransport)transport.flushRequest() -> httpConnection.flush() （flush是真正的发出请求的代码段）-> (Okio.sink)sink.flush() 为什么是Okio.sink，因为HttpTransport 是在 Connection中创建的，构造方法HttpTransport时，传入了sink作为参数 而Connection中的sink 就是Okio.sink  ->  （！！！ 到了这里已经有一些代码是android原生代码 的底层代码了） out.flush() 这个 out 通过Connection中的socket.getOutputStream() 获取 是 PlainSocketOutputStream 类 创建于SocksSocketImpl(继承PlainSocketImpl) 中

Connection中的代码已接近于对底层源码的调用，
java.net.Socket 和
java.net.Proxy 和
java.net.SocketTimeoutException
javax.net.ssl.SSLSocket 都是android原生代码


Socket类关乎网络 请求和响应的数据传输, 查看了下java的代码，网络数据传输就是用socket的输入输出流进行传输的



是真正发送请求的代码段

Connection.connect.socket.getOutputStream()


  以下列okhttp1.5的代码为例， 一共会调用两次到三次 excute和sendRequest，第一次是由connection.connect触发
以后都是由connection.getResponseCode()触发，最后一次sendRequest，服务器就收到了一条get请求，并返回响应，
  可以理解为connection.getResponseCode() 才是发送请求到服务器的代码段，
此过程中，本人一直开着服务器的终端 和android机器调试 进行监测
          	connection = okHttpClient.open(url);
                connection.setReadTimeout(3000);
                connection.setConnectTimeout(600000);
                connection.setRequestMethod("GET");
                connection.setDoInput(true);
                connection.connect();
                int responseCode = connection.getResponseCode();
                stream = connection.getInputStream();





      java.net.PlainSocketImpl;
      PlainSocketOutputStream;


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Okhttp3 框架


整体框架:

无论是 okhttp3 还是3之前的1和2，整体架构都是用门面模式（设计模式之一，也称外观模式）去写的，
门面模式：
一、概念介绍
　　外观模式（Facade）,他隐藏了系统的复杂性，并向客户端提供了一个可以访问系统的接口。这种类型的设计模式属于结构性模式。为子系统中的一组接口提供了一个统一的访问接口，这个接口使得子系统更容易被访问或者使用。 
二、角色及使用场景
　　简单来说，该模式就是把一些复杂的流程封装成一个接口供给外部用户更简单的使用。这个模式中，设计到3个角色。
　　1）.门面角色：外观模式的核心。它被客户角色调用，它熟悉子系统的功能。内部根据客户角色的需求预定了几种功能的组合。
　　2）.子系统角色:实现了子系统的功能。它对客户角色和Facade时未知的。它内部可以有系统内的相互交互，也可以由供外界调用的接口。
　　3）.客户角色:通过调用Facede来完成要实现的功能。
　　使用场景：
　　1- 为复杂的模块或子系统提供外界访问的模块；
　　2- 子系统相互独立；
　　3- 在层析结构中，可以使用外观模式定义系统的每一层的入口


其他设计模式：
*设计模式的根本目的是减少项目变化所造成的影响, 就是减少当代码需要修改时，代码修改量的减少

拦截器集群中使用到的设计模式
职责链模式（Chain of Responsibility）：使多个对象都有机会处理同一个请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。
应用场景：
为完成同一个请求，如果存在多个请求处理器以及未知请求处理器个数或者请求处理器可动态配置的情况下，可以考虑使用责任链模式。
简单来说就是降低耦合度，可以单独的对某个链环做修改甚至替换掉这个链环，而不会影响其他链环，更不会影响整体的代码结构



工厂模式
工厂模式是我们最常用的实例化对象模式了，是用工厂方法代替new操作的一种模式。
定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。
用一个工厂类创建不同的 继承自同一个类或者实现自同一个接口的 类的对象，这样设计的原因是为了解决大量同接口类的创建问题，经过分组抽象后，方便进行统一管理。
*为了把 创建对象的过程和普通代码段解耦，如果有许多地方都需要生成A的对象，那么需要写很多new 。如果需要修改的话，要修改许多地方。
实际应用：如果一个对象的创建

例如 ThreadPoolExecutor（线程池）的创建就需要传入一个线程工厂（ThreadFactory）对象，用来负责创建什么样的线程
如果这么创建，无论写哪一个runnable再传给ThreadPoolExecutor的excuteor()都可以得到执行，
new ThreadFactory() {
      @Override public Thread newThread(Runnable runnable) {
        Thread result = new Thread(runnable, name);
        result.setDaemon(daemon);
        return result;
      }
    };


builder模式（创建者模式）
将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。
随意的 增加配置，通过不同的配置得到一个个功能各不相同的对象，
跟 重载 相比起来，不需要写很多重载构造方法，也不会出现一个构造方法传入大一堆参数的情况，代码更简洁


不论是工厂模式还是其它创建型模式，都是一个目的——为了初始化一个对象。或者说，为了构建一个数据结构模型（类和对象本身就是一种自定义的数据结构）。
目的是为了不想让上层使用者直接使用 new 来初始化对象。
这样的原因有很多，绝大多数原因就是对上层的使用者隔离对象创建的过程；或者是对象创建的过程复杂，使用者不容易掌握；或者是对象创建要满足某种条件，这些条件是业务的需求也好，是系统约束也好，没有必要让上层使用者掌握，增加别人开发的难度。
无论是工厂模式，还是上面的战友说的开闭原则，都是为了隔离一些复杂的过程，使得这些复杂的过程不向外暴露，如果暴露了这些过程，会对使用者增加麻烦，这也就是所谓的团队合作。
面向对象封装的本身也就是为了使得对外的 API 尽可能的简化。


核心入口OkHttpClient
  OkHttpClient知晓子模块的所有配置以及提供需要的参数。client会将所有从客户端发来的请求委派到相应的子系统去，例如上面的cache、连接以及连接池相关类的集合、网络配置相关类集合等等。每个子系统都可以被客户端直接调用，或者被门面角色调用。子系统并不知道门面的存在，对于子系统而言，门面仅仅是另外一个客户端而已。同时，OkHttpClient可以看作是整个框架的上下文。

  该框架的几大核心子系统；路由、连接协议、拦截器、代理、安全性认证、连接池以及网络适配。从client大大降低了开发者使用难度。同时非常明了的展示了该框架在所有需要的配置以及获取结果的方式。

（路由，代理，安全性认证，https，安全传输层协议TLS，dns）

-------------------

先是第一章的 Dispatcher会产生作用，然后 Dispatcher中会调用getResponseWithInterceptorChain

特别要记住这个方法，它位于realcall类中，设置了多个非常重要的默认的拦截器，还有开发者自己实现并添加的拦截器
例如：CacheInterceptor（与缓存有关的拦截器），ConnectInterceptor（与连接池复用有关的拦截器），
     client.interceptors()（开发者自己实现并添加的拦截器）
具体看拦截器篇
  Response getResponseWithInterceptorChain() throws IOException {
    // Build a full stack of interceptors.
    List<Interceptor> interceptors = new ArrayList<>();
    interceptors.addAll(client.interceptors());
    interceptors.add(retryAndFollowUpInterceptor);
    interceptors.add(new BridgeInterceptor(client.cookieJar()));
    interceptors.add(new CacheInterceptor(client.internalCache()));
    interceptors.add(new ConnectInterceptor(client));
    if (!forWebSocket) {
      interceptors.addAll(client.networkInterceptors());
    }
    interceptors.add(new CallServerInterceptor(forWebSocket));

    Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);
  }

所有的拦截器最初始的调用也是在这里：
    Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);


--------------------------------------------------

异步请求并发控制，分发机制，Dispatcher


当我们用OkHttpClient.newCall(request)进行execute/enqueue时，实际是将请求Call放到了Dispatcher中，okhttp使用Dispatcher进行线程分发，
它有两种方法，一个是普通的同步单线程； 另一种是 （异步）使用了队列进行并发任务的分发(Dispatch)与回调，

同步：realcall 的 excute 直接调用 getResponseWithInterceptorChain 获取数据

异步：RealCall 的 enqueue 中 client.dispatcher().enqueue(new AsyncCall(responseCallback)) ， 实例化AsyncCall并入队
     dispatcher类中 的enqueue方法，最大请求数和runningAsyncCalls做了对比，如果满足条件，那么就直接把AsyncCall直接加到runningCalls的队列中，
     并在线程池（ThreadPoolExecutor）中执行（线程池会根据当前负载自动创建，销毁，缓存相应的线程）。反之就放入readyAsyncCalls进行缓存等待。

     AsyncCall 的 execute 方法同样调用了getResponseWithInterceptorChain 来获取 response
     
     ThreadPoolExecutor是从ExecutorService接口继承下来的，ExecutorService继承Executor接口
     
     Dispatcher的 finished 方法将 当前正在运行的任务Call从队列runningAsyncCalls中移除后，接着执行promoteCalls()
     Dispatcher 的 promoteCalls()， 其中判断了 runningAsyncCalls.size() >= maxRequests （最大负荷运转） ， readyAsyncCalls.isEmpty()(缓存区是否为空) ，接着迭代器 （Iterator）遍历缓存区readyAsyncCalls ，把 缓存区的call移除再加入到runningAsyncCalls中并执行call


------------------------

疑问：
0. RealCall 中有内部类 AsyncCall， AsyncCall是从Runnable继承下来的

1. client.dispatcher().finished(this); 的作用
   runningAsyncCalls移除当前AsyncCall，遍历readyAsyncCalls。
   如果满足条件，把readyAsyncCalls中的AsyncCall移除，加入到runningAsyncCalls并执行。
   AsyncCall是这么执行的：ThreadPoolExecutor.execute(Runnable)

2. 同步和异步都会调用getResponseWithInterceptorChain 和 dispatcher().finished
   同步中 RealCall的execute方法直接调用 dispatcher().finished
   异步中 RealCall的 AsyncCall类 中的 execute方法 调用dispatcher().finished

3. readyAsyncCalls等待队列里面的任务怎么进入到 runningAsyncCalls 里面执行的
   在同步或者异步的每一次任务完成之后，dispatcher().finished调用 promoteCalls() ，
   promoteCalls()主动移动 readyAsyncCalls 和 runningAsyncCalls

4. JAVA多线程 wait/notify 是多线程时，锁对象调用wait方法 让当前线程等待，等到其他线程调用 锁对象的notify方法，让当前线程继续执行

5. 单步和异步的执行流程的不同点：
   总结：两者是互不干扰的，只是调用的方法有些相同

   一开始的入队就已经不同，同步进的是 Deque<RealCall> runningSyncCalls，
   异步进的是 Deque<AsyncCall> runningAsyncCalls 或者 Deque<AsyncCall> readyAsyncCalls 
   (从代码注释来看，runningSyncCalls 是为同步而创建的)
   下面是异步和同步的finish，是不同的方法，第三参数是不同的，意味着同步不会调用promoteCalls
   也就是说，同步并不会推进异步的线程前进，
  /** Used by {@code AsyncCall#run} to signal completion. */
  void finished(AsyncCall call) {
    finished(runningAsyncCalls, call, true);
  }
  /** Used by {@code Call#execute} to signal completion. */
  void finished(RealCall call) {
    finished(runningSyncCalls, call, false);
  }
  private <T> void finished(Deque<T> calls, T call, boolean promoteCalls) {
    int runningCallsCount;
    Runnable idleCallback;
    synchronized (this) {
      if (!calls.remove(call)) throw new AssertionError("Call wasn't in-flight!");
      if (promoteCalls) promoteCalls();
      runningCallsCount = runningCallsCount();
      idleCallback = this.idleCallback;
    }

    if (runningCallsCount == 0 && idleCallback != null) {
      idleCallback.run();
    }
  }

6. maxRequests 和 maxRequestsPerHost区别
   maxRequests = 64: 最大并发请求数为64
   maxRequestsPerHost = 5: 每个主机最大请求数为5，通过判断域名判断是不是相同主机， runningCallsForHost(Call) 方法

7. ThreadPoolExecutor
   一、重用线程池中的线程， 避免因为线程的创建和销毁所带来的性能开销.
   二、有效控制线程池中的最大并发数，避免大量线程之间因为相互抢占系统资源而导致的阻塞现象.
   三、能够对线程进行简单的管理，可提供定时执行和按照指定时间间隔循环执行等功能.

8. Dispatcher如何实现 任务分发，
   (1) enqueue() 方法操作入队, 入队时，通过 最大并发请求数, 和正在执行的请求数，判定是加入预备队列还是 直接执行队列并直接执行
   (2) 每一个正在执行的请求RealCall.AsyncCall，在execute(执行)最后，
       主动 从直接执行队列移除 本AsyncCall，接着扫描预备执行队列，将待执行请求加入 直接执行队列并直接执行
   


------------------------
并发机制，个人总结下的整体流程：
1. 调用RealCall的enqueue方法进行入队（传入Callback接口的实例）
2. 调用client.dispatcher().enqueue，
   这里判断了 当前最大请求数是否小于 设定的最大请求数，并且判断了 主机最大请求数和当前的请求数
   如果满足，AsyncCall加入runningAsyncCalls并执行；不满足，AsyncCall加入readyAsyncCalls
3. 立即执行client.dispatcher().enqueue(new AsyncCall(responseCallback))，
   executorService()创建一个ThreadPoolExecutor线程池，
4. RealCall内部类AsyncCall被执行
   AsyncCall.execute() 中, 调用getResponseWithInterceptorChain获取response
   client.dispatcher().finished(this) -> dispatcher.promoteCalls,推进线程的执行
5. promoteCalls,主动的把缓存队列向前走了一步:
   遍历缓存区readyAsyncCalls ，把 缓存区的call移除再加入到runningAsyncCalls中并执行call,

------------------------

优点和一句话概括：
OkHttp采用Dispatcher技术，类似于Nginx，与线程池配合实现了高并发，低阻塞的运行
Okhttp采用Deque作为缓存，按照入队的顺序先进先出
OkHttp最出彩的地方就是在try/finally中调用了finished函数，可以主动控制等待队列的移动，而不是采用锁或者wait/notify，极大减少了编码复杂性

Dispatcher这个分发器无疑就是 异步请求，调度机制的核心(但其代码只有200余行)，
通过Dispatcher将任务分发到合适的空闲线程，实现非阻塞，高可用，高并发连接



-----------------------------------------------------------------------------------------------------------------------------------------

线程池相关：

线程池的优点
OkHttp的任务队列在内部维护了一个线程池用于执行具体的网络请求。而线程池最大的好处在于通过线程复用减少非核心任务的损耗。
线程池复用线程，节省了线程创建和销毁的时间：
1.通过对线程进行缓存，减少了创建销毁的时间损失
2.通过控制线程数量阀值，减少了当线程过少时带来的CPU闲置（比如说长时间卡在I/O上了）与线程过多时对JVM的内存与线程切换时系统调用的压力
类似的还有Socket连接池、DB连接池、CommonPool(比如Jedis)等技术。


在线程的使用过程中，要特别注意线程同步的问题，
例如：在线程中遍历列表list，如果其他线程对列表list进行 删除操作，则可能出现 下标溢出、空指针等错误
方法1：如果列表list在主线程创建，则在主线程中复制多个列表list，再作为参数赋给各个线程

方法2：使用线程同步synchronized锁住list，在使用到list的地方都将list使用synchronized锁住

方法3：使用线程同步synchronized锁住方法，封装list，将list用另外的类A 封装，在该类A的实例化对象中对list操作，
	   其他线程通过操作类A的实例化对象来对list操作， 在类A中的操作list的方法method前加入synchronized，将操作list的方法锁住，
	   可以防止多个线程同时操作该方法，这样也就是对list操作实现了线程同步




public ThreadPoolExecutor(int corePoolSize,
                      int maximumPoolSize,
                      long keepAliveTime,
                      TimeUnit unit,
                      BlockingQueue<Runnable> workQueue,
                      ThreadFactory threadFactory,
                      RejectedExecutionHandler handler) {
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
corePoolSize: 线程池的核心线程数，默认情况下， 核心线程会在线程池中一直存活， 即使处于闲置状态. 但如果将allowCoreThreadTimeOut设置为true的话, 那么核心线程也会有超时机制， 在keepAliveTime设置的时间过后， 核心线程也会被终止.
maximumPoolSize: 最大的线程数， 包括核心线程， 也包括非核心线程， 在线程数达到这个值后，新来的任务将会被阻塞.
keepAliveTime: 超时的时间， 闲置的非核心线程超过这个时长，讲会被销毁回收， 当allowCoreThreadTimeOut为true时，这个值也作用于核心线程.
unit：超时时间的时间单位.
workQueue：线程池的任务队列， 通过execute方法提交的runnable对象会存储在这个队列中.
threadFactory: 线程工厂, 为线程池提供创建新线程的功能.
handler: 任务无法执行时，回调handler的rejectedExecution方法来通知调用者.

Okhttp中的创建线程工厂
  public static ThreadFactory threadFactory(final String name, final boolean daemon) {
    return new ThreadFactory() {
      @Override public Thread newThread(Runnable runnable) {
        Thread result = new Thread(runnable, name);
        result.setDaemon(daemon);
        return result;
      }
    };
  }

可以使用 execute 和 submit 两个方法向线程池提交任务
（1）execute方法用于提交不需要返回值的任务，利用这种方式提交的任务无法得知是否正常执行
threadPoolExecutor.execute(new Runnable() {  
              
            @Override  
            public void run() {  
                try {  
                    Thread.sleep(5000);  
                } catch (InterruptedException e) {  
                    e.printStackTrace();  
                }  
            }  
        });  
（2） submit方法用于提交一个任务并带有返回值，这个方法将返回一个Future类型对象。可以通过这个返回对象判断任务是否执行成功，并且可以通过future.get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成。
Future<?> future=threadPoolExecutor.submit(futureTask);  
Object value=future.get();  


关闭线程池
可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。

-----------------------------------------------------------------------------------------------------------------------------------------

拦截器机制：

1. getResponseWithInterceptorChain 中创建了Interceptor.Chain，
参数interceptors就是所有的拦截器， 0 是当前index（表示从下标0的interceptor开始执行）
 Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);


2. 在proceed方法中的核心代码可以看到，proceed实际上也做了两件事：
创建下一个拦截链。传入index + 1使得下一个拦截器链只能从下一个拦截器开始访问
执行索引为index的intercept方法，并将下一个拦截器链传入该方法
    RealInterceptorChain next = new RealInterceptorChain(
        interceptors, streamAllocation, httpCodec, connection, index + 1, request);
    Interceptor interceptor = interceptors.get(index);
    Response response = interceptor.intercept(next);


3. 首先是开发者自己在okhttpclient.builder里面add进去的Interceptor，
例如：new OkHttpClient.Builder().addInterceptor(new Interceptor()
之前写过一个Interceptor，我的Interceptor也是通过以下语句来获取response的，
Response response = chain.proceed(request);
而chain.proceed(request) 的 proceed方法就是 RealInterceptorChain的proceed方法，
proceed方法又会去再次执行下一个拦截器的intercept方法


4.总体的执行逻辑：
第一个默认的拦截器RetryAndFollowUpInterceptor的intercept中
这段代码最关键的代码是:
response = ((RealInterceptorChain) chain).proceed(request, streamAllocation, null, null);
这行代码就是执行下一个拦截器链的proceed方法。

***而我们知道在下一个拦截器链（RealInterceptorChain）中又会执行（proceed）下一个拦截器的intercept方法。
所以整个执行链就在拦截器与拦截器链中交替执行，最终完成所有拦截器的操作。
这也是OkHttp拦截器的链式执行逻辑。而一个拦截器的intercept方法所执行的逻辑大致分为三部分：
（1）在发起请求前对request进行处理
（2）调用下一个拦截器，获取response
（3）对response进行处理，返回给上一个拦截器

这就是OkHttp拦截器机制的核心逻辑。
所以一个网络请求实际上就是一个个拦截器执行其intercept方法的过程。
而这其中除了用户自定义的拦截器外还有几个核心拦截器完成了网络访问的核心逻辑，按照先后顺序依次是：
RetryAndFollowUpInterceptor
BridgeInterceptor
CacheInterceptor
ConnectIntercetot
CallServerInterceptor


5. RetryAndFollowUpInterceptor
如上文代码所示，RetryAndFollowUpInterceptor负责两部分逻辑：
在网络请求失败后进行重试
当服务器返回当前请求需要进行重定向时直接发起新的请求，并在条件允许情况下复用当前连接


6. BridgeInterceptor主要负责以下几部分内容：
设置内容长度，内容编码
设置gzip压缩，并在接收到内容后进行解压。省去了应用层处理数据解压的麻烦
添加cookie
设置其他报头，如User-Agent,Host,Keep-alive等。其中Keep-Alive是实现多路复用的必要步骤


7. CacheInterceptor的职责很明确，就是负责Cache的管理
当网络请求有符合要求的Cache时直接返回Cache
当服务器返回内容有改变时更新当前cache
如果当前cache失效，删除


8. ConnectInterceptor的intercept方法只有一行关键代码:
RealConnection connection = streamAllocation.connection();
即为当前请求找到合适的连接，可能复用已有连接也可能是重新创建的连接，返回的连接由连接池负责决定。


9. client.networkInterceptors()，开发者自己加进来的 networkInterceptors，其实也是 Interceptors接口的实现，但是是开发者自己实现的


10. CallServerInterceptor负责向服务器发起真正的访问请求，并在接收到服务器返回后读取响应返回。



总结（再一次写出执行流程）：
1. 分发机制Dispatcher调用 RealCall.getResponseWithInterceptorChain(此过程中将 拦截器列表给了RealInterceptorChain) ->
2. RealInterceptorChain.proceed此过程中 
读取拦截器列表，
创建新的new RealInterceptorChain(本chain的变量给了新的chain，包括了List<Interceptor>,StreamAllocation,HttpCodec,RealConnection,index,Request)
执行 interceptor.intercept()，拦截器index+1
3. intercept又再次执行了 RealInterceptorChain.proceed（为了获取response）
4. 最后由 CallServerInterceptor返回真正从网络拿到的 response

-----------------------------------------------------------------------------------------------------------------------------------------

301访问的资源已经永久删除，客户端要根据新的URI访问重定向；
301代表永久性转移(Permanently Moved)
302访问的资源可能暂时先用location的URI访问，但旧资源还在的，下次再来访问的时候可能就不用重定向了。
302代表暂时性转移(Temporarily Moved )

RetryAndFollowUpInterceptor （重定向）拦截器

其实就是个死循环，在死循环中重复请求，重复销毁和创建请求，
当不需要重定向返回，或者抛出异常，就退出死循环，
值得注意的是，有个循环20次的限制，此时也是抛出异常退出死循环


1. 会根据客户端请求Request以及OkHttpClient，创建出StreamAllocation，它主要用于管理客户端与服务器之间的连接，同时管理连接池，以及请求成功后的连接释放等操作，
streamAllocation = new StreamAllocation(
        client.connectionPool(), createAddress(request.url()), callStackTrace);

2. 在执行StreamAllocation创建时，可以看到根据客户端请求的地址url，还调用了createAddress方法。进入该方法可以看出，这里返回了一个创建成功的Address，实际上Address就是将客户端请求的网络地址，以及服务器的相关信息，进行了统一的包装，也就是将客户端请求的数据，转换为OkHttp框架中所定义的服务器规范，这样一来，OkHttp框架就可以根据这个规范来与服务器之间进行请求分发了。关于createAddress方法的源代码如下所示，我们这里不针对Address进行详细分析。
  private Address createAddress(HttpUrl url) {
    SSLSocketFactory sslSocketFactory = null;
    HostnameVerifier hostnameVerifier = null;
    CertificatePinner certificatePinner = null;
    if (url.isHttps()) {
      sslSocketFactory = client.sslSocketFactory();
      hostnameVerifier = client.hostnameVerifier();
      certificatePinner = client.certificatePinner();
    }

    return new Address(url.host(), url.port(), client.dns(), client.socketFactory(),
        sslSocketFactory, hostnameVerifier, certificatePinner, client.proxyAuthenticator(),
        client.proxy(), client.protocols(), client.connectionSpecs(), client.proxySelector());
  }


3. 这时我们分析StreamAllocation的构造方法，观察此构造方法可以看出，StreamAllocation创建时，又根据Address，创建了一个路由选择器RouteSelector，可以这样理解，OkHttp通过层层的封装，将请求的服务器相关信息，封装到了不同层次中，而每个层次所处理的职责不同，而Address、RouteSelector等，都是不同层次中，用于对服务器相关信息的包装处理，同时也起到了桥梁的作用。


4. 接下来继续回到RetryAndFollowUpInterceptor，
这时会进入一个while死循环，在这个循环中，一旦出现抛出异常的判断或者退出了死循环（返回resonance），就会释放streamAllocation.release()，
而如果需要重定向，会一直在死循环中跑


5. 首先会进行一个安全检查操作，检查当前请求是否被取消，如果这时请求被取消了，则会通过StreamAllocation释放连接，并抛出异常，
如果这时没有发生上述情况，接下来会通过RealInterceptorChain的proceed方法处理请求，在请求过程中，只要发生异常，releaseConnection就会为true，一旦变为true，就会将StreamAllocation释放掉，


6. 如果这时没有产生异常情况，接下来则会通过响应Response来执行followUpRequest方法，来检查是否需要进行重定向操作。这里我们暂且先不分析此方法，继续在while循环中向下分析，当不需要进行重新定向操作时，就会直接返回Response，
** 注意，这里是死循环（while）中，套一个 try/catch，再执行followUpRequest，如果不需要重定向则返回Response，如果需要重定向，会一只在死循环中跑代码
代码：
      Request followUp = followUpRequest(response);
      if (followUp == null) {
        if (!forWebSocket) {
          streamAllocation.release();
        }
        return response;
      }


7.   // 如果需要重定向，则关闭取回来的response.body
     closeQuietly(response.body());

       // 重定向数量加一，并且不能大于20 个
       // Chrome follows 21 redirects; Firefox,curl, and wget follow 20; Safari follows 16; and HTTP/1.0 recommends 5.
       // Chrome遵循21次重定向; Firefox，curl和wget遵循20; Safari遵循16; HTTP / 1.0建议5。
      if (++followUpCount > MAX_FOLLOW_UPS) {
        streamAllocation.release();
        throw new ProtocolException("Too many follow-up requests: " + followUpCount);
      }

     // UnrepeatableRequestBody 不可重复的的请求
      if (followUp.body() instanceof UnrepeatableRequestBody) {
        streamAllocation.release();
        throw new HttpRetryException("Cannot retry streamed HTTP body", response.code());
      }

     // 如果连接的url不同，重新创建一个streamAllocation
      if (!sameConnection(response, followUp.url())) {
        streamAllocation.release();
        streamAllocation = new StreamAllocation(
            client.connectionPool(), createAddress(followUp.url()), callStackTrace);
      } else if (streamAllocation.codec() != null) {
        throw new IllegalStateException("Closing the body of " + response
            + " didn't close its backing stream. Bad interceptor?");
      }

      request = followUp;
      priorResponse = response;

-----------------------------------------------------------------------------------------------------------------------------------------

通常，HTTP协议中使用Content-Length这个头来告知数据的长度。
然后，在数据下行的过程中，Content-Length的方式要预先在服务器中缓存所有数据，然后所有数据再一股脑儿地发给客户端。
如果要一边产生数据，一边发给客户端，WEB 服务器就需要使用"Transfer-Encoding: chunked"这样的方式来代替Content-Length。

BridgeInterceptor,
Bridges from application code to network code. First it builds a network request from a user request. Then it proceeds to call the network. Finally it builds a user response from the network response.

1. 给请求加一些请求头，值得注意的是，有gzip和Cookie这两个代码比较多的头
      ......
      if (contentType != null) {
        requestBuilder.header("Content-Type", contentType.toString());
      }
      ......
      if (contentLength != -1) {
        requestBuilder.header("Content-Length", Long.toString(contentLength));
        requestBuilder.removeHeader("Transfer-Encoding");
      } else {
        requestBuilder.header("Transfer-Encoding", "chunked");
        requestBuilder.removeHeader("Content-Length");
      }
      ......
  if (userRequest.header("Host") == null) {
    requestBuilder.header("Host", hostHeader(userRequest.url(), false));
  }

  if (userRequest.header("Connection") == null) {
    requestBuilder.header("Connection", "Keep-Alive");
  }

  // If we add an "Accept-Encoding: gzip" header field we're responsible for also decompressing
  // the transfer stream.
  // 如果传了 Accept-Encoding: gzip这个头给服务器，那么需要将服务器回传的 response解压
  boolean transparentGzip = false;
  if (userRequest.header("Accept-Encoding") == null && userRequest.header("Range") == null) {
    transparentGzip = true;
    requestBuilder.header("Accept-Encoding", "gzip");
  }
  // 创建Okhpptclitent时候配置的cookieJar，
  List<Cookie> cookies = cookieJar.loadForRequest(userRequest.url());
  if (!cookies.isEmpty()) {
    requestBuilder.header("Cookie", cookieHeader(cookies));
  }
  // 默认的是 okhttp3/3.0.1，即版本号
  if (userRequest.header("User-Agent") == null) {
    requestBuilder.header("User-Agent", Version.userAgent());
  }


2. 取到Response之后, 保存了cookie，条件判断之后解压了networkResponse.body()

    ......
    Response networkResponse = chain.proceed(requestBuilder.build());
    // 将cookie 保存到cookieJar
    HttpHeaders.receiveHeaders(cookieJar, userRequest.url(), networkResponse.headers());
    ......
    // 交给okio解压 gzip，注意之前是有判断响应头的 Content-Encoding是不是 gzip
    GzipSource responseBody = new GzipSource(networkResponse.body().source());







-----------------------------------------------------------------------------------------------------------------------------------------


304 表示服务器没有做修改，客户端直接使用上一次请求的缓存，

跟缓存有关的头字段，需要注意的是，有些字段是请求头的，有些是响应头的，但是是内容相同的，并且有关联：

Expires(响应头字段)
　　http/1.0中定义的header，是最基础的浏览器缓存处理，表示资源在一定时间内从浏览器的缓存中获取资源，不需要请求服务器获取资源，从而达到快速获取资源，缓解服务器压力的目的。
　　在response的header中的格式为：Expires: Thu, 01 Dec 1994 16:00:00 GMT （必须是GMT格式）

Last-modified(Reponse Header) 和 If-Modified-Since报头(Request Header)
　　望文知义，根据这个词条的直译应该是上次修改（时间），通过修改服务器端的文件后再请求，发现response的header中的Last-modified改变了
更新原理：
　　1、在浏览器首次请求某个资源时，服务器端返回的状态码是200 （ok），内容是你请求的资源，同时有一个Last-Modified的属性标记(Reponse Header)，标识此文件在服务期端最后被修改的时间，格式：Last-Modified:Tue, 24 Feb 2009 08:01:04 GMT
　　2、浏览器第二次请求该资源时，根据HTTP协议的规定，浏览器会向服务器传送If-Modified-Since报头(Request Header)，询问该文件是否在指定时间之后有被修改过，格式为：If-Modified-Since:Tue, 24 Feb 2009 08:01:04 GMT
　　3、如果服务器端的资源没有变化，则服务器返回304状态码（Not Modified），内容为空，这样就节省了传输数据量。当服务器端代码发生改变，则服务器返回200状态码（ok），内容为请求的资源，和第一次请求资源时类似。从而保证在资源没有修改时不向客户端重复发出资源，也保证当服务器有变化时，客户端能够及时得到最新的资源。

ETag（response header） 和 If-None-Match(Request Header)
1、当浏览器首次请求资源的时候，服务器会返回200的状态码（ok）,内容为请求的资源，同时response header会有一个ETag标记，该标记是服务器端根据容器（IIS或者Apache等等）中配置的ETag生成策略生成的一串唯一标识资源的字符串，ETag格式为 ETag:"856247206"
2、当浏览器第2次请求该资源时，浏览器会在传递给服务器的request中添加If-None-Match报头，询问服务器改文件在上次获取后是否修改了，报头格式：If-None-Match:"856246825"
3、服务器在获取到浏览器的请求后，会根据请求的资源查找对应的ETag，将当前服务器端指定资源对应的Etag与request中的If-None-Match进行对比，如果相同，说明资源没有修改，服务器返回304状态码（Not Modified），内容为空；如果对比发现不相同，则返回200状态码，同时将新的Etag添加到返回浏览器的response中。

max-age
 Cache-Control中设置资源在本地缓存时间的一个值，单位为：秒(s)，其他值还有private、no-cache、must-revalidate等
---------------
Last-Modified和Expires的区别
Last-Modified标识是发了http请求出去的，但在资源未修改时（304）返回的response内容为空
Expires不用发送HTTP请求，
通常而言，Last-Modified和Expires一起用，不会只用一个

Etag和Expires
和 Last-Modified和Expires的情况类似，需要Expires控制请求的频率，Etag在强制刷新时作为保障

----------------
Last-Modified和Etag区别
Last-Modified和Etag的功能差不多，实现有区别，一个是标识时间，一个是标识资源。

Last-Modified与ETag是可以一起使用的，服务器会优先验证ETag，一致的情况下，才会继续比对Last-Modified，
最后才决定是否返回304。现在我知道 因为last-modified只能精确到秒级 所以etag才比last-modified的优先级高
如果 ETag 和 Last-Modified 都有，则必须一次性都发给服务器，没有优先级。
最后，如果服务器输出了 ETag，没有必要再输出 Last-Modified。

总之，把Last-Modified 和ETags请求的http报头一起使用，过程如下: 
1. 客户端请求一个页面（A）。  
2. 服务器返回页面A，并在给A加上一个Last-Modified/ETag。  
3. 客户端展现该页面，并将页面连同Last-Modified/ETag一起缓存。  
4. 客户再次请求页面A，并将上次请求时服务器返回的Last-Modified/ETag一起传递给服务器。  
5. 服务器检查该Last-Modified或ETag，并判断出该页面自上次客户端请求之后还未被修改，直接返回响应304和一个空的响应体。

-----------------------------------------------------------------------------------------------------------------------------------------

Okhttp 缓存策略
只是分析了代码，加强了自身理解，具体还是看文档

0. 缓存入口：是否获取缓存是从getResponseWithInterceptorChain这个位于realcall中的方法来判断的，
  Response getResponseWithInterceptorChain() throws IOException {
    // Build a full stack of interceptors.
    List<Interceptor> interceptors = new ArrayList<>();
    interceptors.addAll(client.interceptors());
    interceptors.add(retryAndFollowUpInterceptor);
    interceptors.add(new BridgeInterceptor(client.cookieJar()));

    // 关键， 把 internalCache 给了进去
    interceptors.add(new CacheInterceptor(client.internalCache()));
    interceptors.add(new ConnectInterceptor(client));
    if (!forWebSocket) {
      interceptors.addAll(client.networkInterceptors());
    }
    interceptors.add(new CallServerInterceptor(forWebSocket));

    Interceptor.Chain chain = new RealInterceptorChain(
        interceptors, null, null, null, 0, originalRequest);
    return chain.proceed(originalRequest);
  }
}

client中的代码，判断了cache是否为空，再把 cache.internalCache传到CacheInterceptor中，下一篇会介绍cache类的实现，这里跳过
CacheInterceptor 中的InternalCache cache 就是 cacha类的 InternalCache
  InternalCache internalCache() {
    return cache != null ? cache.internalCache : internalCache;
  }


CacheInterceptor 的intercept方法 是关键，
流程 
1.从cache取出候选 Response，如果没有cache，那么cacheCandidate就是null
 Response cacheCandidate = cache != null
        ? cache.get(chain.request())
        : null;

2.接着把使用了cacheCandidate 传给 CacheStrategy（缓存策略类）
在 CacheStrategy中 判断请求头，响应过期等信息，判断缓存是否能用，如下代码
    CacheStrategy strategy = new CacheStrategy.Factory(now, chain.request(), cacheCandidate).get();
    Request networkRequest = strategy.networkRequest;
    Response cacheResponse = strategy.cacheResponse;

这里需要注意的是，通过 get()取出来的 strategy的 cacheResponse很有可能是null的，因为通过了策略判断之后，有可能 缓存的response已经不能用了
networkRequest也可能是空的，因为断网了

3.接下来调用closeQuietly关闭了不可用缓存，

4.判断了networkRequest 和 cacheResponse 是否为空，抛出504

5.判断了网络环境（networkRequest是否为空），返回了 cacheResponse （缓存的请求）

6.之前的取cache已经走完了，接下来是 通过请求网络来获取 response，
networkResponse = chain.proceed(networkRequest) 是 执行网络请求，获取response的语句
chain是RealInterceptorChain类

7.判断了cacheResponse是否为空 和 responseHTTP状态码（HTTP Status Code）是不是 304（状态未改变，可以使用缓存），
并返回response

8.重新封装 cacheResponse 和 networkResponse到一个新的 response

9.检查cache是否为空，把 新的response 存到 cache中



类：
1. CacheStrategy 缓存策略类
new CacheStrategy.Factory(now, chain.request(), cacheCandidate).get()
Factory()方法初始化了多个全局变量，例如：
sentRequestMillis，receivedResponseMillis， servedDate，servedDateString ，expires，lastModified，lastModifiedString ，etag，ageSeconds

get()方式调用getCandidate()真正的逻辑实现，getCandidate()方法中，会创建一个CacheStrategy对象并返回，
CacheStrategy(Request networkRequest, Response cacheResponse)的两个参数是否为空进过的层层判断

getCandidate()总体分为两部分：
上部分是判断了null值，https等等
      if (cacheResponse == null) {
        return new CacheStrategy(request, null);
      }
      if (request.isHttps() && cacheResponse.handshake() == null) {
        return new CacheStrategy(request, null);
      }
      if (!isCacheable(cacheResponse, request)) {
        return new CacheStrategy(request, null);
      }
      CacheControl requestCaching = request.cacheControl();
      if (requestCaching.noCache() || hasConditions(request)) {
        return new CacheStrategy(request, null);
      }
下半部分是判断了过期时间，并且返回一个缓存的response, 此处省略代码
      long ageMillis = cacheResponseAge();
      long freshMillis = computeFreshnessLifetime();
      ......
      if (!responseCaching.noCache() && ageMillis + minFreshMillis < freshMillis + maxStaleMillis) {
        ......
        return new CacheStrategy(null, builder.build());
      }
      ......
      String conditionName;
      String conditionValue;
      if (etag != null) {
      ......
      } else if (lastModified != null) {
      ......
      } else if (servedDate != null) {
      ......
      } else {
        return new CacheStrategy(request, null); // No condition! Make a regular request.
      }
      ......
      return new CacheStrategy(conditionalRequest, cacheResponse);



-----------------------------------------------------------------------------------------------------------------------------------------

序列化 (Serialization)是将对象的状态信息转换为可以存储或传输的形式的过程。一般将一个对象存储至一个储存媒介，例如档案或是记亿体缓冲等。在网络传输过程中，可以是字节或是XML等格式。而字节的或XML编码格式可以还原完全相等的对象。这个相反的过程又称为反序列化。

磁盘缓存 Cache类，
cache类可以直接设置给 OkHttpClient.Builder()，在cache类中可看到代码，只缓存get请求，不是get不缓存
查看其源码可见cache.internalCache 是Cache 类的内部类，但是需要注意的是Cache最终调用的是DiskLruCache 类，Cache 类只不过是它的封装，调用Cache 类来对本地缓存数据进行修改、删除等操作。

这里贴出cache类和DiskLruCache类中的 读取磁盘和写入磁盘代码（删除和更新就不贴了，只是最终操作不一样，流程差不多）

cache.internalCache中的（例如以下put） get,put,remove,update,trackConditionalCacheHit,trackResponse等方法都是调用cahce自己的相同方法名的方法，
    @Override public CacheRequest put(Response response) throws IOException {
      return Cache.this.put(response);
    }

cache的put方法返回response，
private CacheRequest put(Response response) {
    String requestMethod = response.request().method();
    if (HttpMethod.invalidatesCache(response.request().method())) {
      try {
        remove(response.request());
      } catch (IOException ignored) {
      }
      return null;
    }
    if (!requestMethod.equals("GET")) {
      return null;
    }

    if (HttpHeaders.hasVaryAll(response)) {
      return null;
    }
    Entry entry = new Entry(response);
    DiskLruCache.Editor editor = null;
    try {
      editor = cache.edit(urlToKey(response.request()));
      if (editor == null) {
        return null;
      }
      entry.writeTo(editor);
      return new CacheRequestImpl(editor);
    } catch (IOException e) {
      abortQuietly(editor);
      return null;
    }
  }

Cache类的put 方法最终调用的还是DiskLruCache类，即它才是操作本地缓存的底层对象，此方法就是往本地文件中写入缓存数据，首先if判断当前的请求方式是否支持，如果支持的话先移除对应请求的数据，避免重复；然后通过DiskLruCache类获取可书写Editor 对象，然后会根据当前请求的URL做一个MD5的加密，生成的本地缓存名字就是一串字符，如下图所示，获取此文件后，调用Entry的writeTo 方法写入数据即可结束。此方法源码如下：
public void writeTo(DiskLruCache.Editor editor) throws IOException {
      BufferedSink sink = Okio.buffer(editor.newSink(ENTRY_METADATA));

      sink.writeUtf8(url)
          .writeByte('\n');
      sink.writeUtf8(requestMethod)
          .writeByte('\n');
      sink.writeDecimalLong(varyHeaders.size())
          .writeByte('\n');
      for (int i = 0, size = varyHeaders.size(); i < size; i++) {
        sink.writeUtf8(varyHeaders.name(i))
            .writeUtf8(": ")
            .writeUtf8(varyHeaders.value(i))
            .writeByte('\n');
      }

      sink.writeUtf8(new StatusLine(protocol, code, message).toString())
          .writeByte('\n');
      sink.writeDecimalLong(responseHeaders.size() + 2)
          .writeByte('\n');
      for (int i = 0, size = respon
      ......
      }



最后，去查看okhttpclient中设置的缓存目录，可以看到用MD5加密文件名出来的文件
联系上一篇，可以在 CacheInterceptor中看到 对InternalCache cache 的各种操作

-----------------------------------------------------------------------------------------------------------------------------------------
okhttp连接池 复用机制

keep-alive 就是浏览器和服务端之间保持长连接，这个连接是可以复用的。在HTTP1.1中是默认开启的。
Connection是response中的头字段，他有两个值，其中之一就是keep-alive

例如：浏览器加载一个HTML网页，HTML中可能需要加载数十个资源，典型场景下这些资源中大部分来自同一个站点。
按照HTTP1.0的做法，这需要建立数十个TCP连接，每个连接负责一个资源请求。创建一个TCP连接需要3次握手，而释放连接则需要2次或4次握手。
重复的创建和释放连接极大地影响了网络效率，同时也增加了系统开销。

keep-alive在传输数据后仍然保持连接，当客户端需要再次获取数据时，直接使用刚刚空闲下来的连接而 不需要再次握手（这个很重要）
在现代浏览器中，一般同时开启6～8个keepalive connections的socket连接，并保持一定的链路生命，当不需要时再关闭；
而在服务器中，一般是由软件根据负载情况(比如FD最大值、Socket内存、超时时间、栈内存、栈数量等)决定是否主动关闭。

缺点：如果存在大量空闲的keepalive connections（我们可以称作僵尸连接或者泄漏连接），其它客户端们的正常连接速度也会受到影响

---------------------------

怎么去取到一个已经存在的可靠连接？ 
RealConnection中的isEligible(address, route)方法判断连接符合,
判断代理方式必须是DIRECT（直连），判断此次连接的主机名是否与遍历中的主机名相同，验证证书

路由选择起到什么样的作用？
第二次在连接池中查找可用连接会加上代理参数

怎么保持的keep-alive？
tcp连接tcp释放 (socket 不调用close就是 keep-alive)


个人总结：
1.连接池产生作用是在ConnectInterceptor这个拦截器中，ConnectInterceptor只做了一件事情，就是 拿到一个HttpCodec和RealConnection
（这个Connection在连接池内有对应连接连接时，是复用的；在没有时，则是一个重新创建的对象）传递给realChain.proceed
2.在ConnectInterceptor 的intercept中调用 streamAllocation.newStream，newStream使用了 连接池机制
3.连接池ConnectionPool 复用connection（RealConnection封装了socket，其实就是复用socket），节省了创建对象和网络TCP连接 所消耗的时间和资源
4.为了避免复用socket带来的内存泄漏，空闲连接没有被使用等等问题，连接池维持一套自动创建和销毁 connection的机制（这套机制就是连接池的核心）
  (1). streamAllocation.newStream层层调用下去，最终调用findConnection，
       findConnection在连接池查找两次connection（Internal.instance.get() -> ConnectionPool.get()），
       找到后返回connection复用，没找到则new新的RealConnection
  (2). ConnectionPool.get() 和 new RealConnection，都会调用acquire方法，使得RealConnection的 弱引用列表 加一
  (3). 如果是复用直接返回connection，如果是new则把result，
       put进connectionPool中（Internal.instance.put），最终调用的是ConnectionPool的put方法
  (4). Put方法会用线程池去执行executor.execute(cleanupRunnable)，这儿调用了cleanup方法来清理不符合要求的connection，
      （弱引用列表为零的connection不一定会被清理，清理规则是：空闲连接数量大于5，存在时间超过5分钟等等）
       清理方法分两步，先是把connection从ConnectionPool中移除，接着再关闭Connection中的socket
  (5). RealConnection中的弱引用列表 List<Reference<StreamAllocation>> allocations，(加一就是List.add(),减一就是List.remove())
       加一是StreamAllocation中 RealConnection在被复用或者被创建时，
       减一是StreamAllocation中 的release(connection)。release的调用者deallocate方法 被多处调用，情况复杂，
       大体调用情况是 外部的拦截器拿到了response之后，调用streamAllocation.release()主动释放了弱引用，
       或者在获取response的过程中出错，调用streamAllocation.streamFailed主动释放了弱引用，
       或者连接池中重复了connection，调用Internal.instance.deduplicate主动释放了弱引用，
       还有其他许多情况也会主动释放弱引用。


---------------------------
这是 okhttpClient中的代码，很多地方都会使用到Internal.instance，
特别是用到连接池的几个方法：connectionBecameIdle， get， put等等
Internal.instance = new Internal()

---------------------------

1. 在 ConnectInterceptor的intercept方法中，一步一步往下走，最终步骤是取得到一个RealConnection（这个类会调用socket的connect方法来进行tcp连接）用来拿response
关键代码：创建一个HttpCodec然后传下去（交给最后一个拦截器：CallServerInterceptor）：
streamAllocation.newStream(client, doExtensiveHealthChecks) -> findHealthyConnection -> findConnection


2. get是ConnectionPool中最为重要的方法，StreamAllocation在其findConnection方法内部通过调用get方法为其找到stream找到合适的连接，如果没有则新建一个连接。首先来看下findConnection的逻辑：
查看当前streamAllocation是否有之前已经分配过的连接，有则直接使用
从连接池中查找可复用的连接，有则返回该连接
配置路由，配置后再次从连接池中查找是否有可复用连接，有则直接返回
新建一个连接，并修改其StreamAllocation标记计数，将其放入连接池中
查看连接池是否有重复的多路复用连接，有则清除


private RealConnection findConnection(int connectTimeout, int readTimeout, int writeTimeout,
                                        boolean connectionRetryEnabled) throws IOException {
    Route selectedRoute;
    synchronized (connectionPool) {
      if (released) throw new IllegalStateException("released");
      if (codec != null) throw new IllegalStateException("codec != null");
      if (canceled) throw new IOException("Canceled");

      // 一个StreamAllocation刻画的是一个Call的数据流动，一个Call可能存在多次请求(重定向，Authenticate等)，所以当发生类似重定向等事件时优先使用原有的连接
      RealConnection allocatedConnection = this.connection;
      if (allocatedConnection != null && !allocatedConnection.noNewStreams) {
        return allocatedConnection;
      }

      // 试图从连接池中找到可复用的连接
      // 这里的get很绕，最终调用的是 connectionPool的get方法，而这个方法里面，又会对 this(streamAllocation), 的connection对象赋值，
      // 所以接下来才可以直接判断connection
      Internal.instance.get(connectionPool, address, this, null);
      if (connection != null) {
        return connection;
      }

      selectedRoute = route;
    }

    // 获取路由配置，所谓路由其实就是代理，ip地址等参数的一个组合
    if (selectedRoute == null) {
      selectedRoute = routeSelector.next();
    }

    RealConnection result;
    synchronized (connectionPool) {
      if (canceled) throw new IOException("Canceled");

      //拿到路由后可以尝试重新从连接池中获取连接，这里主要针对http2协议下清除域名碎片机制
      Internal.instance.get(connectionPool, address, this, selectedRoute);
      if (connection != null) return connection;

      //新建连接
      route = selectedRoute;
      refusedStreamCount = 0;
      result = new RealConnection(connectionPool, selectedRoute);
      //修改result连接stream计数，方便connection标记清理
      acquire(result);
    }

    // Do TCP + TLS handshakes. This is a blocking operation.
    result.connect(connectTimeout, readTimeout, writeTimeout, connectionRetryEnabled);
    routeDatabase().connected(result.route());

    Socket socket = null;
    synchronized (connectionPool) {
      // 将新建的连接放入到连接池中
      Internal.instance.put(connectionPool, result);

      // 如果同时存在多个连向同一个地址的多路复用连接，则关闭多余连接，只保留一个
      if (result.isMultiplexed()) {
        socket = Internal.instance.deduplicate(connectionPool, address, this);
        result = connection;
      }
    }
    closeQuietly(socket);

    return result;
  }



Internal.instance实在okhttpclient中创建实例的，实例的get方法就是直接调用的 connectionPool 的get方法
有关于connectionPool的逻辑，看一下篇


3. 调用了Internal.instance.get会调用ConnectionPool的get方法，调用StreamAllocation的acquire进行计数加1，
新创建出来的connect也会调用acquire加一计数


---------------------------

Okhttp支持5个并发KeepAlive，默认链路生命为5分钟(链路空闲后，保持存活的时间)

*Connection: （其实是RealConnection，Connection只是一个接口，一个RealConnection对应一个socket）
对jdk的socket物理连接的包装，它内部有List<WeakReference<StreamAllocation>>的引用

ConnectionPool: Socket连接池，对连接缓存进行回收与管理，与CommonPool有类似的设计
Call: 对http的请求封装，属于程序员能够接触的上层高级代码
StreamAllocation: 表示RealConnection被上层高级代码的引用次数
Deque: Deque也就是双端队列，双端队列同时具有队列和栈性质，经常在缓存中被使用，这个是java基础

*在socket连接中，也就是RealConnection中，本质是封装好的流操作，除非手动close掉连接，基本不会被GC掉，非常容易引发内存泄露。

*小结：在okhttp中，在高层代码的调用中，使用了类似于引用计数的方式跟踪Socket流的调用，这里的计数对象是StreamAllocation，它被反复执行acquire方法（加一计数）与release方法(减一计数)，这两个函数其实是在改变RealConnection中的List<WeakReference<StreamAllocation>>大小。List中Allocation的数量也就是物理socket被引用的计数（Refference Count），如果计数为0的话，说明此连接没有被使用，是空闲的，需要通过下文的算法实现回收；如果上层代码仍然引用，就不需要关闭连接。
（ StreamAllocation 中的 acquire方法是创建一个StreamAllocationReference弱引用并把this传给这个弱引用，接着把StreamAllocationReference对象add进
List<WeakReference<StreamAllocation>>列表中，
release方法是遍历List<WeakReference<StreamAllocation>>列表查找和this相同的对象并remove）

引用计数法：给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用。它不能处理循环引用的问题。

代码分析：
okhttpclient的build方法，创建ConnectionPool，当然，也可以在builder中将自己创建的ConnectionPool传入
      connectionPool = new ConnectionPool();

连接池内部维护了一个叫做OkHttp ConnectionPool的ThreadPool，专门用来淘汰末位的socket，当满足以下条件时，就会进行末位淘汰，非常像GC
1. 并发socket空闲连接超过5个
2. 某个socket的keepalive时间大于5分钟
源码：  private static final Executor executor = new ThreadPoolExecutor(0 /* corePoolSize */,
      Integer.MAX_VALUE, 60L, TimeUnit.SECONDS,
      new SynchronousQueue<Runnable>(), Util.threadFactory("OkHttp ConnectionPool", true));

维护着一个Deque<Connection>，提供get/put/remove等数据结构的功能
  private final Deque<RealConnection> connections = new ArrayDeque<>();

维护着一个RouteDatabase，它用来记录连接失败的Route的黑名单，当连接失败的时候就会把失败的线路加进去（本文不讨论）
  final RouteDatabase routeDatabase = new RouteDatabase();

在连接池ConnectionPool中，提供如下的操作，这里可以看成是对deque的一个简单的包装
//从连接池中获取
get
//放入连接池
put
//线程变成空闲，并调用清理线程池
connectionBecameIdle
//关闭所有连接
evictAll

例如 get方法，遍历了 connections，并返回其中一个满足条件的RealConnection，RealConnection中有一个socket对象，
  @Nullable RealConnection get(Address address, StreamAllocation streamAllocation, Route route) {
    assert (Thread.holdsLock(this));
    for (RealConnection connection : connections) {
      if (connection.isEligible(address, route)) {
        streamAllocation.acquire(connection);
        return connection;
      }
    }
    return null;
  }

随着上述操作被更高级的对象调用，RealConnection中的StreamAllocation被不断的aquire与release，
也就是List<WeakReference<StreamAllocation>>的大小将时刻变化


-----------------------------

自动回收机制：

当用户socket连接成功，向连接池中put新的socket时，回收函数会被主动调用，线程池就会执行cleanupRunnable，如下
//Socket清理的Runnable，每当put操作时，就会被主动调用
//注意put操作是在网络线程， executor 是 ThreadPoolExecutor对象
      executor.execute(cleanupRunnable);

//而Socket清理是在`OkHttp ConnectionPool`线程池中调用
  private final Runnable cleanupRunnable = new Runnable() {
    @Override public void run() {
      while (true) {
        long waitNanos = cleanup(System.nanoTime());
        if (waitNanos == -1) return;
        if (waitNanos > 0) {
          long waitMillis = waitNanos / 1000000L;
          waitNanos -= (waitMillis * 1000000L);
          synchronized (ConnectionPool.this) {
            try {
              ConnectionPool.this.wait(waitMillis, (int) waitNanos);
            } catch (InterruptedException ignored) {
            }
          }
        }
      }
    }
  };
这段死循环实际上是一个阻塞的清理任务，首先进行清理(clean)，并返回下次需要清理的间隔时间，
然后调用wait(timeout)进行等待以释放锁与时间片，当等待时间到了后，再次进行清理，并返回下次要清理的间隔时间

Connect变得闲置时调用了 connectionBecameIdle方法，里面调用了 notifyAll() ，唤醒通知：


Cleanup:
cleanup使用了类似于GC的标记-清除算法，也就是首先标记出最不活跃的连接(我们可以叫做泄漏连接，或者空闲连接)，接着进行清除，流程如下:
 long cleanup(long now) {
    int inUseConnectionCount = 0;
    int idleConnectionCount = 0;
    RealConnection longestIdleConnection = null;
    long longestIdleDurationNs = Long.MIN_VALUE;

    // Find either a connection to evict, or the time that the next eviction is due.
    synchronized (this) {
      // 迭代器遍历
      for (Iterator<RealConnection> i = connections.iterator(); i.hasNext(); ) {
        RealConnection connection = i.next();

        // If the connection is in use, keep searching.
        if (pruneAndGetAllocationCount(connection, now) > 0) {
          // 如果是被使用的，就是活跃的，跳过这个connection，被使用数量加一
          inUseConnectionCount++;
          continue;
        }

        // 如果上面的判断失败，就是不活跃的, 闲置数量加一
        idleConnectionCount++;

        // If the connection is ready to be evicted, we're done.
        long idleDurationNs = now - connection.idleAtNanos;
        // 遍历找出最不活跃的连接,选择排序法
        if (idleDurationNs > longestIdleDurationNs) {
          longestIdleDurationNs = idleDurationNs;
          longestIdleConnection = connection;
        }
      }



    if (longestIdleDurationNs >= this.keepAliveDurationNs
        || idleConnectionCount > this.maxIdleConnections) {
      //如果(`空闲socket连接超过5个`
      //且`keepalive时间大于5分钟`)
      //就将此泄漏连接从`Deque`中移除
      connections.remove(longestIdleConnection);
    } else if (idleConnectionCount > 0) {
      //返回此连接即将到期的时间，供下次清理
      //这里依据是在上文`connectionBecameIdle`中设定的计时
      return keepAliveDurationNs - longestIdleDurationNs;
    } else if (inUseConnectionCount > 0) {
      //全部都是活跃的连接，5分钟后再次清理
      return keepAliveDurationNs;
    } else {
      //没有任何连接，跳出循环
      cleanupRunning = false;
      return -1;
    }
  }

  //关闭连接，返回`0`，也就是立刻再次清理
  closeQuietly(longestIdleConnection.socket());
  return 0;
  }


1. 遍历Deque中所有的RealConnection，标记泄漏的连接
2. 如果被标记的连接满足(空闲socket连接超过5个&&keepalive时间大于5分钟)，就将此连接从Deque中移除，并关闭连接，返回0，也就是将要执行wait(0)，提醒立刻再次扫描
3. 如果(目前还可以塞得下5个连接，但是有可能泄漏的连接(即空闲时间即将达到5分钟))，就返回此连接即将到期的剩余时间，供下次清理
4. 如果(全部都是活跃的连接)，就返回默认的keep-alive时间，也就是5分钟后再执行清理
5. 如果(没有任何连接)，就返回-1,跳出清理的死循环


需要注意的是pruneAndGetAllocationCount方法，这个方法标记并找到最不活跃的连接呢，这里使用了pruneAndGetAllocationCount的方法，它主要依据弱引用是否为null而判断这个连接是否泄漏

//类似于引用计数法，如果引用全部为空，返回立刻清理
private int pruneAndGetAllocationCount(RealConnection connection, long now) {
  //虚引用列表
  List<Reference<StreamAllocation>> references = connection.allocations;
  //遍历弱引用列表
  for (int i = 0; i < references.size(); ) {
    Reference<StreamAllocation> reference = references.get(i);
    //如果正在被使用，跳过，接着循环
    //是否置空是在上文`connectionBecameIdle`的`release`控制的
    if (reference.get() != null) {
      //非常明显的引用计数
      i++;
      continue;
    }

    //否则移除引用
    references.remove(i);
    connection.noNewStreams = true;

    //如果所有分配的流均没了，标记为已经距离现在空闲了5分钟
    if (references.isEmpty()) {
      connection.idleAtNanos = now - keepAliveDurationNs;
      return 0;
    }
  }
    
  return references.size();
}
遍历RealConnection连接中的StreamAllocationList，它维护着一个弱引用列表
查看此StreamAllocation是否为空(它是在线程池的put/remove手动控制的)，如果为空，说明已经没有代码引用这个对象了，需要在List中删除
遍历结束，如果List中维护的StreamAllocation删空了，就返回0，表示这个连接已经没有代码引用了，是泄漏的连接;否则返回非0的值，表示这个仍然被引用，是活跃的连接。

-----------------------------------------------------------------------------------------------------------------------------------------

最后一个拦截器：CallServerInterceptor，负责发出网络请求

不过其实在这个拦截器之前，还可以自定义networkInterceptors。
在Okhttp的拦截器链条里面有两个地方可以自定义拦截：
最开始的时候（Interceptors）：对发出去的请求做最初的处理，以及在拿到最后Reponse时候做最后的处理；
最后数据交换前（networkInterceptors）：对发出去的请求做最后的处理，以及在拿到结果时候做最初的处理。
我们可以自定义拦截器，去处理我们需要做的事情。

我们知道Http发送网络请求前两个步骤是： 
1、建立TCP链接 
2、客户端向web服务器发送请求命令：形如GET /login/login.jsp?username=android&password=123 HTTP/1.1的信息
在Okhttp中ConnectInterceptor负责第一个步骤，
第二个步骤是是httpCodec对象的writeRequestHeaders方法。(该方法在CallserverInterceptor的intercept里面调用)

代码
 public Response intercept(Chain chain) throws IOException {
    // 省略部分代码
    // 获取HttpCodec 
    HttpCodec httpCodec = realChain.httpStream();
    // 省略部分代码
    Request request = realChain.request();
    //向服务器发送请求
    httpCodec.writeRequestHeaders(request);

    Response.Builder responseBuilder = null;
    // 检测是否有请求body
    if (HttpMethod.permitsRequestBody(request.method()) && request.body() != null) {

      if ("100-continue".equalsIgnoreCase(request.header("Expect"))) {
        httpCodec.flushRequest();
        //构建responseBuilder对象
        responseBuilder = httpCodec.readResponseHeaders(true);
      }

       //如果服务器允许发送请求body发送
      if (responseBuilder == null) {
        Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength());
        BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
        request.body().writeTo(bufferedRequestBody);
        bufferedRequestBody.close();
      } else if (!connection.isMultiplexed()) {
         //省略部分代码
      }
    }

    //结束请求
    httpCodec.finishRequest();

    //构建请求buidder对象
    if (responseBuilder == null) {
      responseBuilder = httpCodec.readResponseHeaders(false);
    }

    Response response = responseBuilder
        .request(request)
        .handshake(streamAllocation.connection().handshake())
        .sentRequestAtMillis(sentRequestMillis)
        .receivedResponseAtMillis(System.currentTimeMillis())
        .build();

    int code = response.code();
    if (forWebSocket && code == 101) {
      //省略部分代码
    } else {
      response = response.newBuilder()
          .body(httpCodec.openResponseBody(response))
          .build();
    }

    //省略部分代码

    return response;
  }


1. 该方法首先是获取了httpCodec对象，该对象的主要功能就是对不同http协议（http1.1和http/2）的请求和响应做处理，
该对象的初始化是在ConnectIntercepor的intercept里面：
 HttpCodec httpCodec = streamAllocation.newStream(client, doExtensiveHealthChecks);


2. 最终httpCodec的初始化又是在StreamAllocation的newStream方法
  public HttpCodec newStream(OkHttpClient client, boolean doExtensiveHealthChecks) {
     //：省略部分代码;
      HttpCodec resultCodec = resultConnection.newCodec(client, this);

  }
    public HttpCodec newCodec(
      OkHttpClient client, StreamAllocation streamAllocation) throws SocketException {
    if (http2Connection != null) {
      return new Http2Codec(client, streamAllocation, http2Connection);
    } else {
      //设置socket的读超时时间
      socket.setSoTimeout(client.readTimeoutMillis());
      //InputStream的超时时间
      source.timeout().timeout(client.readTimeoutMillis(), MILLISECONDS);
      //OutputStream的超时时间
      sink.timeout().timeout(client.writeTimeoutMillis(), MILLISECONDS);
      return new Http1Codec(client, streamAllocation, source, sink);
    }
  }

3. 可以发现Okhttp的提供了两种HttpCodec的实现类，如果使用了http2协议则返回Http2Codec，否则返回Http1Codec！并且设置了超时时间,本篇就以Http1Codec对象来进行分析。

4. 调用了
public void writeRequestHeaders(Request request) throws IOException {
  //RequestLine.get用来构建形如GET xx HTTP/1.1的字符串
    String requestLine = RequestLine.get(
        request, streamAllocation.connection().route().proxy().type());
  //像服务器发送请求，形如GET xxx HTTP/1.1
    writeRequest(request.headers(), requestLine);
  }  

5. 可以发现Okhttp通过OkIO的Sink对象（该对象可以看做Socket的OutputStream对象）的writeRequest来向服务器发送请求的。
public void writeRequest(Headers headers, String requestLine) throws IOException {
    if (state != STATE_IDLE) throw new IllegalStateException("state: " + state);
    sink.writeUtf8(requestLine).writeUtf8("\r\n");
    for (int i = 0, size = headers.size(); i < size; i++) {
      sink.writeUtf8(headers.name(i))
          .writeUtf8(": ")
          .writeUtf8(headers.value(i))
          .writeUtf8("\r\n");
    }
    sink.writeUtf8("\r\n");
    state = STATE_OPEN_REQUEST_BODY;
  }


6. 我们知道HTTP支持post,delete,get,put等方法，而post，put等方法是需要请求体的（在Okhttp中用RequestBody来表示）。所以接着writeRequestHeaders之后Okhttp对请求体也做了响应的处理：

    //如果当前request请求需要请求体
    if (HttpMethod.permitsRequestBody(request.method()) && request.body() != null) {

      //询问Server使用愿意接受数据 
      if ("100-continue".equalsIgnoreCase(request.header("Expect"))) {
        httpCodec.flushRequest();
        //构建responseBuilder对象
        responseBuilder = httpCodec.readResponseHeaders(true);
      }

       //向服务器发送请求体
      if (responseBuilder == null) {

         //发送请求体，详见下文描述
      } else if (!connection.isMultiplexed()) {
        //省略部分代码
      }
    }
通过上面的代码可以发现Okhttp对Expect头部也做了支持，上面代码对客户端是否使用该头部做了判断，“100 continue”的作用就是：客户端有一个RequestBody(比如post或者PUT方法)要发给服务器，但是客户端希望在发送RequestBody之前查看服务器是否接受这个body,服务端在接受到这个请求后必须进行响应。客户端通过Expect首部来发送这个消息，当然如果客户端没有实体发送，就不应该发送100 continue 首部，因为这样会使服务器误以为客户端有body要发送。所以okhttp在发送这个之前要permitsRequestBody来判断。当然常规的get请求是不会走这个方法的。

7.   //构建请求体对象组成的输入流
  Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength());
        BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
        //发送请求体
        request.body().writeTo(bufferedRequestBody);

8.   //构建请求体对象组成的输入流
  Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength());
        BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
        //发送请求体
        request.body().writeTo(bufferedRequestBody);


9. 客户端向服务端发送请求的部分已经讲解完毕，下面就剩下读取服务器响应然后构建Response对象了
//构建请求buider对象
    if (responseBuilder == null) {
      responseBuilder = httpCodec.readResponseHeaders(false);
    }

    //构建response对象
    Response response = responseBuilder
        .request(request)
        .handshake(streamAllocation.connection().handshake())
        .sentRequestAtMillis(sentRequestMillis)
        .receivedResponseAtMillis(System.currentTimeMillis())
        .build();

    int code = response.code();
    if (forWebSocket && code == 101) {
      //返回空的即无效的响应
      response = response.newBuilder()
          .body(Util.EMPTY_RESPONSE)
          .build();
    } else {
      response = response.newBuilder()
          .body(httpCodec.openResponseBody(response))
          .build();
    }

上面的代码做了三个工作： 
（1）、调用HttpCodec的readResponseHeaders方法读取服务器响应的数据，构建Response.Builder对象（以Hppt1Codec分析）：

 public Response.Builder readResponseHeaders(boolean expectContinue) throws IOException {
      //省略部分代码
      //读取服务器
      StatusLine statusLine = StatusLine.parse(source.readUtf8LineStrict());

      Response.Builder responseBuilder = new Response.Builder()
          .protocol(statusLine.protocol)//http协议版本
          .code(statusLine.code)//http响应状态码
          //http的message :like "OK" or "Not Modified"
          .message(statusLine.message)
          .headers(readHeaders());//http响应header
      //省略部分代码

      return responseBuilder;

  }

（2）、通过ResopnseBuilder对象来最终创建Response对象，并返回。 
最关键的是服务器的响应体或者响应内容是如果传给Response的，代码如下：

  response = response.newBuilder()
          .body(httpCodec.openResponseBody(response))

Response的body通过httpCodec对象的openResponseBody传进来,进入Http1Codec对象的openResponseBody方法看看都做了些神马：

public ResponseBody openResponseBody(Response response) throws IOException {
    Source source = getTransferStream(response);
    return new RealResponseBody(response.headers(), Okio.buffer(source));
  }

很简单，openResponseBody将Socket的输入流InputStream对象交给OkIo的Source对象(在本篇博文中只需简单的将Sink作为Socket的输入流，Source作为Socket的输入流看待即可，详细的分析可参考OKIO），然后封装成RealResponseBody（该类是ResponseBody的子类）作为Response的body.

那么我们怎么通过这个body来获取服务器发送过来的字符串呢？ResponseBody提供了string()方法：

  public final String string() throws IOException {
    BufferedSource source = source();
    try {
      Charset charset = Util.bomAwareCharset(source, charset());
      //InputStream 读取数据
      return source.readString(charset);
    } finally {
      Util.closeQuietly(source);
    }
  }

string(）方法也很简单，就是通过一些处理然后让调用source.readString来读取服务器的数据。需要注意的是该方法最后调用closeQuietly来关闭了当前请求的InputStream输入流，所以string()方法只能调用一次,再次调用的话会报错，毕竟输入流已经关闭了，你还怎么读取数据呢？


总结：
到此为止CallServerInterceptor简单分析完毕，总结下主要做了如下工作： 
（1）获取HttpCodec对象，对<=Http1.1之前的或者http/2不同协议的http请求处理。 
（2）发送http请求数据，构建Resposne.Builder对象，然后构建Response并返回。




其他小结：
1. streamAllocation被创建于RetryAndFollowUpInterceptor，从RetryAndFollowUpInterceptor开始， streamAllocation在RealInterceptorChain中就不再是null，每一次走Interceptor.Intercept 都会被传递给下一个RealInterceptorChain
这个类是用于 连接池的复用计数的，具体看连接池篇

2. HttpCodec 的创建
ConnectInterceptor中 -> streamAllocation.newStream，
StreamAllocation中 -> resultConnection.newCodec 这里判断是支持http1或http2来返回
注释翻译：
/** Flush the request to the underlying socket. */
/** 将请求刷新到底层套接字。*/
HttpCodec.flushRequest

/** Flush the request to the underlying socket and signal no more bytes will be transmitted. */
/** 将请求刷新到底层套接字，并且不会传输更多的字节。*/
HttpCodec.finishRequest

3. sink和source 位于 RealConnection 中，是这么创建的
source = Okio.buffer(Okio.source(socket));
sink = Okio.buffer(Okio.sink(socket));
sink封装了socket的OutputStream输出流
source封装了socket的InputStream输出流
sink和source只是接口，但他们都在Okio.java中被实现了，
他们的flush() close() 等方法都是拿 socket 的输入流和输出流去操作的
具体查看Okio.java

4. http 100-continue 用于客户端在发送POST数据给服务器前，征询服务器情况，看服务器是否处理POST的数据，
如果不处理，客户端则不上传POST数据，如果处理，则POST上传数据。在现实应用中，通过在POST大数据时，才会使用100-continue协议。
客户端策略:
　　　　1）如果客户端有POST数据要上传，可以考虑使用100-continue协议。加入头{"Expect":"100-continue"}
　　　　2）如果没有POST数据，不能使用100-continue协议，因为这会让服务端造成误解。
　　　　3）并不是所有的Server都会正确实现100-continue协议，如果Client发送Expect:100-continue消息后，在timeout时间内无响应，Client需要立马上传POST数据。
　　　　4）有些Server会错误实现100-continue协议，在不需要此协议时返回100，此时客户端应该忽略。
服务端策略:
　　　　1）正确情况下，收到请求后，返回100或错误码。
　　　　2）如果在发送100-continue前收到了POST数据（客户端提前发送POST数据），则不发送100响应码(略去)。


-----------------------------------------------------------------------------------------------------------------------------------------

okhttp代理和路由

??
-> 怎么选择路由，怎么知道网络地址可用
普通的网络请求会不会过路由选择器

HTTP请求的整体处理过程大体可以理解为，

建立TCP连接。
如果是HTTPS的话，完成SSL/TLS的协商。
发送请求。
获取响应。
结束请求，关闭连接。

然而，当为系统设置了代理的时候，整个数据流都会经过代理服务器。
代理分为两种类型，一种是SOCKS代理，另一种是HTTP代理。对于SOCKS代理，在HTTP的场景下，代理服务器完成TCP数据包的转发工作。而HTTP代理服务器，在转发数据之外，还会解析HTTP的请求及响应，并根据请求及响应的内容做一些处理。

这里看一下OkHttp中对代理的处理。
(路由选择和代理在StreamAllocation中使用)

1. 这个是java底层代码，可以看出，代理有三种形势，1.直连（无代理或者代理缺失） 2.http代理  3. SOCKS代理
    java.net.Proxy
    public enum Type {
        /**
         * Represents a direct connection, or the absence of a proxy.
         */
        DIRECT,
        /**
         * Represents proxy for high level protocols such as HTTP or FTP.
         */
        HTTP,
        /**
         * Represents a SOCKS (V4 or V5) proxy.
         */
        SOCKS
    };


2. okHttpClient可以直接设置.proxy().proxySelector().proxyAuthenticator()
  等等代理

中抽象出Route来描述网络数据包的传输路径，最主要还是要描述直接与其建立TCP连接的目标端点。
public final class Route {
  final Address address;
  final Proxy proxy;
  final InetSocketAddress inetSocketAddress;

  public Route(Address address, Proxy proxy, InetSocketAddress inetSocketAddress) {
    if (address == null) {
      throw new NullPointerException("address == null");
    }
    if (proxy == null) {
      throw new NullPointerException("proxy == null");
    }
    if (inetSocketAddress == null) {
      throw new NullPointerException("inetSocketAddress == null");
    }
    this.address = address;
    this.proxy = proxy;
    this.inetSocketAddress = inetSocketAddress;
  }
  ......
}
主要通过 代理服务器的信息proxy ，及 连接的目标地址 描述路由。 连接的目标地址inetSocketAddress 根据代理类型的不同而有着不同的含义，这主要是由不同代理协议的差异而造成的。对于无需代理的情况， 连接的目标地址inetSocketAddress 中包含HTTP服务器经过了DNS域名解析的IP地址及协议端口号；对于SOCKS代理，其中包含HTTP服务器的域名及协议端口号；对于HTTP代理，其中则包含代理服务器经过域名解析的IP地址及端口号。


3. RouteSelector 工作于StreamAllocation

* HTTP请求处理过程中所需的TCP连接建立过程，主要是找到一个Route，然后依据代理协议的规则与特定目标建立TCP连接。对于无代理的情况，是与HTTP服务器建立TCP连接；对于SOCKS代理及HTTP代理，是与代理服务器建立TCP连接，虽然都是与代理服务器建立TCP连接，而SOCKS代理协议与HTTP代理协议做这个动作的方式又会有一定的区别。

借助于域名解析做负载均衡已经是网络中非常常见的手法了，因而，常常会有相同域名对应不同IP地址的情况。同时相同系统也可以设置多个代理，这使Route的选择变得复杂起来。

在OkHttp中，对Route连接失败有一定的错误处理机制。OkHttp会逐个尝试找到的Route建立TCP连接，直到找到可用的那一个。这同样要求，对Route信息有良好的管理。

OkHttp3借助于 RouteSelector 类管理所有的路由信息，并帮助选择路由。 RouteSelector 主要完成3件事：

（1）收集所有可用的路由。
public final class RouteSelector {
  private final Address address;
  private final RouteDatabase routeDatabase;

  /* The most recently attempted route. */
  private Proxy lastProxy;
  private InetSocketAddress lastInetSocketAddress;

  /* State for negotiating the next proxy to use. */
  private List<Proxy> proxies = Collections.emptyList();
  private int nextProxyIndex;

  /* State for negotiating the next socket address to use. */
  private List<InetSocketAddress> inetSocketAddresses = Collections.emptyList();
  private int nextInetSocketAddressIndex;

  /* State for negotiating failed routes */
  private final List<Route> postponedRoutes = new ArrayList<>();

  public RouteSelector(Address address, RouteDatabase routeDatabase) {
    this.address = address;
    this.routeDatabase = routeDatabase;

    resetNextProxy(address.url(), address.proxy());
  }
. . . . . .

  /** Prepares the proxy servers to try. */
  private void resetNextProxy(HttpUrl url, Proxy proxy) {
    if (proxy != null) {
      // If the user specifies a proxy, try that and only that.
      proxies = Collections.singletonList(proxy);
    } else {
      // Try each of the ProxySelector choices until one connection succeeds. If none succeed
      // then we'll try a direct connection below.
      proxies = new ArrayList<>();
      List<Proxy> selectedProxies = address.proxySelector().select(url.uri());
      if (selectedProxies != null) proxies.addAll(selectedProxies);
      // Finally try a direct connection. We only try it once!
      proxies.removeAll(Collections.singleton(Proxy.NO_PROXY));
      proxies.add(Proxy.NO_PROXY);
    }
    nextProxyIndex = 0;
  }
收集路由分为两个步骤：第一步收集所有的代理；第二步则是收集特定代理服务器选择情况下的所有 连接的目标地址 。
收集代理的过程如上面的这段代码所示，有两种方式，一是外部通过address传入了代理，此时代理集合将包含这唯一的代理。address的代理最终来源于OkHttpClient，我们可以在构造OkHttpClient时设置代理，来指定由该client执行的所有请求经过特定的代理。
另一种方式是，借助于ProxySelector获取多个代理。ProxySelector最终也来源于OkHttpClient，OkHttp的用户当然也可以对此进行配置。但通常情况下，使用系统默认的ProxySelector，来获取系统中配置的代理。
收集到的所有代理保存在列表 proxies 中。
为OkHttpClient配置Proxy或ProxySelector的场景大概是，需要让连接使用代理，但不使用系统的代理配置的情况。
收集特定代理服务器选择情况下的所有路由，因代理类型的不同而有着不同的过程：

  /** Returns the next proxy to try. May be PROXY.NO_PROXY but never null. */
  private Proxy nextProxy() throws IOException {
    if (!hasNextProxy()) {
      throw new SocketException("No route to " + address.url().host()
          + "; exhausted proxy configurations: " + proxies);
    }
    Proxy result = proxies.get(nextProxyIndex++);
    resetNextInetSocketAddress(result);
    return result;
  }

  /** Prepares the socket addresses to attempt for the current proxy or host. */
  private void resetNextInetSocketAddress(Proxy proxy) throws IOException {
    // Clear the addresses. Necessary if getAllByName() below throws!
    inetSocketAddresses = new ArrayList<>();

    String socketHost;
    int socketPort;
    if (proxy.type() == Proxy.Type.DIRECT || proxy.type() == Proxy.Type.SOCKS) {
      socketHost = address.url().host();
      socketPort = address.url().port();
    } else {
      SocketAddress proxyAddress = proxy.address();
      if (!(proxyAddress instanceof InetSocketAddress)) {
        throw new IllegalArgumentException(
            "Proxy.address() is not an " + "InetSocketAddress: " + proxyAddress.getClass());
      }
      InetSocketAddress proxySocketAddress = (InetSocketAddress) proxyAddress;
      socketHost = getHostString(proxySocketAddress);
      socketPort = proxySocketAddress.getPort();
    }

    if (socketPort < 1 || socketPort > 65535) {
      throw new SocketException("No route to " + socketHost + ":" + socketPort
          + "; port is out of range");
    }

    if (proxy.type() == Proxy.Type.SOCKS) {
      inetSocketAddresses.add(InetSocketAddress.createUnresolved(socketHost, socketPort));
    } else {
      // Try each address for best behavior in mixed IPv4/IPv6 environments.
      List<InetAddress> addresses = address.dns().lookup(socketHost);
      for (int i = 0, size = addresses.size(); i < size; i++) {
        InetAddress inetAddress = addresses.get(i);
        inetSocketAddresses.add(new InetSocketAddress(inetAddress, socketPort));
      }
    }

    nextInetSocketAddressIndex = 0;
  }

  /**
   * Obtain a "host" from an {@link InetSocketAddress}. This returns a string containing either an
   * actual host name or a numeric IP address.
   */
  // Visible for testing
  static String getHostString(InetSocketAddress socketAddress) {
    InetAddress address = socketAddress.getAddress();
    if (address == null) {
      // The InetSocketAddress was specified with a string (either a numeric IP or a host name). If
      // it is a name, all IPs for that name should be tried. If it is an IP address, only that IP
      // address should be tried.
      return socketAddress.getHostName();
    }
    // The InetSocketAddress has a specific address: we should only try that address. Therefore we
    // return the address and ignore any host name that may be available.
    return address.getHostAddress();
  }
收集一个特定代理服务器选择下的 连接的目标地址 因代理类型的不同而不同，这主要分为3种情况。 对于没有配置代理的情况，会对HTTP服务器的域名进行DNS域名解析，并为每个解析到的IP地址创建 连接的目标地址；对于SOCKS代理，直接以HTTP服务器的域名及协议端口号创建 连接的目标地址；而对于HTTP代理，则会对HTTP代理服务器的域名进行DNS域名解析，并为每个解析到的IP地址创建 连接的目标地址。
这里是OkHttp中发生DNS域名解析唯一的场合。对于使用代理的场景，没有对HTTP服务器的域名做DNS域名解析，也就意味着HTTP服务器的域名解析要由代理服务器完成。
代理服务器的收集是在创建 RouteSelector 完成的；而一个特定代理服务器选择下的 连接的目标地址 收集则是在选择Route时根据需要完成的。


2. RouteSelector 做的第二件事情是选择可用的路由。
  /**
   * Returns true if there's another route to attempt. Every address has at least one route.
   */
  public boolean hasNext() {
    return hasNextInetSocketAddress()
        || hasNextProxy()
        || hasNextPostponed();
  }

  public Route next() throws IOException {
    // Compute the next route to attempt.
    if (!hasNextInetSocketAddress()) {
      if (!hasNextProxy()) {
        if (!hasNextPostponed()) {
          throw new NoSuchElementException();
        }
        return nextPostponed();
      }
      lastProxy = nextProxy();
    }
    lastInetSocketAddress = nextInetSocketAddress();

    Route route = new Route(address, lastProxy, lastInetSocketAddress);
    if (routeDatabase.shouldPostpone(route)) {
      postponedRoutes.add(route);
      // We will only recurse in order to skip previously failed routes. They will be tried last.
      return next();
    }

    return route;
  }

  /** Returns true if there's another proxy to try. */
  private boolean hasNextProxy() {
    return nextProxyIndex < proxies.size();
  }

  /** Returns true if there's another socket address to try. */
  private boolean hasNextInetSocketAddress() {
    return nextInetSocketAddressIndex < inetSocketAddresses.size();
  }

  /** Returns the next socket address to try. */
  private InetSocketAddress nextInetSocketAddress() throws IOException {
    if (!hasNextInetSocketAddress()) {
      throw new SocketException("No route to " + address.url().host()
          + "; exhausted inet socket addresses: " + inetSocketAddresses);
    }
    return inetSocketAddresses.get(nextInetSocketAddressIndex++);
  }

  /** Returns true if there is another postponed route to try. */
  private boolean hasNextPostponed() {
    return !postponedRoutes.isEmpty();
  }

  /** Returns the next postponed route to try. */
  private Route nextPostponed() {
    return postponedRoutes.remove(0);
  }
RouteSelector 实现了两级迭代器来提供选择路由的服务。

3.维护接失败的路由的信息，以避免浪费时间去连接一些不可用的路由。 RouteSelector 借助于RouteDatabase 维护失败的路由的信息。
  /**
   * Clients should invoke this method when they encounter a connectivity failure on a connection
   * returned by this route selector.
   */
  public void connectFailed(Route failedRoute, IOException failure) {
    if (failedRoute.proxy().type() != Proxy.Type.DIRECT && address.proxySelector() != null) {
      // Tell the proxy selector when we fail to connect on a fresh connection.
      address.proxySelector().connectFailed(
          address.url().uri(), failedRoute.proxy().address(), failure);
    }

    routeDatabase.failed(failedRoute);
  }
RouteDatabase是一个简单的容器：

public final class RouteDatabase {
  private final Set<Route> failedRoutes = new LinkedHashSet<>();

  /** Records a failure connecting to {@code failedRoute}. */
  public synchronized void failed(Route failedRoute) {
    failedRoutes.add(failedRoute);
  }

  /** Records success connecting to {@code failedRoute}. */
  public synchronized void connected(Route route) {
    failedRoutes.remove(route);
  }

  /** Returns true if {@code route} has failed recently and should be avoided. */
  public synchronized boolean shouldPostpone(Route route) {
    return failedRoutes.contains(route);
  }
}

代理选择器ProxySelector的实现
在OkHttp3中，ProxySelector对象由OkHttpClient维护。

public class OkHttpClient implements Cloneable, Call.Factory {
. . . . . .
  final ProxySelector proxySelector;
  
  private OkHttpClient(Builder builder) {
    this.dispatcher = builder.dispatcher;
    this.proxy = builder.proxy;
    this.protocols = builder.protocols;
    this.connectionSpecs = builder.connectionSpecs;
    this.interceptors = Util.immutableList(builder.interceptors);
    this.networkInterceptors = Util.immutableList(builder.networkInterceptors);
    this.proxySelector = builder.proxySelector;

. . . . . .

  public ProxySelector proxySelector() {
    return proxySelector;
  }

. . . . . .

    public Builder() {
      dispatcher = new Dispatcher();
      protocols = DEFAULT_PROTOCOLS;
      connectionSpecs = DEFAULT_CONNECTION_SPECS;
      proxySelector = ProxySelector.getDefault();

. . . . . .

    Builder(OkHttpClient okHttpClient) {
      this.dispatcher = okHttpClient.dispatcher;
      this.proxy = okHttpClient.proxy;
      this.protocols = okHttpClient.protocols;
      this.connectionSpecs = okHttpClient.connectionSpecs;
      this.interceptors.addAll(okHttpClient.interceptors);
      this.networkInterceptors.addAll(okHttpClient.networkInterceptors);
      this.proxySelector = okHttpClient.proxySelector;
在创建OkHttpClient时，可以通过为OkHttpClient.Builder设置ProxySelector来定制ProxySelector。若没有指定，则使用系统默认的ProxySelector。OpenJDK 1.8版默认的ProxySelector为sun.net.spi.DefaultProxySelector：

public abstract class ProxySelector {
    /**
     * The system wide proxy selector that selects the proxy server to
     * use, if any, when connecting to a remote object referenced by
     * an URL.
     *
     * @see #setDefault(ProxySelector)
     */
    private static ProxySelector theProxySelector;

    static {
        try {
            Class<?> c = Class.forName("sun.net.spi.DefaultProxySelector");
            if (c != null && ProxySelector.class.isAssignableFrom(c)) {
                theProxySelector = (ProxySelector) c.newInstance();
            }
        } catch (Exception e) {
            theProxySelector = null;
        }
    }

    /**
     * Gets the system-wide proxy selector.
     *
     * @throws  SecurityException
     *          If a security manager has been installed and it denies
     * {@link NetPermission}{@code ("getProxySelector")}
     * @see #setDefault(ProxySelector)
     * @return the system-wide {@code ProxySelector}
     * @since 1.5
     */
    public static ProxySelector getDefault() {
        SecurityManager sm = System.getSecurityManager();
        if (sm != null) {
            sm.checkPermission(SecurityConstants.GET_PROXYSELECTOR_PERMISSION);
        }
        return theProxySelector;
    }
在Android平台上，默认ProxySelector所用的则是另外的实现：

public abstract class ProxySelector {

    private static ProxySelector defaultSelector = new ProxySelectorImpl();

    /**
     * Returns the default proxy selector, or null if none exists.
     */
    public static ProxySelector getDefault() {
        return defaultSelector;
    }

    /**
     * Sets the default proxy selector. If {@code selector} is null, the current
     * proxy selector will be removed.
     */
    public static void setDefault(ProxySelector selector) {
        defaultSelector = selector;
    }
Android平台下，默认的ProxySelector ProxySelectorImpl，其实现 (不同Android版本实现不同，这里以android-6.0.1_r61为例) 如下：

package java.net;
import java.io.IOException;
import java.util.Collections;
import java.util.List;
final class ProxySelectorImpl extends ProxySelector {
    @Override public void connectFailed(URI uri, SocketAddress sa, IOException ioe) {
        if (uri == null || sa == null || ioe == null) {
            throw new IllegalArgumentException();
        }
    }
    @Override public List<Proxy> select(URI uri) {
        return Collections.singletonList(selectOneProxy(uri));
    }
    private Proxy selectOneProxy(URI uri) {
        if (uri == null) {
            throw new IllegalArgumentException("uri == null");
        }
        String scheme = uri.getScheme();
        if (scheme == null) {
            throw new IllegalArgumentException("scheme == null");
        }
        int port = -1;
        Proxy proxy = null;
        String nonProxyHostsKey = null;
        boolean httpProxyOkay = true;
        if ("http".equalsIgnoreCase(scheme)) {
            port = 80;
            nonProxyHostsKey = "http.nonProxyHosts";
            proxy = lookupProxy("http.proxyHost", "http.proxyPort", Proxy.Type.HTTP, port);
        } else if ("https".equalsIgnoreCase(scheme)) {
            port = 443;
            nonProxyHostsKey = "https.nonProxyHosts"; // RI doesn't support this
            proxy = lookupProxy("https.proxyHost", "https.proxyPort", Proxy.Type.HTTP, port);
        } else if ("ftp".equalsIgnoreCase(scheme)) {
            port = 80; // not 21 as you might guess
            nonProxyHostsKey = "ftp.nonProxyHosts";
            proxy = lookupProxy("ftp.proxyHost", "ftp.proxyPort", Proxy.Type.HTTP, port);
        } else if ("socket".equalsIgnoreCase(scheme)) {
            httpProxyOkay = false;
        } else {
            return Proxy.NO_PROXY;
        }
        if (nonProxyHostsKey != null
                && isNonProxyHost(uri.getHost(), System.getProperty(nonProxyHostsKey))) {
            return Proxy.NO_PROXY;
        }
        if (proxy != null) {
            return proxy;
        }
        if (httpProxyOkay) {
            proxy = lookupProxy("proxyHost", "proxyPort", Proxy.Type.HTTP, port);
            if (proxy != null) {
                return proxy;
            }
        }
        proxy = lookupProxy("socksProxyHost", "socksProxyPort", Proxy.Type.SOCKS, 1080);
        if (proxy != null) {
            return proxy;
        }
        return Proxy.NO_PROXY;
    }
    /**
     * Returns the proxy identified by the {@code hostKey} system property, or
     * null.
     */
    private Proxy lookupProxy(String hostKey, String portKey, Proxy.Type type, int defaultPort) {
        String host = System.getProperty(hostKey);
        if (host == null || host.isEmpty()) {
            return null;
        }
        int port = getSystemPropertyInt(portKey, defaultPort);
        return new Proxy(type, InetSocketAddress.createUnresolved(host, port));
    }
    private int getSystemPropertyInt(String key, int defaultValue) {
        String string = System.getProperty(key);
        if (string != null) {
            try {
                return Integer.parseInt(string);
            } catch (NumberFormatException ignored) {
            }
        }
        return defaultValue;
    }
    /**
     * Returns true if the {@code nonProxyHosts} system property pattern exists
     * and matches {@code host}.
     */
    private boolean isNonProxyHost(String host, String nonProxyHosts) {
        if (host == null || nonProxyHosts == null) {
            return false;
        }
        // construct pattern
        StringBuilder patternBuilder = new StringBuilder();
        for (int i = 0; i < nonProxyHosts.length(); i++) {
            char c = nonProxyHosts.charAt(i);
            switch (c) {
            case '.':
                patternBuilder.append("\\.");
                break;
            case '*':
                patternBuilder.append(".*");
                break;
            default:
                patternBuilder.append(c);
            }
        }
        // check whether the host is the nonProxyHosts.
        String pattern = patternBuilder.toString();
        return host.matches(pattern);
    }
}
在Android平台上，主要是从系统属性System properties中获取代理服务器的配置信息，这里会过滤掉不能进行代理的主机的访问。

前面我们看到 RouteSelector 通过 Address 提供的Proxy和ProxySelector来收集Proxy信息及连接的目标地址信息。OkHttp3中用 Address 描述建立连接所需的配置信息，包括HTTP服务器的地址，DNS，SocketFactory，Proxy，ProxySelector及TLS所需的一些设施等等：

public final class Address {
  final HttpUrl url;
  final Dns dns;
  final SocketFactory socketFactory;
  final Authenticator proxyAuthenticator;
  final List<Protocol> protocols;
  final List<ConnectionSpec> connectionSpecs;
  final ProxySelector proxySelector;
  final Proxy proxy;
  final SSLSocketFactory sslSocketFactory;
  final HostnameVerifier hostnameVerifier;
  final CertificatePinner certificatePinner;

  public Address(String uriHost, int uriPort, Dns dns, SocketFactory socketFactory,
      SSLSocketFactory sslSocketFactory, HostnameVerifier hostnameVerifier,
      CertificatePinner certificatePinner, Authenticator proxyAuthenticator, Proxy proxy,
      List<Protocol> protocols, List<ConnectionSpec> connectionSpecs, ProxySelector proxySelector) {
    this.url = new HttpUrl.Builder()
        .scheme(sslSocketFactory != null ? "https" : "http")
        .host(uriHost)
        .port(uriPort)
        .build();

    if (dns == null) throw new NullPointerException("dns == null");
    this.dns = dns;

    if (socketFactory == null) throw new NullPointerException("socketFactory == null");
    this.socketFactory = socketFactory;

    if (proxyAuthenticator == null) {
      throw new NullPointerException("proxyAuthenticator == null");
    }
    this.proxyAuthenticator = proxyAuthenticator;

    if (protocols == null) throw new NullPointerException("protocols == null");
    this.protocols = Util.immutableList(protocols);

    if (connectionSpecs == null) throw new NullPointerException("connectionSpecs == null");
    this.connectionSpecs = Util.immutableList(connectionSpecs);

    if (proxySelector == null) throw new NullPointerException("proxySelector == null");
    this.proxySelector = proxySelector;

    this.proxy = proxy;
    this.sslSocketFactory = sslSocketFactory;
    this.hostnameVerifier = hostnameVerifier;
    this.certificatePinner = certificatePinner;
  }

  /**
   * Returns a URL with the hostname and port of the origin server. The path, query, and fragment of
   * this URL are always empty, since they are not significant for planning a route.
   */
  public HttpUrl url() {
    return url;
  }

  /** Returns the service that will be used to resolve IP addresses for hostnames. */
  public Dns dns() {
    return dns;
  }

  /** Returns the socket factory for new connections. */
  public SocketFactory socketFactory() {
    return socketFactory;
  }

  /** Returns the client's proxy authenticator. */
  public Authenticator proxyAuthenticator() {
    return proxyAuthenticator;
  }

  /**
   * Returns the protocols the client supports. This method always returns a non-null list that
   * contains minimally {@link Protocol#HTTP_1_1}.
   */
  public List<Protocol> protocols() {
    return protocols;
  }

  public List<ConnectionSpec> connectionSpecs() {
    return connectionSpecs;
  }

  /**
   * Returns this address's proxy selector. Only used if the proxy is null. If none of this
   * selector's proxies are reachable, a direct connection will be attempted.
   */
  public ProxySelector proxySelector() {
    return proxySelector;
  }

  /**
   * Returns this address's explicitly-specified HTTP proxy, or null to delegate to the {@linkplain
   * #proxySelector proxy selector}.
   */
  public Proxy proxy() {
    return proxy;
  }

  /** Returns the SSL socket factory, or null if this is not an HTTPS address. */
  public SSLSocketFactory sslSocketFactory() {
    return sslSocketFactory;
  }

  /** Returns the hostname verifier, or null if this is not an HTTPS address. */
  public HostnameVerifier hostnameVerifier() {
    return hostnameVerifier;
  }

  /** Returns this address's certificate pinner, or null if this is not an HTTPS address. */
  public CertificatePinner certificatePinner() {
    return certificatePinner;
  }

. . . . . .
}
OkHttp3中通过职责链执行HTTP请求。在其中的RetryAndFollowUpInterceptor里创建Address对象时，从OkHttpClient对象获取ProxySelector。Address对象会被用于创建StreamAllocation对象。StreamAllocation在建立连接时，从Address对象中获取ProxySelector以选择路由。

public final class RetryAndFollowUpInterceptor implements Interceptor {
. . . . . .
  private Address createAddress(HttpUrl url) {
    SSLSocketFactory sslSocketFactory = null;
    HostnameVerifier hostnameVerifier = null;
    CertificatePinner certificatePinner = null;
    if (url.isHttps()) {
      sslSocketFactory = client.sslSocketFactory();
      hostnameVerifier = client.hostnameVerifier();
      certificatePinner = client.certificatePinner();
    }

    return new Address(url.host(), url.port(), client.dns(), client.socketFactory(),
        sslSocketFactory, hostnameVerifier, certificatePinner, client.proxyAuthenticator(),
        client.proxy(), client.protocols(), client.connectionSpecs(), client.proxySelector());
  }
在StreamAllocation中，Address对象会被用于创建 RouteSelector 对象：

public final class StreamAllocation {
. . . . . .

  public StreamAllocation(ConnectionPool connectionPool, Address address) {
    this.connectionPool = connectionPool;
    this.address = address;
    this.routeSelector = new RouteSelector(address, routeDatabase());
  }
代理协议
如我们在 OkHttp3 HTTP请求执行流程分析 中看到的，OkHttp3对HTTP请求是通过Interceptor链来处理的。
RetryAndFollowUpInterceptor创建StreamAllocation对象，处理http的重定向及出错重试。对后续Interceptor的执行的影响为修改Request并创建StreamAllocation对象。
BridgeInterceptor补全缺失的一些http header。对后续Interceptor的执行的影响主要为修改了Request。
CacheInterceptor处理http缓存。对后续Interceptor的执行的影响为，若缓存中有所需请求的响应，则后续Interceptor不再执行。
ConnectInterceptor借助于前面分配的StreamAllocation对象建立与服务器之间的连接，并选定交互所用的协议是HTTP 1.1还是HTTP 2。对后续Interceptor的执行的影响为，创建了HttpStream和connection。
CallServerInterceptor作为Interceptor链中的最后一个Interceptor，用于处理IO，与服务器进行数据交换。

在OkHttp3中，收集的路由信息，是在ConnectInterceptor中建立连接时用到的。ConnectInterceptor 借助于 StreamAllocation 完成整个连接的建立，包括TCP连接建立，代理协议所要求的协商，以及SSL/TLS协议的协商，如ALPN等。我们暂时略过整个连接建立的完整过程，主要关注TCP连接建立及代理协议的协商过程的部分。

StreamAllocation 的findConnection()用来为某次特定的网络请求寻找一个可用的连接。

/**
   * Returns a connection to host a new stream. This prefers the existing connection if it exists,
   * then the pool, finally building a new connection.
   */
  private RealConnection findConnection(int connectTimeout, int readTimeout, int writeTimeout,
      boolean connectionRetryEnabled) throws IOException {
    Route selectedRoute;
    synchronized (connectionPool) {
      if (released) throw new IllegalStateException("released");
      if (codec != null) throw new IllegalStateException("codec != null");
      if (canceled) throw new IOException("Canceled");

      RealConnection allocatedConnection = this.connection;
      if (allocatedConnection != null && !allocatedConnection.noNewStreams) {
        return allocatedConnection;
      }

      // Attempt to get a connection from the pool.
      RealConnection pooledConnection = Internal.instance.get(connectionPool, address, this);
      if (pooledConnection != null) {
        this.connection = pooledConnection;
        return pooledConnection;
      }

      selectedRoute = route;
    }

    if (selectedRoute == null) {
      selectedRoute = routeSelector.next();
      synchronized (connectionPool) {
        route = selectedRoute;
        refusedStreamCount = 0;
      }
    }
    RealConnection newConnection = new RealConnection(selectedRoute);
    acquire(newConnection);

    synchronized (connectionPool) {
      Internal.instance.put(connectionPool, newConnection);
      this.connection = newConnection;
      if (canceled) throw new IOException("Canceled");
    }

    newConnection.connect(connectTimeout, readTimeout, writeTimeout, address.connectionSpecs(),
        connectionRetryEnabled);
    routeDatabase().connected(newConnection.route());

    return newConnection;
  }
OkHttp3中有一套连接池的机制，这里先尝试从连接池中寻找可用的连接，找不到时才会新建连接。新建连接的过程是：

选择一个Route；
创建 RealConnection 连接对象。
将连接对象保存进连接池中。
建立连接。
RealConnection 中建立连接的过程是这样的：

public final class RealConnection extends Http2Connection.Listener implements Connection {
  private final Route route;

  /** The low-level TCP socket. */
  private Socket rawSocket;

  /**
   * The application layer socket. Either an {@link SSLSocket} layered over {@link #rawSocket}, or
   * {@link #rawSocket} itself if this connection does not use SSL.
   */
  public Socket socket;
  private Handshake handshake;
  private Protocol protocol;
  public volatile Http2Connection http2Connection;
  public int successCount;
  public BufferedSource source;
  public BufferedSink sink;
  public int allocationLimit;
  public final List<Reference<StreamAllocation>> allocations = new ArrayList<>();
  public boolean noNewStreams;
  public long idleAtNanos = Long.MAX_VALUE;

  public RealConnection(Route route) {
    this.route = route;
  }

  public void connect(int connectTimeout, int readTimeout, int writeTimeout,
      List<ConnectionSpec> connectionSpecs, boolean connectionRetryEnabled) {
    if (protocol != null) throw new IllegalStateException("already connected");

    RouteException routeException = null;
    ConnectionSpecSelector connectionSpecSelector = new ConnectionSpecSelector(connectionSpecs);

    if (route.address().sslSocketFactory() == null) {
      if (!connectionSpecs.contains(ConnectionSpec.CLEARTEXT)) {
        throw new RouteException(new UnknownServiceException(
            "CLEARTEXT communication not enabled for client"));
      }
      String host = route.address().url().host();
      if (!Platform.get().isCleartextTrafficPermitted(host)) {
        throw new RouteException(new UnknownServiceException(
            "CLEARTEXT communication to " + host + " not permitted by network security policy"));
      }
    }

    while (protocol == null) {
      try {
        if (route.requiresTunnel()) {
          buildTunneledConnection(connectTimeout, readTimeout, writeTimeout,
              connectionSpecSelector);
        } else {
          buildConnection(connectTimeout, readTimeout, writeTimeout, connectionSpecSelector);
        }
      } catch (IOException e) {
        closeQuietly(socket);
        closeQuietly(rawSocket);
        socket = null;
        rawSocket = null;
        source = null;
        sink = null;
        handshake = null;
        protocol = null;

        if (routeException == null) {
          routeException = new RouteException(e);
        } else {
          routeException.addConnectException(e);
        }

        if (!connectionRetryEnabled || !connectionSpecSelector.connectionFailed(e)) {
          throw routeException;
        }
      }
    }
  }
在这个方法中，SSLSocketFactory为空，也就是要求请求/响应明文传输时，先做安全性检查，以确认系统允许明文传输，允许以请求的域名做明文传输。

然后根据路由的具体情况，执行不同的连接建立过程。对于需要创建隧道连接的路由，执行buildTunneledConnection()，对于其它情况，则执行buildConnection()。

判断是否要建立隧道连接的依据是代理的类型，以及连接的类型：

  /**
   * Returns true if this route tunnels HTTPS through an HTTP proxy. See <a
   * href="http://www.ietf.org/rfc/rfc2817.txt">RFC 2817, Section 5.2</a>.
   */
  public boolean requiresTunnel() {
    return address.sslSocketFactory != null && proxy.type() == Proxy.Type.HTTP;
  }
如果是HTTP代理，且请求建立SSL/TLS加密通道 (http/1.1的https和http2) ，则需要建立隧道连接。其它情形不需要建立隧道连接。


非隧道连接的建立
非隧道连接的建立过程为：

  /** Does all the work necessary to build a full HTTP or HTTPS connection on a raw socket. */
  private void buildConnection(int connectTimeout, int readTimeout, int writeTimeout,
      ConnectionSpecSelector connectionSpecSelector) throws IOException {
    connectSocket(connectTimeout, readTimeout);
    establishProtocol(readTimeout, writeTimeout, connectionSpecSelector);
  }

  private void connectSocket(int connectTimeout, int readTimeout) throws IOException {
    Proxy proxy = route.proxy();
    Address address = route.address();

    rawSocket = proxy.type() == Proxy.Type.DIRECT || proxy.type() == Proxy.Type.HTTP
        ? address.socketFactory().createSocket()
        : new Socket(proxy);

    rawSocket.setSoTimeout(readTimeout);
    try {
      Platform.get().connectSocket(rawSocket, route.socketAddress(), connectTimeout);
    } catch (ConnectException e) {
      throw new ConnectException("Failed to connect to " + route.socketAddress());
    }
    source = Okio.buffer(Okio.source(rawSocket));
    sink = Okio.buffer(Okio.sink(rawSocket));
  }
有 3 种情况需要建立非隧道连接：

无代理。
明文的HTTP代理。
SOCKS代理。
非隧道连接的建立过程为，建立TCP连接，然后在需要时完成SSL/TLS的握手及HTTP/2的握手建立Protocol。建立TCP连接的过程为：

创建Socket。非SOCKS代理的情况下，通过SocketFactory创建；在SOCKS代理则传入proxy手动new一个出来。
为Socket设置读超时。
完成特定于平台的连接建立。
创建用语IO的source和sink。
AndroidPlatform 的 connectSocket() 是这样的：

  @Override public void connectSocket(Socket socket, InetSocketAddress address,
      int connectTimeout) throws IOException {
    try {
      socket.connect(address, connectTimeout);
    } catch (AssertionError e) {
      if (Util.isAndroidGetsocknameError(e)) throw new IOException(e);
      throw e;
    } catch (SecurityException e) {
      // Before android 4.3, socket.connect could throw a SecurityException
      // if opening a socket resulted in an EACCES error.
      IOException ioException = new IOException("Exception in connect");
      ioException.initCause(e);
      throw ioException;
    }
  }
设置了SOCKS代理的情况下，仅有的特别之处在于，是通过传入proxy手动创建的Socket。route的socketAddress包含着目标HTTP服务器的域名。由此可见SOCKS协议的处理，主要是在Java标准库的 java.net.Socket 中处理的。对于外界而言，就好像是于HTTP服务器直接建立连接一样，因为连接时传入的地址都是HTTP服务器的域名。

而对于明文HTTP代理的情况下，这里没有任何特殊的处理。route的socketAddress包含着代理服务器的IP地址。HTTP代理自身会根据请求及响应的实际内容，建立与HTTP服务器的TCP连接，并转发数据。猜测HTTP代理服务器是根据HTTP请求中的"Host"等header内容来确认HTTP服务器地址的。

暂时先略过对建立协议过程的分析。

HTTP代理的隧道连接
buildTunneledConnection()用于建立隧道连接：

  /**
   * Does all the work to build an HTTPS connection over a proxy tunnel. The catch here is that a
   * proxy server can issue an auth challenge and then close the connection.
   */
  private void buildTunneledConnection(int connectTimeout, int readTimeout, int writeTimeout,
      ConnectionSpecSelector connectionSpecSelector) throws IOException {
    Request tunnelRequest = createTunnelRequest();
    HttpUrl url = tunnelRequest.url();
    int attemptedConnections = 0;
    int maxAttempts = 21;
    while (true) {
      if (++attemptedConnections > maxAttempts) {
        throw new ProtocolException("Too many tunnel connections attempted: " + maxAttempts);
      }

      connectSocket(connectTimeout, readTimeout);
      tunnelRequest = createTunnel(readTimeout, writeTimeout, tunnelRequest, url);

      if (tunnelRequest == null) break; // Tunnel successfully created.

      // The proxy decided to close the connection after an auth challenge. We need to create a new
      // connection, but this time with the auth credentials.
      closeQuietly(rawSocket);
      rawSocket = null;
      sink = null;
      source = null;
    }

    establishProtocol(readTimeout, writeTimeout, connectionSpecSelector);
  }
这里主要是两个过程：

建立隧道连接。
建立Protocol。
建立隧道连接的过程又分为几个步骤：

创建隧道请求
建立Socket连接
发送请求建立隧道
隧道请求是一个常规的HTTP请求，只是请求的内容有点特殊。最初创建的隧道请求如：

  /**
   * Returns a request that creates a TLS tunnel via an HTTP proxy. Everything in the tunnel request
   * is sent unencrypted to the proxy server, so tunnels include only the minimum set of headers.
   * This avoids sending potentially sensitive data like HTTP cookies to the proxy unencrypted.
   */
  private Request createTunnelRequest() {
    return new Request.Builder()
        .url(route.address().url())
        .header("Host", Util.hostHeader(route.address().url(), true))
        .header("Proxy-Connection", "Keep-Alive")
        .header("User-Agent", Version.userAgent()) // For HTTP/1.0 proxies like Squid.
        .build();
  }
一个隧道请求的例子如下：

Tunnel Request
请求的"Host" header中包含了目标HTTP服务器的域名。建立socket连接的过程这里不再赘述。

创建隧道的过程是这样子的：

  /**
   * To make an HTTPS connection over an HTTP proxy, send an unencrypted CONNECT request to create
   * the proxy connection. This may need to be retried if the proxy requires authorization.
   */
  private Request createTunnel(int readTimeout, int writeTimeout, Request tunnelRequest,
      HttpUrl url) throws IOException {
    // Make an SSL Tunnel on the first message pair of each SSL + proxy connection.
    String requestLine = "CONNECT " + Util.hostHeader(url, true) + " HTTP/1.1";
    while (true) {
      Http1Codec tunnelConnection = new Http1Codec(null, null, source, sink);
      source.timeout().timeout(readTimeout, MILLISECONDS);
      sink.timeout().timeout(writeTimeout, MILLISECONDS);
      tunnelConnection.writeRequest(tunnelRequest.headers(), requestLine);
      tunnelConnection.finishRequest();
      Response response = tunnelConnection.readResponse().request(tunnelRequest).build();
      // The response body from a CONNECT should be empty, but if it is not then we should consume
      // it before proceeding.
      long contentLength = HttpHeaders.contentLength(response);
      if (contentLength == -1L) {
        contentLength = 0L;
      }
      Source body = tunnelConnection.newFixedLengthSource(contentLength);
      Util.skipAll(body, Integer.MAX_VALUE, TimeUnit.MILLISECONDS);
      body.close();

      switch (response.code()) {
        case HTTP_OK:
          // Assume the server won't send a TLS ServerHello until we send a TLS ClientHello. If
          // that happens, then we will have buffered bytes that are needed by the SSLSocket!
          // This check is imperfect: it doesn't tell us whether a handshake will succeed, just
          // that it will almost certainly fail because the proxy has sent unexpected data.
          if (!source.buffer().exhausted() || !sink.buffer().exhausted()) {
            throw new IOException("TLS tunnel buffered too many bytes!");
          }
          return null;

        case HTTP_PROXY_AUTH:
          tunnelRequest = route.address().proxyAuthenticator().authenticate(route, response);
          if (tunnelRequest == null) throw new IOException("Failed to authenticate with proxy");

          if ("close".equalsIgnoreCase(response.header("Connection"))) {
            return tunnelRequest;
          }
          break;

        default:
          throw new IOException(
              "Unexpected response code for CONNECT: " + response.code());
      }
    }
  }
在前面创建的TCP连接之上，完成与代理服务器的HTTP请求/响应交互。请求的内容类似下面这样：

"CONNECT m.taobao.com:443 HTTP/1.1"
这里可能会根据HTTP代理是否需要认证而有多次HTTP请求/响应交互。

总结一下OkHttp3中代理相关的处理：

1.没有设置代理的情况下，直接与HTTP服务器建立TCP连接，然后进行HTTP请求/响应的交互。
2.设置了SOCKS代理的情况下，创建Socket时，为其传入proxy，连接时还是以HTTP服务器为目标地址。在标准库的Socket中完成SOCKS协议相关的处理。此时基本上感知不到代理的存在。
3.设置了HTTP代理时的HTTP请求，与HTTP代理服务器建立TCP连接。HTTP代理服务器解析HTTP请求/响应的内容，并根据其中的信息来完成数据的转发。也就是说，如果HTTP请求中不包含"Host" header，则有可能在设置了HTTP代理的情况下无法与HTTP服务器建立连接。
设置了HTTP代理时的HTTPS/HTTP2请求，与HTTP服务器建立通过HTTP代理的隧道连接。HTTP代理不再解析传输的数据，仅仅完成数据转发的功能。此时HTTP代理的功能退化为如同SOCKS代理类似。
4.设置了代理时，HTTP服务器的域名解析会被交给代理服务器执行。其中设置了HTTP代理时，会对HTTP代理的域名做域名解析。



1. RetryAndFollowUpInterceptor的createAddress中，Address的初始化就已经创建了代理相关的信息，

2. 在StreamAllocation构造中会创建RouteSelector，此时调用resetNextProxy，
   初始化List<Proxy> proxie,分创建OkhttpClient时有没有传入proxy两种情况, 
   如果有传入proxy，则是把proxy作为列表proxie的唯一元素，
   如果没有传入proxy，则使用address中的proxySelector来获取可用代理，
   proxySelector也可以像proxy一样，在OkhttpClient创建时传入，如果没有传入，则是使用 android操作系统默认的proxySelector（ProxySelector.getDefault()）

3. 在StreamAllocation中的findConnection(在死循环中调用的findConnection)方法中会调用routeSelector.next()，
   从此next()中产生递归调用，直到找到一个可用代理proxy,
   注意，调用routeSelector.next()是为了获取一个内部封装了proxy的route，这个route是用来获取（或者创建）一个可靠connection的

4. next()中的调用顺序 next->nextProxy->resetNextInetSocketAddress
   resetNextInetSocketAddress中对代理的处理分两种，
   一是socks代理，直接创建InetSocketAddress，add进List<InetSocketAddress> inetSocketAddresses
   二是无代理和http代理，先进行dns解析：address.dns()，将解析到地址的List<InetAddress> addresses列表遍历，全部创建InetSocketAddress，
	最后add进List<InetSocketAddress> inetSocketAddresses，
        这里的dns解析需要十分关注，即routeSelector的resetNextInetSocketAddress方法中的address.dns()
   
   next->nextInetSocketAddress，将列表inetSocketAddresses中的InetSocketAddress返回

   也就是说，即使是无代理状态，只要连接池中没有可用连接，就会走routeSelector.next

5. 在死循环StreamAllocation.findHealthyConnection方法中，RealConnection.isHealthy方法用于判断连接是否可用，如果通过findconnection拿到的连接不可用，
   那么就查找下一条connection
   isHealthy对socket是否可用进行了判断，连接是否关闭，输入流和输出流是否关机
   socket.isClosed() || socket.isInputShutdown() || socket.isOutputShutdown()
   如果是非get请求，还额外做了Timeout检查,

   Socket是否连接成功的设置是在 Socket.connect() 方法中，对connected变量的修改，仔细看它的 抛出异常字符串
   个人认为，如果tcp超时，或者断网就会是 close或者Shutdown状态)
   java.net.PlainSocketImpl继承java.net.AbstractPlainSocketImpl，
   PlainSocketImpl中用native实现了大量的连接方法，例如socketConnect，socketCreate，socketShutdown等等，
   例如调用了socketConnect，如果连接报错，就会抛出异常，那么connected变量就不会被设置为true
   还有java.net.SocksSocketImpl也值得看一看

-----------------------------------------------------------------------------------------------------------------------------------------

安全性相关,有关于安全性相关的 网络协议内容，到network_protocol中看，

TLS是在https中使用的，和http相比，https在传输层(tcp)到应用层(http)之间，多了个TLS或SSL安全协议

1. Okhttp3中，可直接添加sslSocketFactory到 OkHttpClient对象中，
或者使用默认的 TLS方法:
    X509TrustManager trustManager = systemDefaultTrustManager();
    this.sslSocketFactory = systemDefaultSslSocketFactory(trustManager);
    this.certificateChainCleaner = CertificateChainCleaner.get(trustManager);
systemDefaultSslSocketFactory -> sslContext（sslContext是androidSDK的框架）

2. certificateChainCleaner作为参数，创建一个很重要的对象：certificatePinner
     this.certificatePinner = builder.certificatePinner.withCertificateChainCleaner(
        certificateChainCleaner);
   certificatePinner就是 受信用证书集合

3. Address类中判断 传入的 sslSocketFactory是否为空，如果不是空，就设置scheme为https
.scheme(sslSocketFactory != null ? "https" : "http")

4. 重点解析RealConnection的connectTls()方法，
connectTls的很多 连接 TLS协议的参数都是从 Address中get出来的，
   (1)这个方法中，创建了 sslSocket对象
   (2)sslSocket.startHandshake() 开始 SSL或者TLS握手
   (3)获取握手对象 
      Handshake unverifiedHandshake = Handshake.get(sslSocket.getSession());
   (4)检查 证书是否满足：证书管理器certificatePinner
      // Check that the certificate pinner is satisfied by the certificates presented.
      address.certificatePinner().check(address.url().host(),
          unverifiedHandshake.peerCertificates());
      注意，如果不满足，会抛出异常，不会往下走了
   (5)连接成功，把当前socket 设置为sslSocket，并且创建source和sink
      socket = sslSocket;
      source = Okio.buffer(Okio.source(socket));
      sink = Okio.buffer(Okio.sink(socket));


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Http 请求头中的字段

Accept 设置接受的内容类型
Accept: text/plain

Accept-Charset 设置接受的字符编码
Accept-Charset: utf-8

Accept-Encoding 设置接受的编码格式
Accept-Encoding: gzip, deflate

Accept-Datetime 设置接受的版本时间
Accept-Datetime: Thu, 31 May 2007 20:35:00 GMT

Accept-Language 设置接受的语言
Accept-Language: en-US

Authorization 设置HTTP身份验证的凭证
Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==

Cache-Control 设置请求响应链上所有的缓存机制必须遵守的指令
Cache-Control: no-cache

Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项
Connection: keep-alive
Connection: Upgrade

Content-Length 设置请求体的字节长度
Content-Length: 348

Content-MD5 设置基于MD5算法对请求体内容进行Base64二进制编码
Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==

Content-Type 设置请求体的MIME类型（适用POST和PUT请求）
Content-Type: application/x-www-form-urlencoded

Cookie 设置服务器使用Set-Cookie发送的http cookie
Cookie: $Version=1; Skin=new;

Date 设置消息发送的日期和时间
Date: Tue, 15 Nov 1994 08:12:31 GMT

Expect 标识客户端需要的特殊浏览器行为
Expect: 100-continue

Forwarded 披露客户端通过http代理连接web服务的源信息
Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43
Forwarded: for=192.0.2.43, for=198.51.100.17

From 设置发送请求的用户的email地址
From: user@example.com

Host 设置服务器域名和TCP端口号，如果使用的是服务请求标准端口号，端口号可以省略
Host: en.wikipedia.org:8080
Host: en.wikipedia.org

If-Match 设置客户端的ETag,当时客户端ETag和服务器生成的ETag一致才执行，适用于更新自从上次更新之后没有改变的资源
If-Match: "737060cd8c284d8af7ad3082f209582d

If-Modified-Since 设置更新时间，从更新时间到服务端接受请求这段时间内如果资源没有改变，允许服务端返回304 Not Modified
If-Modified-Since: Sat, 29 Oct 1994 19:43:31 GMT

If-None-Match 设置客户端ETag，如果和服务端接受请求生成的ETage相同，允许服务端返回304 Not Modified
If-None-Match: "737060cd8c284d8af7ad3082f209582d"

If-Range 设置客户端ETag，如果和服务端接受请求生成的ETage相同，返回缺失的实体部分；否则返回整个新的实体
If-Range: "737060cd8c284d8af7ad3082f209582d"

If-Unmodified-Since 设置更新时间，只有从更新时间到服务端接受请求这段时间内实体没有改变，服务端才会发送响应
If-Unmodified-Since: Sat, 29 Oct 1994 19:43:31 GMT

Max-Forwards 限制代理或网关转发消息的次数
Max-Forwards: 10

Origin 标识跨域资源请求（请求服务端设置Access-Control-Allow-Origin响应字段）
Origin: http://www.example-social-network.com

Pragma 设置特殊实现字段，可能会对请求响应链有多种影响
Pragma: no-cache

Proxy-Authorization 为连接代理授权认证信息
Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==

Range 请求部分实体，设置请求实体的字节数范围，具体可以参见HTTP/1.1中的Byte serving
Range: bytes=500-999

Referer 设置前一个页面的地址，并且前一个页面中的连接指向当前请求，意思就是如果当前请求是在A页面中发送的，那么referer就是A页面的url地址（轶事：这个单词正确的拼法应该是"referrer",但是在很多规范中都拼成了"referer"，所以这个单词也就成为标准用法）
Referer: http://en.wikipedia.org/wiki/Main_Page

TE 设置用户代理期望接受的传输编码格式，和响应头中的Transfer-Encoding字段一样
TE: trailers, deflate

Upgrade 请求服务端升级协议
Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket

User-Agent 用户代理的字符串值
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0

Via 通知服务器代理请求
Via: 1.0 fred, 1.1 example.com (Apache/1.1)

Warning 实体可能会发生的问题的通用警告
Warning: 199 Miscellaneous warning

-----------------------------------------------------------------------------------------------------------------------------------------

Http 响应头中的字段
Access-Control-Allow-Origin 指定哪些站点可以参与跨站资源共享
Access-Control-Allow-Origin: *

Accept-Patch 指定服务器支持的补丁文档格式，适用于http的patch方法
Accept-Patch: text/example;charset=utf-8

Accept-Ranges 服务器通过byte serving支持的部分内容范围类型
Accept-Ranges: bytes

Age 对象在代理缓存中暂存的秒数
Age: 12

Allow 设置特定资源的有效行为，适用方法不被允许的http 405错误
Allow: GET, HEAD

Alt-Svc 服务器使用"Alt-Svc"（Alternative Servicesde的缩写）头标识资源可以通过不同的网络位置或者不同的网络协议获取
Alt-Svc: h2="http2.example.com:443"; ma=7200

Cache-Control 告诉服务端到客户端所有的缓存机制是否可以缓存这个对象，单位是秒
Cache-Control: max-age=3600

Connection 设置当前连接和hop-by-hop协议请求字段列表的控制选项
Connection: close

Content-Disposition 告诉客户端弹出一个文件下载框，并且可以指定下载文件名
Content-Disposition: attachment; filename="fname.ext"

Content-Encoding 设置数据使用的编码类型
Content-Encoding gzip

Content-Language 为封闭内容设置自然语言或者目标用户语言
Content-Language: en

Content-Length 响应体的字节长度
Content-Length: 348

Content-Location 设置返回数据的另一个位置
Content-Location: /index.htm

Content-MD5 设置基于MD5算法对响应体内容进行Base64二进制编码
Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==

Content-Range 标识响应体内容属于完整消息体中的那一部分
Content-Range: bytes 21010-47021/47022

Content-Type 设置响应体的MIME类型
Content-Type: text/html; charset=utf-8

Date 设置消息发送的日期和时间
Date: Tue, 15 Nov 1994 08:12:31 GMT

ETag 特定版本资源的标识符，通常是消息摘要
ETag: "737060cd8c284d8af7ad3082f209582d"

Expires 设置响应体的过期时间
Expires: Thu, 01 Dec 1994 16:00:00 GMT

Last-Modified 设置请求对象最后一次的修改日期
Last-Modified: Tue, 15 Nov 1994 12:45:26 GMT

Link 设置与其他资源的类型关系
Link: </feed>; rel="alternate"

Location 在重定向中或者创建新资源时使用
Location: http://www.w3.org/pub/WWW/People.html

P3P 以P3P:CP="your_compact_policy"的格式设置支持P3P(Platform for Privacy Preferences Project)策略，大部分浏览器没有完全支持P3P策略，许多站点设置假的策略内容欺骗支持P3P策略的浏览器以获取第三方cookie的授权
P3P: CP="This is not a P3P policy! See http://www.google.com/support/accounts/bin/answer.py?hl=en&answer=151657 for more info."

Pragma 设置特殊实现字段，可能会对请求响应链有多种影响
Pragma: no-cache

Proxy-Authenticate 设置访问代理的请求权限
Proxy-Authenticate: Basic

Public-Key-Pins 设置站点的授权TLS证书
Public-Key-Pins: max-age=2592000; pin-sha256="E9CZ9INDbd+2eRQozYqqbQ2yXLVKB9+xcprMF+44U1g=";

Refresh "重定向或者新资源创建时使用，在页面的头部有个扩展可以实现相似的功能，并且大部分浏览器都支持
<meta http-equiv="refresh" content="5; url=http://example.com/">

Refresh: 5; url=http://www.w3.org/pub/WWW/People.html
Retry-After 如果实体暂时不可用，可以设置这个值让客户端重试，可以使用时间段（单位是秒）或者HTTP时间

Example 1: Retry-After: 120
Example 2: Retry-After: Fri, 07 Nov 2014 23:59:59 GMT

Server 服务器名称
Server: Apache/2.4.1 (Unix)

Set-Cookie 设置HTTP Cookie
Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1

Status 设置HTTP响应状态
Status: 200 OK

Strict-Transport-Security 一种HSTS策略通知HTTP客户端缓存HTTPS策略多长时间以及是否应用到子域
Strict-Transport-Security: max-age=16070400; includeSubDomains

Trailer 标识给定的header字段将展示在后续的chunked编码的消息中
Trailer: Max-Forwards

Transfer-Encoding 设置传输实体的编码格式，目前支持的格式： chunked, compress, deflate, gzip, identity
Transfer-Encoding: chunked

TSV Tracking Status Value，在响应中设置给DNT(do-not-track),可能的取值
　　　"!" — under construction
　　　"?" — dynamic
　　　"G" — gateway to multiple parties
　　　"N" — not tracking
　　　"T" — tracking
　　　"C" — tracking with consent
　　　"P" — tracking only if consented
　　　"D" — disregarding DNT
　　　"U" — updated
TSV: ?

Upgrade 请求客户端升级协议
Upgrade: HTTP/2.0, HTTPS/1.3, IRC/6.9, RTA/x11, websocket

Vary 通知下级代理如何匹配未来的请求头已让其决定缓存的响应是否可用而不是重新从源主机请求新的

Example 1: Vary: *
Example 2: Vary: Accept-Language

Via 通知客户端代理，通过其要发送什么响应
Via: 1.0 fred, 1.1 example.com (Apache/1.1)

Warning 实体可能会发生的问题的通用警告
Warning: 199 Miscellaneous warning

WWW-Authenticate 标识访问请求实体的身份验证方案
WWW-Authenticate: Basic

X-Frame-Options 点击劫持保护：
　　　deny frame中不渲染
　　　sameorigin 如果源不匹配不渲染
　　　allow-from 允许指定位置访问
　　　allowall 不标准，允许任意位置访问
X-Frame-Options: deny


----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


服务器集群负载均衡原理？
在分布式集群环境中，如何把众多并发请求分布到不同的服务器上的呢？


什么是负载均衡
一台服务器的处理能力，主要受限于服务器自身的可扩展硬件能力。所以，在需要处理大量用户请求的时候，通常都会引入负载均衡器，将多台普通服务器组成一个系统，来完成高并发的请求处理任务。

最早的负载均衡技术是通过DNS来实现的，将多台服务器配置为相同的域名，使不同客户端在进行域名解析时，从这一组服务器中的请求随机分发到不同的服务器地址，从而达到负载均衡的目的。

但在使用DNS均衡负载时，由于DNS数据刷新的延迟问题，无法确保用户请求的完全均衡。而且，一旦其中某台服务器出现故障，即使修改了DNS配置，仍然需要等到新的配置生效后，故障服务器才不会被用户访问到。目前，DNS负载均衡仍在大量使用，但多用于实现“多地就近接入”的应用场景。

1996年之后，出现了新的网络负载均衡技术。通过设置虚拟服务地址（IP），将位于同一地域（Region）的多台服务器虚拟成一个高性能、高可用的应用服务池；再根据应用指定的方式，将来自客户端的网络请求分发到服务器池中。网络负载均衡会检查服务器池中后端服务器的健康状态，自动隔离异常状态的后端服务器，从而解决了单台后端服务器的单点问题，同时提高了应用的整体服务能力。

网络负载均衡主要有硬件与软件两种实现方式，主流负载均衡解决方案中，硬件厂商以F5为代表，软件主要为NGINX与LVS。但是，无论硬件或软件实现，都逃不出基于四层交互技术的“报文转发”或基于七层协议的“请求代理”这两种方式。 四层的转发模式通常性能会更好，但七层的代理模式可以根据更多的信息做到更智能地分发流量。一般大规模应用中，这两种方式会同时存在。






----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



